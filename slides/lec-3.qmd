---
title: "Data manipulation"
subtitle: "`tidyverse`, importing data"
author: 
  - name: Gerko Vink
    orcid: 0000-0001-9767-1924
    email: g.vink@uu.nl
    affiliations:
      - name: Methodology & Statistics @ Utrecht University
  - name: Statistical programming with R team
    orcid: 0000-0001-9767-1924
    email: no email
    affiliations:
      - name: Summerschool @ Utrecht University
date: 5 June 2025
date-format: "D MMM YYYY"
execute: 
  echo: true
format: 
  revealjs:
    theme: [solarized, gerko.scss]
    embed-resources: true
    progress: true
    margin: 0.075
    logo: logo.png 
    toc: false
    toc-depth: 1
    toc-title: Outline
    slide-number: true
    scrollable: false
    width: 1200
    reference-location: margin
    footer: Gerko Vink @ Anton de Kom Universiteit, Paramaribo
    standalone: true
    smaller: true
---

## Disclaimer {.smaller}
I owe a debt of gratitude to many people as the thoughts and code in these slides are the process of years-long development cycles and discussions with my team, friends, colleagues and peers. When someone has contributed to the content of the slides, I have credited their authorship.

These materials are generated by Gerko Vink, who holds the copyright. The intellectual property belongs to Utrecht University. Images are either directly linked, or generated with StableDiffusion or DALL-E. That said, there is no information in this presentation that exceeds legal use of copyright materials in academic settings, or that should not be part of the public domain. 

::: {.callout-warning}
You **may use** any and all content in this presentation - including my name - and submit it as input to generative AI tools, with the following **exception**:

- You must ensure that the content is not used for further training of the model
:::

## Slide materials and source code
::: callout-tip
# Materials
- course page: [www.gerkovink.com/sur](https://www.gerkovink.com/sur)
- source: [github.com/gerkovink/sur](https://github.com/gerkovink/sur)
:::

## Recap

Yesterday we have learned:



## Today
Today we will learn how to:

```{r include=FALSE}
knitr::opts_chunk$set(message = FALSE, comment = "")

```


```{r echo=F}
# Ensures the package "pacman" is installed
if (!require("pacman")) install.packages("pacman")

pacman::p_load(tidyverse,
               ggplot2
               )
```


```{r prepare data, echo=F}
planet     <- c("Mercury", "Venus", "Earth", "Mars", 
                "Jupiter", "Saturn", "Uranus", "Neptune")

planet_type     <- c("Terrestrial planet", "Terrestrial planet", 
              "Terrestrial planet", "Terrestrial planet", "Gas giant", 
              "Gas giant", "Gas giant", "Gas giant")

diameter <- c(0.382, 0.949, 1, 0.532, 11.209, 9.449, 4.007, 3.883)

rotation <- c(58.64, -243.02, 1, 1.03, 0.41, 0.43, -0.72, 0.67)

rings    <- c(FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE)

planets <- data.frame(planet_type = factor(planet_type), diameter, rotation, rings, row.names = planet)
```


## Topics of this lecture

The `tidyverse` packages 

* `dplyr` package
* pipe operator `%>%`
* standard solves for missing data

Importing data


# The tidyverse packages


## `tidyverse` and the data analysis cycle

![](img/lec-3/tidyverse.png){width=70%}

## Tidyverse and the verbs of data manipulation

Leading principle: language of programming should really behave like a language, tidy**verse**.

<br>

tidyverse: a few key **verb** that perform common types of data manipulation.


## Tidy data

The `tidyverse` packages operate on *tidy* data:

1. Each column is a __variable__

2. Each row is an __observation__

3. Each cell is a single __value__

<br>

```{r echo=FALSE, fig.align="center", out.width="70%", fig.cap="Untidy versus tidy data"}
knitr::include_graphics("img/lec-3/tidy.png")
```

# The `dplyr` package

## Data manipulation with `dplyr`

The *dplyr* package is a specialized package for working with `data.frames` (and the related `tibble`) to transform and summarize tabular data:

* summary statistics for grouped data
* selecting variables
* filtering cases
* (re)arranging cases
* computing new variables
* recoding variables


## `dplyr` cheatsheet

![](img/lec-3/Dplyr_CheatSheet.png)

## Why `dplyr`?

* Targeted for data analysis with data frames (tibbles)
* More intuitive and easier than base R functions
* No need for working with square brackets

<br> 

In combination with the pipe operator `%>%`:

* performs a series of operations step-by-step
* no need to write code inside-out
* no need to make intermediate objects 

## `dplyr` functions in this lecture

There are many functions available in dplyr, but we will focus on just the following `dplyr` functions (verbs):

| dplyr verbs   | Description           |
| --------------| ----------------------|
| `glimpse()`   | a transposed print of the data that shows all variables |
| `select()`    | selects variables (columns) based on their names |
| `filter()`    | subsets the rows of a data frame based on their values |
| `arrange()`   | re-order or arrange rows |
| `mutate()`    | adds new variables, or new variables that are functions of existing variables |
| `summarise()` | creates a new data frame with statistics of the variables (optional grouped by another variables) |
| `group_by()` | allows for group operations in the "split-apply-combine" concept |

Check the [`dplyr` cheat sheet](https://rstudio.github.io/cheatsheets/data-transformation.pdf) for examples.

## `dplyr::glimpse()`

* Prints a transposed version of the data: variables are the rows, observations are the columns.
* Makes it possible to see every column in a data frame.
* It is similar to `str()`, but shows more data.
* `str()` shows more detailed information about data structure.

```{r , echo=T, collapse=T}
dplyr::glimpse(planets)
str(planets)
```

## Select columns with `dplyr::select()`

Select variables `type` and `diameter` from the planets data frame:

```{r }

dplyr::select(planets, planet_type, diameter)

```

## Select columns with `dplyr::select()`

Select numerical variables with `where(is.numeric)`:

```{r}
dplyr::select(planets, where(is.numeric))
```

## Select rows with `dplyr::filter()`

Selects subsets of the rows of a data frame based on their values.

Select the planets that have a ring and that are gas giants:

```{r}
dplyr::filter(planets, rings == TRUE, planet_type == "Gas giant")
```

## The pipe operator %>%

Shortcut key: `Ctrl/Cmd + Shift + M` 

![](img/lec-3/pipe.png){width=25%}


## How `%>%` works

Passes (transformed) data on to the next operation

* avoids nested code

* avoids creation of intermediate objects
  

<br>

Basic principle of `%>%` operator

```{r  eval=FALSE}
data %>% 
  
  perform operation A and pass on transformed data %>% 
  
  perform operation B and pass on transformed data %>% 
  
  etc.
```


## `dplyr::select()` with the pipe operator

<div class="columns-2">
`dplyr::select` **without `%>%`**
```{r}
dplyr::select(planets, planet_type, diameter)
```
Straightforward and might be more familiar to those used to base R functions.

`dplyr::select` **with `%>%`**
```{r}
planets %>%
  dplyr::select(planet_type, diameter)
```
More readable and flexible when chaining multiple `dplyr` functions.
</div>


## Compute new variables with `dplyr::mutate()`

`dplyr::mutate()` adds a new variable to the data frame.

```{r include=T, echo=T, eval=F}
data %>% 
  dplyr::mutate(..., .keep = c("all", ...), .before = NULL, .after = NULL)
```

<br>

*Arguments:*

`.keep` specifies which variables to return, "all", "used", "unused", "none".

`.before` or `.after` determine where the new variables are inserted.


## Compute new variables with `dplyr::mutate()`

```{r include=T, echo=T, eval=F}
data %>% 
  dplyr::mutate(..., .keep = c("all", ...), .before = NULL, .after = NULL)
```

<br>

**Example**: compute a new variable `rotation_diameter = rotation/diameter`, add it to the data frame and keep all other variables:

```{r}
planets %>% 
  dplyr::mutate(rotation_diameter = rotation/diameter, .keep = "all") %>%
  glimpse()
```

## Temporary / permanent changes

The pipe operations do not make changes to the original data set, unless you save the results:

**Temporary:**
```{r eval=FALSE}
planets %>% 
  dplyr::mutate(rotation_diameter = 
                  rotation/diameter)

```

```{r}
names(planets)
```

**Changes saved in new data frame:**
```{r collapse=T}
new_data_set <- planets %>% 
  dplyr::mutate(rotation_diameter = 
                  rotation/diameter) 
names(new_data_set)
```


## Re-order rows with `dplyr::arrange()` 

Order the rows of the `planets` data set on ascending values of `diameter`:

<br>

<div class="columns-2">

Original data set:
```{r}
planets
```

Ordered data set, based on diameter:
```{r }
planets %>% 
  dplyr::arrange(diameter)
```
</div>



## Multiple transformations: base R and `dplyr`

Suppose we want to perform the following transformations:

1. Sort the rows of `planets` on ascending values of `rotation`
2. Select only planets with diameter `> 1`
3. Display the variables `planet_type`, `diameter` and `rotation`

<div class="columns-2">
**With base R code:**
```{r}
subset(planets[order(planets$rotation), ],  
       subset = diameter > 1, 
       select = c(planet_type, diameter, 
                  rotation))
```

**With `dplyr` and the pipe `%>%` operator**
```{r}
planets %>% 
  dplyr::filter(diameter > 1) %>% 
  dplyr::arrange(rotation) %>% 
  dplyr::select(planet_type, diameter, rotation)
```
</div>


## Summary statistics with `summarise()`

The `dplyr` function for summarizing data:

```{r}
planets %>% 
  dplyr::summarise(
    mean_diameter = mean(diameter), 
    sd_diameter = sd(diameter)
  )
```

* Various summary function(s):
  + `mean()`, `median()`, `sd()`, `var()`, `sum()`, for numeric variables
  + `n()`, `n_distinct()` for counts
  + many others, see: `?dplyr::select` and [cheat sheet](https://rstudio.github.io/cheatsheets/data-transformation.pdf))


## Summaries for groups with `group_by()`

The `dplyr` function for grouping rows of a data frame is very useful in combination with `summarise()`

Example: group the planets based on having rings (or not) and compute the mean and the standard deviation for each group.

```{r}
planets %>% 
  dplyr::group_by(rings) %>%
  dplyr::summarise(
    mean_diameter = mean(diameter), 
    sd_diameter = sd(diameter)
  )
```

## Pipes and the R model formula `~`

Sometimes the data we want to use, are "piped" in the wrong argument, see e.g.:
```{r eval=FALSE}
planets %>% 
  lm(diameter ~ rotation)
```
This leads to an error:

<font color="grey">Error in as.data.frame.default(data) : 

  cannot coerce class ‘"formula"’ to a data.frame</font>

The `%>%` pipe operator works with functions where the **first** argument of the next function in the pipeline is a data frame. 

For the function `lm()` the first argument is the model formula (a text object):

`lm(x ~ y, data = dataframe)`


## Solution: use placeholder `.`

We can use the `.` symbol to act as placeholder for the data:
```{r}
planets %>% 
  lm(diameter ~ rotation, data = .)
```



# Standard solves for missing values

## Dealing with missing values in `R`

Calculations based on missing values (NA's) are not possible in `R`:
```{r , collapse=T, echo=T}
variable <- c(1, 2, NA, 4, 5)
mean(variable)
```

There are two easy ways to perform "listwise deletion":
```{r collapse=T, echo=T}
mean(variable, na.rm = TRUE)
mean(na.omit(variable))
```

## Dealing with missing values with `dplyr`

```{r echo=F}
score <- c(1, 2, NA, 4, 5)
df <- data.frame(score)
```

```{r collapse=T}
df$score
```

<div class="columns-2">
No solution for missing values:
```{r}
df %>% 
  dplyr::summarise(
    mean_variable = mean(score), 
    sd_variable = sd(score)
  )
```
Use `na.rm = TRUE`:
```{r}
df %>% 
  dplyr::summarise(
    mean_variable = mean(score, na.rm = TRUE), 
    sd_variable = sd(score, na.rm = TRUE)
  )
```
</div>

## Style guide for coding pipes

Code with a single pipe operator on one line and spaces around `%>%`:

```{r include=T, echo=T, eval=F}
data %>% dplyr::select(X)
```

Code with multiple pipe operators on multiple lines:

```{r include=T, echo=T, eval=F}
data %>% 
  dplyr::group_by(X) %>% 
  dplyr::filter(Y > 4) %>% 
  dplyr::summarise(mean(Y))
```

but definitely NOT:

```{r include=T, echo=T, eval=F}
data%>%dplyr::group_by(X)%>%dplyr::filter(Y>4)%>%dplyr::summarise(mean(Y))
```

## More about coding style: `tidyverse` style guide

https://style.tidyverse.org/index.html



# Importing data into `R`

## R data format and workspace: `.RData`

The `R`  data file format is `.RData`.

In RStudio your data and the alterations on the data, are saved in the workspace.

* A workspace contains all changes you made to your data and functions during a session. 
* Workspaces are compressed and require relatively little memory when stored. The compression is very efficient and beats reloading large data sets from raw text.

You can save a data frame saved in your workspace with:

```{r eval=FALSE}
save(name_data_frame, "name_file.RData")
```

To open the data use:
```{r eval=FALSE}
load("name_file.Rdata")
```

Note: This code works if you have placed the .RData file in the same project folder as your Rmd file. You do not have to specify a file path. 

## Data sets in R (packages)

R has many in-built data sets. The command `data()` will give a list of all in-built data sets (also the data included in the non-base packages that are activated). 

Open an in-built data set as follows:
```{r eval=F}
require(MASS) # load the package MASS that contains the mammals data.
data(mammals) # load the mammals data
```

## Importing delimited data files

Text files (.txt) can be imported in to R with:
```{r eval=FALSE}
read.table("mammalsleep.txt")
```

CSV (comma seperated values) files can be imported with the `readr` package from `tidyverse`:

```{r eval=FALSE}
read_csv("filename.csv")
```


## Read and write statistical data formats

There are many packages that facilitate importing/exporting other data formats from statistical software: 

* SPSS: the function `read_spss` from package `haven` (but also other data formats from Stata and SAS)
* Mplus: package `MplusAutomation`
* Stata: `read.dta()` in `foreign`
* SAS: `sasxport.get()` from package `Hmisc` 
* MS Excel: 
    + function `read.xlsx()` from package `openxlsx`
    + function `read_excel()` from package `readxl`

[`haven`](https://haven.tidyverse.org/index.html) by [Hadley Wickham](http://hadley.nz) provides wonderful functions to import and export many data types from software such as Stata, SAS and SPSS. 

For a short guideline to import multiple formats into `R`, see e.g. http://www.statmethods.net/input/importingdata.html. 

# Linear regression

## Content

1. The linear model `lm()`

2. Simple regression
    
3. Multiple regression



```{r include = FALSE}
knitr::opts_chunk$set(comment = "", message=F, warning=F)
library(ggplot2)
library(dplyr)
library(patchwork)
```

## Linear Model

The linear regression model:

$$y_i=\beta_0+\sum_{j}\beta_{j} x_{ij}+\varepsilon_i, \ \ \ \ \ \  \varepsilon_i\sim N(0, \sigma^2)$$
where

- $y_i$ is score of individual $i$ on the numeric dependent variable $Y$

- $x_{ij}$ is the score of individual $i$ on predictor $X_j$  

- $\beta_0$ is the intercept 

- $\beta_j$ is the slope of $X_j$

- $\varepsilon_{i}$ is the residual (prediction error)


## The `lm()` function

```{r eval = FALSE}
lm(formula, data) # returns an object of class lm
```

formula        | model
:--------------|--------------------------
`y ~ 1`        | intercept-only
`y ~ x1`       | main effect of x1
`y ~ x1 + x2`  | main effects of x1, x2
`y ~ .`        | main effects of all predictors
`y ~ . - x1`   | main effects of all predictors except x1
`y ~ x1 + x2 + x1:x2`    | main effects + interaction between x1 and x2
`y ~ x1*x2`    | idem
`y ~ .^2`      | main effects + pairwise interactions between all predictors


# Simple regression 

## Continuous predictor


- observed = fitted + residual

$$y_i=\hat{y}_i+\varepsilon_i$$
- fitted = intercept + slope times x

$$\hat{y}_i=\beta_0 + \beta_1x_i$$

<br>

- fitted changes with $\beta_1$ for each unit increase in $x$

## Regression line for `mpg ~ disp`

```{r message = FALSE}
ggplot(mtcars, aes(disp, mpg)) + 
  geom_point() +
  xlim(0, 500) +
  geom_smooth(method = "lm", se = FALSE, fullrange=T)
```

## Coefficients

Interpretation the parameter estimates.

```{r}
(fit <- lm(mpg ~ disp, mtcars))
```

## Structure of `lm` object

```{r}
str(fit)
```

## Summary of `lm` object 

```{r}
summary(fit)
```

## Structure summary `lm` object

```{r}
str(summary(fit))
```


## Extracting  `lm` list elements:


Function / Subsetting        | Output
-----------------------------|-------------------------
`coef(fit) / fit$coef`       | coefficients
`fitted(fit) / fit$fitted`   | fitted values
`resid(fit) / fit$resid`     | residuals
`summary(fit)$r.squared`     | R-squared statistic

```{r collapse = T}
fit$coef
summary(fit)$r.squared
```



# Categorical predictor 


## Dummy variables

Categorical predictors are converted into dummy variables: 

- each category has a dummy with value 1 for that category, and 0 otherwise

- except for the reference category  (0 on all dummies)

- all categories are compared to the reference category



```{r echo = FALSE, out.width = "70%", fig.cap = "Reference category of $z$ is $a$", fig.align = "center"}
knitr::include_graphics("img/lec-3/dummies.png")
```


## Interpreting dummies

Model for categorical $Z$ with categories $a, b, c$:

$$\hat{y}=\beta_0+\beta_1zb+\beta_2zc$$

<br>

parameters        | interpretation
------------------|---------------
$\beta_0$         | predicted mean category $a$ (reference category)
$\beta_0+\beta_1$ | predicted mean category $b$
$\beta_0+\beta_2$ | predicted mean category $c$



## Example

Interpret the parameter estimates of model `mpg ~ factor(am)` 

- `am = 0` is  automatic and `am = 1` is manual transmission

- reference category is `am = 0`


```{r}
coef(lm(mpg ~ factor(am), mtcars))
```



## Regression line

```{r message = FALSE}
ggplot(mtcars, aes(am, mpg)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```


## Predictor `gear` with 3 categories

Works the same as above, but one more dummy needed

- linear model with 2 dummies

- reference category `gear = 3`

```{r}
lm(mpg ~ factor(gear), mtcars)
```



## Regression lines


Two regression lines

- one from reference 3 gears to 4 gears

- one from reference 3 gears to 5 gears

```{r fig.asp = 0.4, echo=F}
mtcars %>% filter(gear != 5) %>%  
    ggplot(aes(gear, mpg)) + 
    geom_point() + 
    geom_smooth(method = "lm", se = F) + 
    scale_x_continuous(breaks = c(3, 4)) +
  
mtcars %>% filter(gear != 4) %>% 
    ggplot(aes(gear, mpg)) + 
    geom_point() + 
    geom_smooth(method = "lm", se = F) + 
    scale_x_continuous(breaks = c(3, 5))
```


## Factor or not?

The model `mpg ~ gear` interprets the number of gears as numeric

- only one slope is estimated

```{r fig.dim=c(4, 3), echo=F}
ggplot(mtcars, aes(gear, mpg)) + geom_point()+geom_smooth(method="lm", se=F) +  
    scale_x_continuous(breaks = 3:5)
```


## Model comparisons with `anova()`

Which model fits better: 

1. `mpg ~ gear`  

2. `mpg ~ factor(gear)`

<br>

Model 2 has one more parameter, so it is expected to fit better.

- But is it significantly better?

<br>

We can check this with an $F$-test for the $R^2$-change

- The function to do this test is `anova(model 1, model 2)`


## ANOVA

Compare the fit of the models:

- `mpg ~ 1`
- `mpg ~ gear`
- `mpg ~ factor(gear)`

```{r}
anova(lm(mpg ~ 1, mtcars),
      lm(mpg ~ gear, mtcars),
      lm(mpg ~ factor(gear), mtcars))
```



# Multiple regression


## Main-effects model

No interactions in the model, e.g.

$$\hat{y}=\beta_0+\beta_1x_1+\beta_2x_2$$
<br>

Interpretation

- the slope of $x_1$ does not depend on $x_2$, and vice versa

- the slopes of $x_1$ and $x_2$ are corrected for the correlation $r_{x_1,x_2}$


## Model with `disp` and `gear`

```{r results = "hold"}
lm(mpg ~ disp, mtcars)$coef %>% round(3)

lm(mpg ~ gear, mtcars)$coef %>% round(3)

lm(mpg ~ disp + gear, mtcars)$coef %>% round(3)
```

- The slope of `gear` almost disappeared in the last model.


## Interactions

The slope of one predictor depends on the value of the other

```{r}
lm(mpg ~ disp * factor(am), mtcars) 
```

- The slope of `disp` for `am = 0` is -0.2758

- The slope of `disp` for `am = 1` is -0.2758 - 0.03145 = -0.30725

## Visualization of the interaction model

There is obviously an interaction

```{r fig.height = 3, fig.width = 4, message=F}
ggplot(mtcars, aes(disp, mpg, col = factor(am))) + 
  geom_point() + 
  geom_smooth(method = "lm", se=F)
```



## Comparison coefficients

```{r echo=F}
full_join(
tibble::rownames_to_column(data.frame("main effects"=lm(mpg ~ disp + factor(am), mtcars)$coef)),
tibble::rownames_to_column(data.frame(interaction=lm(mpg ~ disp * factor(am), mtcars)$coef)))

```



## Compare the plots

- Main effects model: same slopes, different intercepts (not visible)

- Interaction model: different slopes and different intercepts

```{r echo = FALSE, message = FALSE, fig.asp = .4}
ggplot(mtcars, aes(disp, mpg, col = factor(gear))) + 
  geom_point() + 
  geom_line(aes(y = predict(lm(mpg ~ disp + factor(gear), mtcars))), linewidth = 1) +    
  ggtitle("main effects model") +

ggplot(mtcars, aes(disp, mpg, col = factor(gear))) +
  geom_point() +
  geom_smooth(method = "lm", se = F, fullrange = T) +
  ylim(c(10, 35)) +
  ggtitle("interaction model")
```


## ANOVA


Compare the fit of the main effects and interaction model


```{r}
anova(lm(mpg ~ disp + factor(gear), mtcars),
      lm(mpg ~ disp * factor(gear), mtcars))
```

# Practical




