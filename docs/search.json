[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Module 6: Introduction to Data Processing & Programming in R",
    "section": "",
    "text": "Studieprogramma\nDit Quarto boek bevat het cursusmateriaal en de informatie voor Module 6: Introduction to Data Processing & Programming in R. De genummerde hoofdstukken in dit boek komen overeen met de hoorcolleges en practica, waarbij elk gecombineerd hoorcollege en practicum wordt weergegeven als één hoofdstuk.\n\n\n\n\n\n\n\n\nWeek 1\nDate\nLocation\n\n\n\n\nIntroductie in R & RStudio\n02 Juni\nTBD\n\n\nData Management\n03 Juni\nTBD\n\n\nData Manipulatie\n04 Juni\nTBD\n\n\nStatistische Analyse\n05 Juni\nTBD\n\n\nGeen Hoorcollege\n06 Juni\nTBD\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\nDate\nLocation\n\n\n\n\nFunctioneel Programmeren\n09 Juni\nTBD\n\n\nGeavanceerde Data Technieken\n10 Juni\nTBD\n\n\nGeen Hoorcollege\n11 Juni\nTBD\n\n\nData Visualisatie\n12 Juni\nTBD\n\n\nOntwikkelen en Programmeren in R\n13 Juni\nTBD",
    "crumbs": [
      "Studieprogramma"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Module handleiding",
    "section": "",
    "text": "Cursusgegevens",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#cursusgegevens",
    "href": "overview.html#cursusgegevens",
    "title": "Module handleiding",
    "section": "",
    "text": "Vakcode\nAS_06\n\n\nOpleiding\nMaster Applied Statistics\n\n\nLeerlijn/Vakgroep/Discipline\nData-Analyse\n\n\nAantal studiepunten\n6 ECTs\n\n\nSemester en studiefase\nJaar 1, semester 2\n\n\nContacturen per semester\n40\n\n\nCollege periode\n2 juni – 13 juni 2025\n\n\nWerkcolleges+studievrije periode\n16 juni – 10 juli 2025\n\n\nTentamen\n11 juli 2025\n\n\nHertentamenperiode\n25 augustus – 5 september 2025\n\n\nVereiste voorkennis\nAfgeronde Wetenschappelijke Bachelor/ Premaster Wetenschappelijke Vorming IGSR\n\n\nDocent(en) + contactgegevens\nGerko Vink, g.vink@uu.nl\n\n\nSpreekuur docent(en)\nOp afspraak",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#inleiding",
    "href": "overview.html#inleiding",
    "title": "Module handleiding",
    "section": "Inleiding",
    "text": "Inleiding\nDit is de handleiding voor de module Introduction to Data Processing & Programming in R van de Masteropleiding Applied Statistics. Het doel van deze module is om inzicht te bieden in zowel de basisprincipes als de basis dataverwerking- en analysetechnieken in R.\nDeze module richt zich op het ontwikkelen van praktische vaardigheden in R, een statistisch softwarepakket, dat breed wordt ingezet binnen de academische wereld en de beroepspraktijk bij het uitvoeren van statistische analyses. De module biedt daarnaast verdiepende inzichten in de belangrijkste functies bij het programmeren in R, variërend van het importeren en beheren van datasets tot fundamentele analyses en visualisaties en presentatie van documenten. De leerdoelen van de module worden ook in deze handleiding opgenomen evenals een uitgebreide omschrijving van de vakinhoud, het programmaoverzicht en de lesonderdelen. Tenslotte volgt er een uitwerking van de wijze van toetsen en de vaststelling van het eindcijfer.",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#eindkwalificaties-leerdoelen",
    "href": "overview.html#eindkwalificaties-leerdoelen",
    "title": "Module handleiding",
    "section": "Eindkwalificaties & Leerdoelen",
    "text": "Eindkwalificaties & Leerdoelen\nDit vak draagt bij aan de volgende eindkwalificaties van de Masteropleiding:\n\nKennis en inzicht\n\n\nEK3. Verdiepende kennis over statistische softwarepakketten en de standaard terminologie horende bij calculatie-en programeer vaardigheden in R\n\n\nToepassen kennis en inzicht De afgestudeerde is in staat om:\n\n\nEK5. Secundaire of primaire data van geavanceerde statistische technieken in R te combineren en bewerken.\n\n\nCommunicatie De afgestudeerde is in staat om:\n\n\nEK9. Als statisticus binnen multidisciplinaire teams te werken en te communiceren.",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#leerdoelen",
    "href": "overview.html#leerdoelen",
    "title": "Module handleiding",
    "section": "Leerdoelen",
    "text": "Leerdoelen\nLeerdoelen voor deze cursus zijn aangegeven met tussen haakjes aan welke eindkwalificatie die gerelateerd zijn.\nAan het eind van deze module kan de student: - de software R gebruiken voor reproduceerbare statistische analyse van gegevens en programmeren (EK3) - met behulp van syntax en code grafieken te (re)produceren, verwerken en aanpassen (EK5) - in georganiseerd teamverband werken om data uit verschillende bronnen te verkennen, samen te voegen en aan te passen, en inferentiële, predictieve en beschrijvende data-analyse projectmatig te presenteren en uit te voeren (EK9)",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#omschrijving-van-de-vakinhoud",
    "href": "overview.html#omschrijving-van-de-vakinhoud",
    "title": "Module handleiding",
    "section": "Omschrijving van de vakinhoud",
    "text": "Omschrijving van de vakinhoud\nDe hoofdonderwerpen die hierbij aan de orde komen zijn:\n\ndatabestanden beheren, data uit verschillende softwarebronnen exporteren en inlezen (importeren)\ndatabeheer en -hercodering, data mutaties en data throughput\ncreëren van grafieken en visualisaties (visual storytelling)\nsyntax en code lezen en schrijven (programmeren)\ntools om data te verkennen\nbestanden en gegevens uit verschillende bronnen samenvoegen (mergen)\nreproduceerbare codes schrijven om inferentiële, predictieve en beschrijvende statistieken en visualisaties te produceren voor twee of meer variabelen.",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#programmaoverzicht",
    "href": "overview.html#programmaoverzicht",
    "title": "Module handleiding",
    "section": "Programmaoverzicht",
    "text": "Programmaoverzicht\nEen overzicht van het studieprogramma staat op temporale volgorde in de hoofdstukken van dit boek. Een tabel met duidelijke weergave van welk hoofdstuk op welke dag behandeld wordt, is hieronder te vinden. De hoofdstukken met lesstof bevatten een overzicht van de behandelde onderwerpen, leerdoelen, benodigde voorbereiding en cursusmaterialen voor ieder gecombineerd hoor/werkcollege.\n\nProgrammaoverzicht en lesonderdelen\n\n\nCollegedag (=4 uren)\nDatum\n\n\n\n\nGecombineerde HC & WC\nPeriode: 2 juni – 13 juni 2025\n\n\nIntroductie in R & RStudio\nMaandag 2 Juni 2025\n\n\nData Management\nDinsdag 3 Juni 2025\n\n\nGeen hoorcollege\nWoensdag 4 Juni 2025\n\n\nData Manipulatie\nDonderdag 5 Juni 2025\n\n\nStatistische Analyse\nVrijdag 6 Juni 2025\n\n\nFunctioneel Programmeren\nMaandag 09 Juni\n\n\nGeavanceerde Data Technieken\nDinsdag 10 Juni\n\n\nGeen Hoorcollege\nWoensdag 11 Juni\n\n\nData Visualisatie\nDonderdag 12 Juni\n\n\nOntwikkelen en Programmeren in R\nVrijdag 13 Juni\n\n\nWerkcolleges\nMa 16 – Vr 27 juni 2025\n\n\nOnderwijsvrij\n30 juni – 10 juli 2025\n\n\nTentamen\nVrijdag 11 juli 2025",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#onderwijsvormgeving",
    "href": "overview.html#onderwijsvormgeving",
    "title": "Module handleiding",
    "section": "Onderwijsvormgeving",
    "text": "Onderwijsvormgeving\nDe leeractiviteiten in deze module zijn: Hoorcolleges (HC): Theorie en voorbeelden (studenten bestuderen de slides vóór de colleges); Werkcolleges (WC): Tijdens de werkcolleges krijgen studenten verdere instructies/begeleiding voor het maken van de opdrachten; Zelfstudie: Het uitwerken van de gegeven opdrachten en analyses als voorbereiding op de WC (individueel of als groep). In deze module wordt gewerkt met ‘samenwerkend leren’ als didactische werkvorm. Hierbij worden de studenten in groepen ingedeeld waarbij ze, in dit geval, complementair zelfstandig aan de opdrachten werken. Tijdens de werkcolleges worden de opdrachten gepresenteerd en bediscussieerd in groepsverband volgens een beurtensysteem. Na het college wordt door de groep de uitgewerkte opdrachten en aantekeningen geüpload op Moodle in de hiervoor aangemaakte mappen. Deze werkvorm stelt de studenten in staat kennis met elkaar te delen en vaardigheden en inzichten op te doen, tijdens zowel het groepswerk als de presentaties.",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#verwachtingen-van-studenten-en-voorkennis",
    "href": "overview.html#verwachtingen-van-studenten-en-voorkennis",
    "title": "Module handleiding",
    "section": "Verwachtingen van studenten en voorkennis",
    "text": "Verwachtingen van studenten en voorkennis\nVan de studenten wordt verwacht dat ze zich voorbereiden op de werkcolleges. De studenten dienen ook een actieve en zelfsturende leer houding te demonstreren waarbij ze nieuwe kennis willen/kunnen uitzoeken. Verder wordt er verwacht dat ze naast de colleges wekelijks gemiddeld 20 uur aan het vak besteden (zie Module belasting).\nDe verwachtingen van de student voor het goed doorlopen van deze module zijn verder:\n\nBasiskennis wiskunde en statistiek (BSc niveau)\n\nHet tijdig downloaden van college slides, documenten (via Moodle) voor zelfstudie, collegevoorbereiding en het maken van de opdrachten\nControleren van de Module/cursus Moodle page voor aankondigingen over colleges en toetsing\nHet hebben van een Laptop of PC/ microfoon / webcam (eventueel) / Goede Internetverbinding voor het volgen van sommige colleges",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#module-belasting",
    "href": "overview.html#module-belasting",
    "title": "Module handleiding",
    "section": "Module belasting",
    "text": "Module belasting\nDe module belasting telt in totaal 6 ECTs (SP) wat gemiddeld neerkomt op het reserveren van 168 studieuren. In de onderstaande tabel vind je de spreiding van de uren over de diverse activiteiten die betrokken zijn bij het behalen van dit vak met een opsplitsing van contacturen, zelfstudie uren en het tentamen.\n\nSTUDIEPUNTEN UITGEWERKT IN CONTACT EN ZELF-STUDIEUREN\n\n\n\n\n\n\n\nActiviteit\nAantal weken/dagen\nTotaal aantal uren\n\n\n\n\nContacturen\n\n\n\n\nGecombineerde hoor- en werkcolleges\n2 weken\n8 dagen x 4 uren = 40 uren\n\n\nWerkcolleges\n2 dagen\n2 dagen x 4 uren= 8uren\n\n\nResponsiecollege\n1 dag\n3,5 uren\n\n\nZelfstudie uren\n\n\n\n\nStudieplanning maken\n2 weken\n2 uren/week = 4 uren\n\n\nLiteratuurstudie\n2 weken\n8 uren/week = 16 uren\n\n\nUitwerken van vraagstukken/opdrachten\n2 weken\n20 uren/week = 40 uren\n\n\nVoorbereiding middels ondersteunend materiaal (collegeslides, video’s)\n2 weken\n15 uren/week = 30 uren\n\n\nHerhaling\n2 weken\n7,5 uren/week = 15 uren\n\n\nTentamen\n1 dag\n3,5 uren\n\n\n\nTotaal aantal uren: 168 uren (6 ECTs: 6 x 28 = 168 uren )",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#wijze-van-toetsen-en-vaststellen-eindcijfer",
    "href": "overview.html#wijze-van-toetsen-en-vaststellen-eindcijfer",
    "title": "Module handleiding",
    "section": "Wijze van toetsen en vaststellen eindcijfer",
    "text": "Wijze van toetsen en vaststellen eindcijfer\nHet tentamen van Module 5 wordt voor 100% getoetst op basis van opdrachten die fysiek en individueel worden afgenomen in 3-uren tijd. Het toetswerk is een Statistische Analyse kennis- en vaardigheidstoets waarbij de focus gelegd wordt op het uitvoeren van analyses op gecombineerde en bewerkte datafiles (met incomplete informatie). Deze datafiles worden gebruikt voor het beantwoorden van de probleemstellingen van gegeven casussen waarbij ook kennis m.b.t. interpretatie van resultaten getoetst zal worden. Beoordeling geschiedt d.m.v. een antwoordmodel.\n\nCesuur\nDe student haalt deze module met een cijfer van 5.5 of meer. Indien een student de toets niet heeft gehaald, dan komt die in aanmerking voor een herkansing. Voor het deelnemen zijn er geen bijkomende voorwaarden dan die vermeld zijn in de OER waaronder het tijdig intekenen voor deelname.",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "overview.html#collegemateriaal",
    "href": "overview.html#collegemateriaal",
    "title": "Module handleiding",
    "section": "Collegemateriaal",
    "text": "Collegemateriaal\n\nCollegeslides, gepubliceerd Moodle en op www.gerkovink.com/sur\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023, 2nd edition). R for data science. ” O’Reilly Media, Inc.”. Open Access Book freely available from https://r4ds.hadley.nz/\nWickham, H. (2019). Advanced R. Chapman and Hall/CRC. Open Access Book freely available from https://adv-r.hadley.nz\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2023, 2nd edition, corrected print). An introduction to statistical learning with applications in R. New York: springer. Open Access Book freely available from https://www.statlearning.com/\nVan Buuren, S. (2018). Flexible Imputation of Missing Data. CRC Press. Book freely available from https://stefvanbuuren.name/fimd/\nEen selectie van relevante en vrij beschikbare open source materialen",
    "crumbs": [
      "Module handleiding"
    ]
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Docent\nAls psycholoog ben ik per ongeluk statisticus geworden. Ik heb een voorliefde voor het overbrengen van informatie en lesgeven, en doe dit vooral over mijn expertise in rekenen, wiskunde, programmeren en kunstmatige intelligentie (AI). Ik geef lezingen en cursussen over de hele wereld, maar vooral in Utrecht. Daarnaast maak ik als wetenschapper software en web-apps zodat studenten, overheden en onderzoekers die niet zoveel kaas hebben gegeten van lastige wiskundige modellen, toch de state-of-the-art kunnen gebruiken of begrijpen. Ook geef ik in Utrecht leiding aan het universiteitsbrede consortium over de impact van AI in onderwijs. Je kunt me bereiken via e-mail: g.vink@uu.nl",
    "crumbs": [
      "Teaching team"
    ]
  },
  {
    "objectID": "deliverables.html",
    "href": "deliverables.html",
    "title": "Oefentoets",
    "section": "",
    "text": "Een paar voorbeeldvragen zullen worden aangeboden in de week van 23 juni. De oefentoets is bedoeld om een indicatie te krijgen van het soort vragen wat op de echte toets verwacht kan worden. De oefentoets geld niet als richtlijn voor de studieleerstof of de onderwerpen en het aantal vragen die in de echte toets aan bod zullen komen.",
    "crumbs": [
      "Oefentoets"
    ]
  },
  {
    "objectID": "genai.html",
    "href": "genai.html",
    "title": "GenAI rules",
    "section": "",
    "text": "Copyright and intellectual property",
    "crumbs": [
      "GenAI rules"
    ]
  },
  {
    "objectID": "genai.html#copyright-and-intellectual-property",
    "href": "genai.html#copyright-and-intellectual-property",
    "title": "GenAI rules",
    "section": "",
    "text": "Do you know your input rights?\n\n\n\nIn academia we hold ethics, honesty, and the values of open science in the highest regard. These principles are the backbone of our academic community and guide our education as well as our pursuit of knowledge.\nNow that AI tools become more advanced and widespread, it is crucial to uphold these values. While much focus has been on the output of AI tools, I want to bring attention to a different concern: the unjust use of what we input into these tools.\nMany of us interact with AI in what feels like the privacy of our own devices. This perceived privacy can create a false sense of security, leading some to input information that was not theirs to share or should have remained confidential. To safeguard our integrity and respect intellectual property rights, we must be cautious about what we share with AI tools. Specifically,\n\nDo not input assignments, course materials, scientific manuscripts or any other work without explicit permission from the owners.\nAvoid using AI tools to process, summarize, grade or evaluate each other’s work unless you have the author’s consent.\n\nBy following these guidelines, we protect and respect both the creative efforts and the intellectual property in our community.",
    "crumbs": [
      "GenAI rules"
    ]
  },
  {
    "objectID": "genai.html#what-about-this-course",
    "href": "genai.html#what-about-this-course",
    "title": "GenAI rules",
    "section": "What about this course?",
    "text": "What about this course?\nThe materials in this course are generated by Gerko and his team, who hold the copyright. The intellectual property belongs to Utrecht University. Images are either self-generated, directly linked, or generated with AI tools. That said, there is no information in these that exceeds legal use of copyright materials in academic settings, or that is not publicly available or should not be part of the public domain.\n\n\n\n\n\n\nWarning\n\n\n\nYou may use any and all content in this course - including staff names - and submit it as input to generative AI tools, with the following exception:\n\nYou must ensure that the content is not used for further training of the AI model",
    "crumbs": [
      "GenAI rules"
    ]
  },
  {
    "objectID": "genai.html#my-advice",
    "href": "genai.html#my-advice",
    "title": "GenAI rules",
    "section": "My advice",
    "text": "My advice\nGenerative AI can be a great assistant in the generating structured language. Most of the markup and programming skills that we will consider in this course are extremely structured and generative AI can seem of great help. Mastering a new language, however, requires practice and becoming dependent on genAI will hinder your progression in the long run, or even make you pathologically dependent on AI. Therefore we advice you to also interact with your instructors, peers and other resources around the web, as it will transform you from a leecher into a seeder. Or in educational terms: if you can explain to others what and why you are doing, you have transformed from student to master. Only if you have those metacognitive skills you have the proper foundation to start using generative AI.",
    "crumbs": [
      "GenAI rules"
    ]
  },
  {
    "objectID": "meeting1.html",
    "href": "meeting1.html",
    "title": "Introductie in R & RStudio",
    "section": "",
    "text": "Practical 1\nIn this lab you will learn to work with Quarto files and RStudio Projects.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting1.html#practical-1",
    "href": "meeting1.html#practical-1",
    "title": "Introductie in R & RStudio",
    "section": "",
    "text": "Exercise 1. Create an R Project to organise your work\nIn this course you learn to work with RStudio Projects. This way of working ensures that your R code and your analyses will continue to work and are easy to share with collaborators.\n\nCreate a folder on your computer where you will store all the materials of this course. Call it for example “Module_6”. It is better to avoid spaces in the name of your folder; you can use underscore (_) or Capitals to separate words.\nOpen RStudio. The RStudio interface will probably look like this:\n\n\n\nCreate a new RStudio Project by selecting File -&gt; New Project. A new window pops up, choose the option “New Directory”. Then create a folder “Module_6” in a directory of your choice. Click on “Create project”. See the steps to create an R Project below. When you open a new RStudio Project, a new R session starts up and creates the project structure.\n\n \nMore information about RStudio Projects\nOn the RStudio Support website you can find a webpage explaining all you need to know about RStudio Projects.\n\n\nExercise 2. Working with RStudio and Quarto\n\nOpen a new Quarto file\nTo open a new file, click on the little green plus on the upper left part of the menu bar, and select Quarto, as in the image below. In the window that pops up, leave the settings as they are. You do not have to fill in a title yet.\n\n\n\nThe structure of a Quarto file\nQuarto uses Markdown. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. A Markdown file has three components:\n\nOn top of the document, a YAML part, which defines the markup of the document. YAML stands for “Yet Another Markup Language/ Ain’t Markup Language”.\nA text part, where you can create plain text. This part of the document is white.\nThe code chunks, where you type R code (but you can also choose another programming language such as Python). Code chunks are grey coloured boxes.\n\n\n\nOpen the Markdown Quick Reference\nTo learn more about Quarto and to get help with the options, open the Markdown Quick Reference in RStudio, see menu Help -&gt; Markdown Quick Reference. This will open the reference document in the output pane in the tab “Help”. Use the Quick Reference to do the following exercise.\n\n\n\nExercise 3. Try a few options in Quarto\n\nWhen you open a new Quarto file, it contains some example code. Delete all the code from line 5 downwards.\nThe first line of the document shows the word “title”. Change the title of the document in the YAML part of the document into: title: 'Practical 1'. Please note that you have to use quotation marks.\nSave the Quarto file using File -&gt; Save. Because you created an R Project in exercise 1, the Quarto file will be saved automatically in the folder of the R Project.\nFill in your name by adding author: yourname to the YAML header between the title and format.\nAdd a Level 1 Header called “This is a level 1 header” to the document. See Markdown Quick Reference, Headers, for how to make headers.\nAdd a Level 2 sub-header with name “This is a level 2 header”.\nAdd a code chunk by selecting the green button with “c” on the top right, see screenshot below:\n\n\n\nWrite some plain text and mark some part of the text bold and some other part of the text italic. In the Markdown Quick Reference, you see that you can make text italic or bold using either * or _. Do you have an idea why there are two options for making text bold or italic?\nSave your Quarto file.\n\nAfter these steps, your Quarto file should look like this:\n\n\n\nExercise 4: Knitting your Quarto file to HTML\nCompile the Quarto file as a HTML file. Click on the Render icon. Verify how the headers look like and whether some part of the text is indeed in italic or bold.\nInstead of rendering, it is also possible to get a preview by clicking on “Visual” in the left upper corner of the editor pane. Try both options.\n\n\nExercise 5: Entering and running R commands\nThe code chunks are where you put R code in a Quarto file. So far, your “knitted” file (your output document HTML file) does not show any results from R code, because we did not use any code chunks yet.\n\nAdd a code chunk by selecting the green button with “c” on the top right, see screenshot below:\n\n\nWhen you create a new code chunk you should notice that the code area is grey and that it starts and ends with three back ticks `.\nOne common mistake is to accidentally delete these back ticks. Remember, code chunks are grey and text entry is white - if the colour of certain parts of your Markdown does not look right, check that you have not deleted the back ticks.\n\nType the following command to create a new variable called x with the value of 8, in this way: x &lt;- 8.\n\nThe arrow &lt;- is called an assignment operator, and tells R to save an object called x that has the value of 8.\nEven if &lt;- is a pain to type, don’t use = instead, it will work, but it will cause confusion later. Use RStudio’s keyboard shortcut: Alt/Option + - (the minus sign). Notice that RStudio automatically surrounds &lt;- with spaces (good code formatting practice).\nYour Quarto file should look like this now:\n Running R commands\nTo actually RUN this command, you have two options:\n\nClick on the green triangle in the code chunk. Note: this will run all the code in the code chunk.\nHighlight the code and hit Control-Enter on a PC or Command-Return on a Mac. This option allows you to run specific lines of code in a code chunk.\n\nThink of “running” code in your console as telling R: “do this”.\n\nRun the command using one of these two options. Note that you now have a new object in your workspace (top right pane), called x.\nTo look at the value of x (to get the value printed): add x in a new line of the code chunk, see below. Then run the code again. What happens?\n\n\nx &lt;- 8\nx \n\n[1] 8\n\n\n\nCompile the Quarto file again, using the Knit button and have a look at the result. It should look approximately like this:\n\n\n\nRemove the object x from the workspace by typing rm(x) in the code chunk and run this line.\n\n\n\nExercise 6: Customizing chunk options\nYou can customize the way your R code is displayed in the knitted html file. To do this for an individual code chunk, you have to add an option to the chunck header.\nSome commonly used chunk header options are:\n\nShow both R code and output. This is the default R code chunk setting.\nShow the results, not the R code. Use {r echo = FALSE} in the code chunk header.\nDo not show the R code, do not show the results. Use {r include = FALSE}\n\nQuestion\nAdd a new code chunk to your Quarto file and type the code below in your code chunk. It creates a contour plot of the Maunga Whau volcano in New Zealand. Try a few options to control the output of your code chunk, such as {r echo = FALSE} or {r include = FALSE} and see what happens when you knit the your Quarto file.\n\nimage(volcano)\n\n\n\n\n\n\n\n\nSee the R Markdown Cheat Sheet for a complete list of knitr chunk options.\n\n\nClosing RStudio Projects\nWhen you want to close your RStudio Project, there are several options:\n\nQuit RStudio using RStudio -&gt; Quit RStudio. This will close the RStudio application but keep the current RStudio Project active. This means that when you open RStudio the next time, it will automatically open with the current RStudio Project.\nClose the RStudio Project using File -&gt; Close Project. This will only close the current RStudio Project, but it will not close the RStudio application.\n\nClose the RStudio Project using the option where you close the RStudio Project, but keep the RStudio application open. A window will pop up asking you whether you want to save the workspace (this is the piece of memory where x with value 8 is located). Choose “do not save”.\nFor more information about RStudio Projects, see the RStudio Support page.\n\n\nEnd of Practical 1.\nI suggest you continue with Practical 2. If in the end you have time left, play around with R and RStudio or do the advanced exercise.\n\n\n\n\n\n\nAdvanced exercise: Inline code\n\n\n\n\nAdd a new code chunk to your document and type the following code but with your own information (name, age, country of residence, birthday). You can do this by copy the code below and paste it in the new code chunk. In the R language text values and dates need to be contained in quotation marks but numerical values do not.\n\n\nname &lt;- \"Karin\" \nage &lt;- 26\ncountry &lt;- \"The Netherlands\"\ntoday &lt;- Sys.Date()\nbirthday &lt;- as.Date(\"2024-10-11\")\n\n\nA Markdown file is convenient for combining code and text in the same document. When reporting the results of statistical analyses, you will need to refer to the statistics from your analyses. This can be done in Quarto using inline code. Let’s use the information from your code chunk to demonstrate how inline code works. Copy and paste this text exactly (do not change anything) to the white space underneath your code chunk (not in the code chunk!):\n\n\nMy name is `r name` and I am `r age` years old. It is `r birthday - today` days until my birthday.\n\n\nKnit the document using Render and look at the result. It should look like this, but then with your own name, country etc.: My name is Karin and I am 26 years old. It is -241 days until my birthday.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting1.html#practical-2",
    "href": "meeting1.html#practical-2",
    "title": "Introductie in R & RStudio",
    "section": "Practical 2",
    "text": "Practical 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting1.html#exercise-1-5",
    "href": "meeting1.html#exercise-1-5",
    "title": "Introductie in R & RStudio",
    "section": "Exercise 1-5",
    "text": "Exercise 1-5\n\n\nMake two vectors: one named vec1 with values 1 through 6 and one named vec2 with letters A through F. \n\n\nvec1 &lt;- c(1, 2, 3, 4, 5, 6)\nvec2 &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\")\n\nTo create a vector we used c(), which stands for ‘concatenation’. It is just a series of numbers or letters.\n\n\nCreate two matrices, one from vec1 and one from vec2. The dimensions for both matrices are 3 rows by 2 columns. \n\n\nmat1 &lt;- matrix(vec1, nrow = 3, ncol = 2)\nmat2 &lt;- matrix(vec2, nrow = 3, ncol = 2)\n\nTo create a matrix we used matrix(). For a matrix we need to specify the dimensions (in this case 3 rows and 2 columns) and the input (in this case vec1 or vec2) needs to match these dimensions.\n\n\nInspect your vectors and matrices. Are all numerical?\n\n\nvec1\n\n[1] 1 2 3 4 5 6\n\nvec2\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\nmat1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\nmat2\n\n     [,1] [,2]\n[1,] \"A\"  \"D\" \n[2,] \"B\"  \"E\" \n[3,] \"C\"  \"F\" \n\n\nvec1 and mat1 contain numbers and vec2 and mat2 contain characters.\n\n\nMake a matrix from both vec1 and vec2 with 6 rows and 2 columns. Inspect this matrix.\n\n\nmat3 &lt;- matrix(c(vec1, vec2), 6, 2)\nmat3\n\n     [,1] [,2]\n[1,] \"1\"  \"A\" \n[2,] \"2\"  \"B\" \n[3,] \"3\"  \"C\" \n[4,] \"4\"  \"D\" \n[5,] \"5\"  \"E\" \n[6,] \"6\"  \"F\" \n\n\nor\n\nmat3b &lt;- cbind(vec1, vec2)\nis.matrix(mat3b)\n\n[1] TRUE\n\nmat3b\n\n     vec1 vec2\n[1,] \"1\"  \"A\" \n[2,] \"2\"  \"B\" \n[3,] \"3\"  \"C\" \n[4,] \"4\"  \"D\" \n[5,] \"5\"  \"E\" \n[6,] \"6\"  \"F\" \n\n\nIf one or more elements in the matrix represent characters, all other elements are also converted to characters. A matrix is just for either numeric or character elements. Notice that the second approach (the column bind approach from mat3b) returns a matrix where the column names are already set to the name of the bound objects.\nTo solve the problem of charactered numbers we can create a dataframe. A dataframe is essentially a matrix that allows for character elements. The use of a dataframe is often preferred over the use of a matrix in R, except for purposes where pure numerical calculations are done, such as in matrix algebra. However, most datasets do contain character information and a dataframe would normally be your preferred choice when working with your own collected datasets in R.\n\n\nMake a dataframe called dat3 where vec1 and vec2 are both columns. Name the columns V1 and V2, respectively. Use function data.frame().\n\n\ndat3 &lt;- data.frame(V1 = vec1, V2 = vec2)\ndat3\n\n  V1 V2\n1  1  A\n2  2  B\n3  3  C\n4  4  D\n5  5  E\n6  6  F",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting1.html#exercise-6-10",
    "href": "meeting1.html#exercise-6-10",
    "title": "Introductie in R & RStudio",
    "section": "Exercise 6-10",
    "text": "Exercise 6-10\n\n\nAgain, make a dataframe called dat3b where vec1 and vec2 are both columns. Name the columns V1 and V2, respectively. Use function as.data.frame() on the matrix obtained from Question 4. \n\nThis is a tricky situation. At face value, everything may seem to be in order. But, be aware that the code\n\ndat3b &lt;- as.data.frame(mat3, stringsAsFactors = TRUE)\ndat3b\n\n  V1 V2\n1  1  A\n2  2  B\n3  3  C\n4  4  D\n5  5  E\n6  6  F\n\n\ndoes not work properly (at least not as intended) as the matrix nature of mat3 turned everything into a character value and you have lost the numerical nature of vec1. It may appear to be working, but if we check if column 1 is numerical, it turns out not to be the case.\n\n\nCheck if the first column in the data frames from Question 4 and Question 5 are indeed numeric. If not, determine what they are. \n\n\nis.numeric(dat3[, 1])\n\n[1] TRUE\n\nis.numeric(dat3b[, 1])\n\n[1] FALSE\n\n\nThe first column in matrix dat3b obtained from Question 5 is indeed not numeric. As a matter of fact, it is also not a character variable.\n\nis.character(dat3b[, 1])\n\n[1] FALSE\n\n\nRather tricky; the function as.data.frame() has converted the first variable to a factor.\n\nis.factor(dat3b[, 1])\n\n[1] TRUE\n\n\nThis is due to us not specifying the variable correctly in the matrix we used to create the dataframe. Factors are categorical variables that are depicted by numbers. Character vectors are not converted to factors in data frames by default, but the argument stringsAsFactors = TRUE has resulted in this conversion. I forced this to prove a point: You now know that there is a distinction between characters and factors and you know hot to force this conversion to factors in a data frame.\n\n\nSelect 1) the third row, 2) the second column and 3) the intersection of these two in the dataframe dat3 that you have created in Question 4. \n\n\ndat3[3, ] #3rd row\n\n  V1 V2\n3  3  C\n\ndat3[, 2] #2nd column\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\ndat3$V2   #also 2nd column\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\ndat3[3,2] #intersection\n\n[1] \"C\"\n\n\nThe [3,2] index is very useful in ‘R’. The first number (before the comma) represents the row and the second number (after the comma) represents the column. For a vector there are no two dimensions and only one dimension can be called. For example, vec1[3] would yield 3. Try it.\nColumns can also be called by the $ sign, but only if a name has been assigned. With dataframes assigning names happens automatically.\nNote that R automatically reports the values the character column can take. This means that the column is indeed a factor (a categorical variable - as it is supposed to be). A useful function to inspect the structure of a dataframe is str(). Try running it.\n\nstr(dat3)\n\n'data.frame':   6 obs. of  2 variables:\n $ V1: num  1 2 3 4 5 6\n $ V2: chr  \"A\" \"B\" \"C\" \"D\" ...\n\n\nInspecting the structure of your data is vital, as you probably have imported your data from some other source. If we, at a later stage, start analyzing our data without the correct measurement level, we may run into problems. One problem that often occurs is that categorical variables (factors in R) are not coded as such.\n\n\nImagine that the first variable V1 in our dataframe dat3 is not coded correctly, but actually represents grouping information about cities. Convert the variable to a factor and add the labels Utrecht, New York, London, Singapore, Rome and Cape Town.\n\n\ndat3$V1 &lt;- factor(dat3$V1, labels = c(\"Utrecht\", \"New York\", \"London\", \"Singapore\", \"Rome\", \"Capetown\"))\ndat3\n\n         V1 V2\n1   Utrecht  A\n2  New York  B\n3    London  C\n4 Singapore  D\n5      Rome  E\n6  Capetown  F\n\n\n\n\nOpen the workspace boys.RData.\n\nWe have not yet learned to import data into R. Usually, we would store the data in our project and then import it from that location. For now, we load a dataset in from the internet by running and loading the connection\n\ncon &lt;- url(\"https://www.gerkovink.com/fundamentals/data/boys.RData\")\nload(con)\n\nIn the above code we store the connection as a url character string in object con and then load the connection with load(con).\nThe boys object will be added to your Global Environment. You can now use the boys data by running\n\nboys",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting1.html#exercise-11-15",
    "href": "meeting1.html#exercise-11-15",
    "title": "Introductie in R & RStudio",
    "section": "Exercise 11-15",
    "text": "Exercise 11-15\n\n\nMost packages have datasets included. Since we have not learned to load packages yet, you are presented with such a data set in a workspace. Open the boys dataset (it is from package mice, by the way) by typing boys in the console, and subsequently by using the function View(). \n\nThe output is not displayed here as it is simply too large.\nUsing View() is preferred for inspecting datasets that are large. View() opens the dataset in a spreadsheet-like window (conform MS Excel, or SPSS). If you View() your own datasets, you can not edit the datasets’ contents.\n\n\nFind out the dimensions of the boys data set and inspect the first and final 6 cases in the data set. \n\nTo do it numerically, find out what the dimensions of the boys dataset are.\n\ndim(boys)\n\n[1] 748   9\n\n\nThere are 748 cases on 9 variables. To select the first and last six cases, use\n\nboys[1:6, ]\n\n     age  hgt   wgt   bmi   hc  gen  phb tv   reg\n3  0.035 50.1 3.650 14.54 33.7 &lt;NA&gt; &lt;NA&gt; NA south\n4  0.038 53.5 3.370 11.77 35.0 &lt;NA&gt; &lt;NA&gt; NA south\n18 0.057 50.0 3.140 12.56 35.2 &lt;NA&gt; &lt;NA&gt; NA south\n23 0.060 54.5 4.270 14.37 36.7 &lt;NA&gt; &lt;NA&gt; NA south\n28 0.062 57.5 5.030 15.21 37.3 &lt;NA&gt; &lt;NA&gt; NA south\n36 0.068 55.5 4.655 15.11 37.0 &lt;NA&gt; &lt;NA&gt; NA south\n\nboys[743:748, ]\n\n        age   hgt  wgt   bmi   hc  gen  phb tv   reg\n7410 20.372 188.7 59.8 16.79 55.2 &lt;NA&gt; &lt;NA&gt; NA  west\n7418 20.429 181.1 67.2 20.48 56.6 &lt;NA&gt; &lt;NA&gt; NA north\n7444 20.761 189.1 88.0 24.60   NA &lt;NA&gt; &lt;NA&gt; NA  west\n7447 20.780 193.5 75.4 20.13   NA &lt;NA&gt; &lt;NA&gt; NA  west\n7451 20.813 189.0 78.0 21.83 59.9 &lt;NA&gt; &lt;NA&gt; NA north\n7475 21.177 181.8 76.5 23.14   NA &lt;NA&gt; &lt;NA&gt; NA  east\n\n\nor, more efficiently:\n\nhead(boys)\n\n     age  hgt   wgt   bmi   hc  gen  phb tv   reg\n3  0.035 50.1 3.650 14.54 33.7 &lt;NA&gt; &lt;NA&gt; NA south\n4  0.038 53.5 3.370 11.77 35.0 &lt;NA&gt; &lt;NA&gt; NA south\n18 0.057 50.0 3.140 12.56 35.2 &lt;NA&gt; &lt;NA&gt; NA south\n23 0.060 54.5 4.270 14.37 36.7 &lt;NA&gt; &lt;NA&gt; NA south\n28 0.062 57.5 5.030 15.21 37.3 &lt;NA&gt; &lt;NA&gt; NA south\n36 0.068 55.5 4.655 15.11 37.0 &lt;NA&gt; &lt;NA&gt; NA south\n\ntail(boys)\n\n        age   hgt  wgt   bmi   hc  gen  phb tv   reg\n7410 20.372 188.7 59.8 16.79 55.2 &lt;NA&gt; &lt;NA&gt; NA  west\n7418 20.429 181.1 67.2 20.48 56.6 &lt;NA&gt; &lt;NA&gt; NA north\n7444 20.761 189.1 88.0 24.60   NA &lt;NA&gt; &lt;NA&gt; NA  west\n7447 20.780 193.5 75.4 20.13   NA &lt;NA&gt; &lt;NA&gt; NA  west\n7451 20.813 189.0 78.0 21.83 59.9 &lt;NA&gt; &lt;NA&gt; NA north\n7475 21.177 181.8 76.5 23.14   NA &lt;NA&gt; &lt;NA&gt; NA  east\n\n\nThe functions head() and tail() are very useful functions. For example, from looking at both functions we can observe that the data are very likely sorted based on age.\n\n\nIt seems that the boys data are sorted based on age. Verify this.\n\nTo verify if the data are indeed sorted, we can run the following command to test the complement of that statement. Remember that we can always search the help for functions: e.g. we could have searched here for ?sort and we would quickly have ended up at function is.unsorted() as it tests whether an object is not sorted.\n\nis.unsorted(boys$age)\n\n[1] FALSE\n\n\nwhich returns FALSE, indicating that boys’ age is indeed sorted (we asked if it was unsorted!). To directly test if it is sorted, we could have used\n\n!is.unsorted(boys$age)\n\n[1] TRUE\n\n\nwhich tests if data data are not unsorted. In other words the values TRUE and FALSE under is.unsorted() turn into FALSE and TRUE under !is.unsorted(), respectively.\n\n\nInspect the boys dataset with str(). Use one or more functions to find distributional summary information (at least information about the minimum, the maximum, the mean and the median) for all of the variables. Give the standard deviation for age and bmi.  Tip: make use of the help (?) and help search (??) functionality in R.\n\n\nstr(boys)\n\n'data.frame':   748 obs. of  9 variables:\n $ age: num  0.035 0.038 0.057 0.06 0.062 0.068 0.068 0.071 0.071 0.073 ...\n $ hgt: num  50.1 53.5 50 54.5 57.5 55.5 52.5 53 55.1 54.5 ...\n $ wgt: num  3.65 3.37 3.14 4.27 5.03 ...\n $ bmi: num  14.5 11.8 12.6 14.4 15.2 ...\n $ hc : num  33.7 35 35.2 36.7 37.3 37 34.9 35.8 36.8 38 ...\n $ gen: Ord.factor w/ 5 levels \"G1\"&lt;\"G2\"&lt;\"G3\"&lt;..: NA NA NA NA NA NA NA NA NA NA ...\n $ phb: Ord.factor w/ 6 levels \"P1\"&lt;\"P2\"&lt;\"P3\"&lt;..: NA NA NA NA NA NA NA NA NA NA ...\n $ tv : int  NA NA NA NA NA NA NA NA NA NA ...\n $ reg: Factor w/ 5 levels \"north\",\"east\",..: 4 4 4 4 4 4 4 3 3 2 ...\n\nsummary(boys) #summary info\n\n      age              hgt              wgt              bmi       \n Min.   : 0.035   Min.   : 50.00   Min.   :  3.14   Min.   :11.77  \n 1st Qu.: 1.581   1st Qu.: 84.88   1st Qu.: 11.70   1st Qu.:15.90  \n Median :10.505   Median :147.30   Median : 34.65   Median :17.45  \n Mean   : 9.159   Mean   :132.15   Mean   : 37.15   Mean   :18.07  \n 3rd Qu.:15.267   3rd Qu.:175.22   3rd Qu.: 59.58   3rd Qu.:19.53  \n Max.   :21.177   Max.   :198.00   Max.   :117.40   Max.   :31.74  \n                  NA's   :20       NA's   :4        NA's   :21     \n       hc          gen        phb            tv           reg     \n Min.   :33.70   G1  : 56   P1  : 63   Min.   : 1.00   north: 81  \n 1st Qu.:48.12   G2  : 50   P2  : 40   1st Qu.: 4.00   east :161  \n Median :53.00   G3  : 22   P3  : 19   Median :12.00   west :239  \n Mean   :51.51   G4  : 42   P4  : 32   Mean   :11.89   south:191  \n 3rd Qu.:56.00   G5  : 75   P5  : 50   3rd Qu.:20.00   city : 73  \n Max.   :65.00   NA's:503   P6  : 41   Max.   :25.00   NA's :  3  \n NA's   :46                 NA's:503   NA's   :522                \n\nsd(boys$age) #standard deviation for age\n\n[1] 6.894052\n\nsd(boys$bmi, na.rm = TRUE) #standard deviation for bmi\n\n[1] 3.053421\n\n\nNote that bmi contains 21 missing values, e.g. by looking at the summary information. Therefor we need to use na.rm = TRUE to calculate the standard deviation on the observed cases only.\n\n\nSelect all boys that are 20 years or older. How many are there?\n\nThe logical operators (TRUE vs FALSE) are a very powerful tool in R. For example, we can just select the rows (respondents) in the data that are older than 20 by putting the logical operater within the row index of the dataset:\n\nboys2 &lt;- boys[boys$age &gt;= 20, ]\nnrow(boys2)\n\n[1] 12\n\n\nor, alternatively,\n\nboys2.1 &lt;- subset(boys, age &gt;= 20)\nnrow(boys2.1)\n\n[1] 12",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting1.html#exercise-16-17",
    "href": "meeting1.html#exercise-16-17",
    "title": "Introductie in R & RStudio",
    "section": "Exercise 16-17",
    "text": "Exercise 16-17\n\n\nSelect all boys that are older than 19, but younger than 19.5. How many are there?\n\n\nboys3 &lt;- boys[boys$age &gt; 19 & boys$age &lt; 19.5, ]\nnrow(boys3)\n\n[1] 18\n\n\nor, alternatively,\n\nboys3.2 &lt;- subset(boys, age &gt; 19 & age &lt; 19.5)\nnrow(boys3.2)\n\n[1] 18\n\n\n\n\nWhat is the mean age of boys younger than 15 years of age that do not live in region north?\n\n\nmean(boys$age[boys$age &lt; 15 & boys$reg != \"north\" ], na.rm = TRUE)\n\n[1] 6.044461\n\n\nor, alternatively,\n\nmean(subset(boys, age &lt; 15 & reg != \"north\")$age, na.rm=TRUE)\n\n[1] 6.044461\n\n\nThe mean age is 6.0444609 years\n\nToday we have learned to use R at its basics. This offers tremendous flexibility, but may also be inefficient when our aim is some complex analysis, data operation of data manipulation. Doing advanced operations in basic R may require lots and lots of code. Tomorrow we will start using packages that allow us to do complicated operations with just a few lines of code.\nAs you start using R in your own research, you will find yourself in need of packages that are not part of the default R installation. The beauty of R is that its functionality is community-driven. People can add packages to CRAN that other people can use and improve. Chances are that a function and/or package has been already developed for the analysis or operation you plan to carry out. If not, you are of course welcome to fill the gap by submitting your own package.\n\nEnd of practical",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introductie in R & RStudio</span>"
    ]
  },
  {
    "objectID": "meeting2.html",
    "href": "meeting2.html",
    "title": "Data Management",
    "section": "",
    "text": "Practical 1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Management</span>"
    ]
  },
  {
    "objectID": "meeting2.html#practical-1",
    "href": "meeting2.html#practical-1",
    "title": "Data Management",
    "section": "",
    "text": "Exercise 1-5\n\n\nMake two vectors: one named vec1 with values 1 through 6 and one named vec2 with letters A through F. \n\n\nvec1 &lt;- c(1, 2, 3, 4, 5, 6)\nvec2 &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\")\n\nTo create a vector we used c(), which stands for ‘concatenation’. It is just a series of numbers or letters.\n\n\nCreate two matrices, one from vec1 and one from vec2. The dimensions for both matrices are 3 rows by 2 columns. \n\n\nmat1 &lt;- matrix(vec1, nrow = 3, ncol = 2)\nmat2 &lt;- matrix(vec2, nrow = 3, ncol = 2)\n\nTo create a matrix we used matrix(). For a matrix we need to specify the dimensions (in this case 3 rows and 2 columns) and the input (in this case vec1 or vec2) needs to match these dimensions.\n\n\nInspect your vectors and matrices. Are all numerical?\n\n\nvec1\n\n[1] 1 2 3 4 5 6\n\nvec2\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\nmat1\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\nmat2\n\n     [,1] [,2]\n[1,] \"A\"  \"D\" \n[2,] \"B\"  \"E\" \n[3,] \"C\"  \"F\" \n\n\nvec1 and mat1 contain numbers and vec2 and mat2 contain characters.\n\n\nMake a matrix from both vec1 and vec2 with 6 rows and 2 columns. Inspect this matrix.\n\n\nmat3 &lt;- matrix(c(vec1, vec2), 6, 2) # specify rows and column dimensions\nmat3\n\n     [,1] [,2]\n[1,] \"1\"  \"A\" \n[2,] \"2\"  \"B\" \n[3,] \"3\"  \"C\" \n[4,] \"4\"  \"D\" \n[5,] \"5\"  \"E\" \n[6,] \"6\"  \"F\" \n\n\nor\n\nmat3b &lt;- cbind(vec1, vec2) # no dimension specification necessary\nis.matrix(mat3b)\n\n[1] TRUE\n\nmat3b\n\n     vec1 vec2\n[1,] \"1\"  \"A\" \n[2,] \"2\"  \"B\" \n[3,] \"3\"  \"C\" \n[4,] \"4\"  \"D\" \n[5,] \"5\"  \"E\" \n[6,] \"6\"  \"F\" \n\n\nIf one or more elements in the matrix represent characters, all other elements are also converted to characters. A matrix is just for either numeric or character elements. Notice that the second approach (the column bind approach from mat3b) returns a matrix where the column names are already set to the name of the bound objects.\nTo solve the problem of charactered numbers we can create a dataframe. A dataframe is essentially a matrix that allows for character elements. The use of a dataframe is often preferred over the use of a matrix in R, except for purposes where pure numerical calculations are done, such as in matrix algebra. However, most datasets do contain character information and a dataframe would normally be your preferred choice when working with your own collected datasets in R.\n\n\nMake a dataframe called dat3 where vec1 and vec2 are both columns. Name the columns V1 and V2, respectively. Use function data.frame().\n\n\ndat3 &lt;- data.frame(V1 = vec1, V2 = vec2)\ndat3\n\n  V1 V2\n1  1  A\n2  2  B\n3  3  C\n4  4  D\n5  5  E\n6  6  F\n\n\n\n\n\nExercise 6-10\n\n\nAgain, make a dataframe called dat3b where vec1 and vec2 are both columns. Name the columns V1 and V2, respectively. Use function as.data.frame() on the matrix obtained from Question 4. \n\nThis is a tricky situation. At face value, everything may seem to be in order. But, be aware that the code\n\ndat3b &lt;- as.data.frame(mat3, stringsAsFactors = TRUE)\ndat3b\n\n  V1 V2\n1  1  A\n2  2  B\n3  3  C\n4  4  D\n5  5  E\n6  6  F\n\n\ndoes not work properly (at least not as intended) as the matrix nature of mat3 turned everything into a character value and you have lost the numerical nature of vec1. It may appear to be working, but if we check if column 1 is numerical, it turns out not to be the case.\n\n\nCheck if the first column in the data frames from Question 4 and Question 5 are indeed numeric. If not, determine what they are. \n\n\nis.numeric(dat3[, 1])\n\n[1] TRUE\n\nis.numeric(dat3b[, 1])\n\n[1] FALSE\n\n\nThe first column in matrix dat3b obtained from Question 5 is indeed not numeric. As a matter of fact, it is also not a character variable.\n\nis.character(dat3b[, 1])\n\n[1] FALSE\n\n\nRather tricky; the function as.data.frame() has converted the first variable to a factor.\n\nis.factor(dat3b[, 1])\n\n[1] TRUE\n\n\nThis is due to us not specifying the variable correctly in the matrix we used to create the dataframe. Factors are categorical variables that are depicted by numbers. Character vectors are not converted to factors in data frames by default, but the argument stringsAsFactors = TRUE has resulted in this conversion. I forced this to prove a point: You now know that there is a distinction between characters and factors and you know hot to force this conversion to factors in a data frame.\n\n\nSelect 1) the third row, 2) the second column and 3) the intersection of these two in the dataframe dat3 that you have created in Question 4. \n\n\ndat3[3, ] #3rd row\n\n  V1 V2\n3  3  C\n\ndat3[, 2] #2nd column\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\ndat3$V2   #also 2nd column\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\ndat3[3,2] #intersection\n\n[1] \"C\"\n\n\nThe [3,2] index is very useful in ‘R’. The first number (before the comma) represents the row and the second number (after the comma) represents the column. For a vector there are no two dimensions and only one dimension can be called. For example, vec1[3] would yield 3. Try it.\nColumns can also be called by the $ sign, but only if a name has been assigned. With dataframes assigning names happens automatically.\nNote that R automatically reports the values the character column can take. This means that the column is indeed a factor (a categorical variable - as it is supposed to be). A useful function to inspect the structure of a dataframe is str(). Try running it.\n\nstr(dat3)\n\n'data.frame':   6 obs. of  2 variables:\n $ V1: num  1 2 3 4 5 6\n $ V2: chr  \"A\" \"B\" \"C\" \"D\" ...\n\n\nInspecting the structure of your data is vital, as you probably have imported your data from some other source. If we, at a later stage, start analyzing our data without the correct measurement level, we may run into problems. One problem that often occurs is that categorical variables (factors in R) are not coded as such.\n\n\nImagine that the first variable V1 in our dataframe dat3 is not coded correctly, but actually represents grouping information about cities. Convert the variable to a factor and add the labels Utrecht, New York, London, Singapore, Rome and Cape Town.\n\n\ndat3$V1 &lt;- factor(dat3$V1, labels = c(\"Utrecht\", \"New York\", \"London\", \"Singapore\", \"Rome\", \"Capetown\"))\ndat3\n\n         V1 V2\n1   Utrecht  A\n2  New York  B\n3    London  C\n4 Singapore  D\n5      Rome  E\n6  Capetown  F",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Management</span>"
    ]
  },
  {
    "objectID": "meeting2.html#practical-2-pipes",
    "href": "meeting2.html#practical-2-pipes",
    "title": "Data Management",
    "section": "Practical 2: Pipes",
    "text": "Practical 2: Pipes\nWe need the following packages for this part:\n\nlibrary(dplyr)    # for data manipulation\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(magrittr) # for flexible pipes\nlibrary(haven)    # for importing SPSS and Stata data\nlibrary(mice)     # for the boys data\n\n\nAttaching package: 'mice'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n\n\n\n\nRead in the SPSS and Stata data sets that are provided on Moodle. Place them in the Project folder of this practical. Use the functions read_sav() and read_dta() from package haven. \n\n\nlibrary(haven) # for importing SPSS and Stata data\n# Import the SPSS data set\nspss_data &lt;- read_sav(\"SUR_2023_LAPOP_AmericasBarometer_v1.0_w_orginal.sav\")\n# Import the Stata data set\nstata_data &lt;- read_dta(\"03-poverty-analysis-data-2022-rt001-housing-plus.dta\")\n\n\n\nUse a pipe to do the following:\n\n\ndraw 1000 values from a normal distribution with mean = 5 and sd = 1 - \\(N(5, 1)\\),\ncreate a matrix where the first 500 values are the first column and the second 500 values are the second column\nmake a scatterplot of these two columns\n\nIf you’d like the same results as I have obtained, you can fix the random seed\n\nset.seed(123)\n\n\nrnorm(1000, 5) %&gt;%\n  matrix(ncol = 2) %&gt;%\n  plot()\n\n\n\n\n\n\n\n\n\n\nOn the 03-poverty-analysis-data-2022-rt001-housing-plus.dta: Use a pipe to calculate the correlation matrix on the continuous variables only. Round the result to two decimal places.\n\n\ncor_stata &lt;- stata_data %&gt;% \n  as_factor() %&gt;% # first make sure that factors are factors\n  select(where(is.numeric)) %&gt;% # select only numeric variables\n  cor(use = \"pairwise.complete.obs\") # use all info from complete pairs\n\nWarning in cor(., use = \"pairwise.complete.obs\"): the standard deviation is\nzero\n\n\n\nWhat is the maximum correlation in the correlation matrix? Exclude the value 1 in your calculations. # which is the maximum correlation in the correlation matrix? # first, set the diagonal to zero -&gt; these values are all 1 diag(cor_stata) &lt;- 0 cor_stata[cor_stata == 1 | cor_stata == -1] &lt;- NA # set 1 and -1 to NA, as these are not interesting # calculate the maximum correlation max_cor_value &lt;- max(cor_stata, na.rm = TRUE) # there are NAs in cor_stata which_max &lt;- which(cor_stata == max_cor_value, arr.ind = TRUE) # get the indices of rows and columns which_max\n\n\nWe can see that the pairs `fortnight, hhid` and `CPI_2017_22, CPI_june2022` have the highest correlation of 0.9996074. \n\n::: {.cell}\n\n```{.r .cell-code}\nstata_data %&gt;% \n  select(fortnight, hhid) %&gt;% \n  cor(use = \"pairwise.complete.obs\")\n\n          fortnight      hhid\nfortnight 1.0000000 0.9996074\nhhid      0.9996074 1.0000000\n\n:::\n\n\n\n\n\n\nSneak peek for tomorrow\n\n\n\nWe can also select only variables that belong to a specific set of items, such as q13 in the STATA data set. This is done by selecting only variables that start with q13 using the starts_with() verb:\n\ncor_stata &lt;- stata_data %&gt;% \n  as_factor() %&gt;% # first make sure that factors are factors\n  select(where(is.numeric)) %&gt;% # select only numeric variables\n  select(starts_with(\"q13\")) %&gt;% # select only variables that start with q13\n  cor(use = \"pairwise.complete.obs\") # use all info from complete pairs\n\ndiag(cor_stata) &lt;- 0\n# calculate the maximum correlation\nmax_cor_value &lt;- max(cor_stata, na.rm = TRUE) # there are NAs in cor_stata\nwhich_max &lt;- which(cor_stata == max_cor_value, \n                   arr.ind = TRUE) # get the indices of rows and columns\nwhich_max\n\n       row col\nq13_19   4   3\nq13_18   3   4\n\n\n\n\n\n\nNow use a pipe to calculate the correlation for the pair (x4, y4) on the anscombe data set\n\nUsing the standard %&gt;% pipe:\n\nanscombe %&gt;%\n  subset(select = c(x4, y4)) %&gt;%\n  cor()\n\n          x4        y4\nx4 1.0000000 0.8165214\ny4 0.8165214 1.0000000\n\n\nAlternatively, we can use the %$% pipe from package magrittr to make this process much more efficient.\n\nanscombe %$%\n  cor(x4, y4)\n\n[1] 0.8165214\n\n\n\n\nHave a look at the boys data set from package mice (don’t forget to library(mice)). Use a pipe to calculate the correlation between hgt and wgt in the boys data set from package mice.\n\nBecause boys has missing values for almost all variables, we must first select wgt and hgt and then omit the rows that have missing values, before we can calculate the correlation. Using the standard %&gt;% pipe, this would look like:\n\nmice::boys %&gt;% # mice::boys tells us that boys comes from package mice\n  select(wgt, hgt) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\n          wgt       hgt\nwgt 1.0000000 0.9428906\nhgt 0.9428906 1.0000000\n\n\nwhich - because there are only two variables - is equivalent to\n\nboys %&gt;%\n  select(wgt, hgt) %&gt;%\n  na.omit() %&gt;%\n  cor()\n\n          wgt       hgt\nwgt 1.0000000 0.9428906\nhgt 0.9428906 1.0000000\n\n\nAlternatively, we can use the %$% pipe:\n\nboys %$% \n  cor(hgt, wgt, use = \"pairwise.complete.obs\")\n\n[1] 0.9428906\n\n\nThe %$% pipe unfolds the listed dimensions of the boys data set, such that we can refer to them directly.\n\n\nIn the boys data set, hgt is recorded in centimeters. Use a pipe to transform hgt in the boys dataset to height in meters and verify the transformation by calculating the mean of hgt\n\nUsing the standard %&gt;% and the %$% pipes:\n\nboys %&gt;%\n  mutate(hgt = hgt / 100) %$% # transform centimeters to meters\n  mean(hgt, na.rm = TRUE) # verify that indeed it is now in meters\n\n[1] 1.321518\n\n\n\n\nUse a pipe to filter all rows in the boys data set where hgt is larger than 1.5 meters and wgt is larger than 50 kg. How many rows are there in the subset? And how many rows did you exclude?\n\nLet’s first make a subset of the boys data without the excluded rows\n\nboys_subset &lt;- \n  boys %&gt;%\n  filter(hgt &gt; 1.5, wgt &gt; 50) # filter rows where hgt &gt; 1.5 and wgt &gt; 50\n\nThe subset has 263 rows:\n\nboys_subset %&gt;% \n  nrow()\n\n[1] 263\n\n\nThe original boys data had 748 rows. this means that 748 - 263 =485 rows have been excluded.\n\nboys %&gt;% \n  nrow()\n\n[1] 748\n\n\n\n\nUseful References for Practical 2\n\nmagrittr\nR for Data Science - Chapter 18 on pipes",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Management</span>"
    ]
  },
  {
    "objectID": "meeting2.html#extra-practical-data-management",
    "href": "meeting2.html#extra-practical-data-management",
    "title": "Data Management",
    "section": "Extra Practical: Data Management",
    "text": "Extra Practical: Data Management\nBegin this practical exercise by setting the maximum line length in R-Studio to 80 characters. Go to RStudio’s Preferences (or Global Options under Tools) –&gt; Code –&gt; Display, and tick the show margin box. Make sure that the margin column is set to 80\nThe following packages are required for this practical:\n\nlibrary(dplyr)    # for data manipulation\nlibrary(magrittr) # for flexible pipes\nlibrary(mice)     # for the mammalsleep and boys datasets\nlibrary(haven)    # for importing SPSS and Stata data\n\n\n\nExercise 1-5\n\n\nInstall package mice. \n\nGo to Tools &gt; Install Packages in RStudio. If you are connected to the internet, select Repository under Install From and type mice under Packages. Leave the Install to Library at default and make sure that Install Dependencies is selected. Click install. If you are not connected to the internet, select Package Archive File under “Install from” and navigate to the respective file on your drive.\nSome packages depend on other packages, meaning that their functionality may be limited if their dependencies are not installed. Installing dependencies is therefor recommended, but internet connectivity is required.\nIf all is right, you will receive a message in the console that the package has been installed (as well as its dependencies).\nALternatively, if you know the name of the package you would like to install - in this case mice - you can also call install.packages(\"mice\") in the console window.\n\n\nLoad package mice.  Loading packages can be done through functions library() and require().\n\n\nlibrary(mice)\n\nIf you use require() within a function, and the required package is not available, require() will yield a warning and the remainder of the function is still executed, whereas library() will yield an error and terminate all executions. The use of library() when not doing too complicated things is preferred - require() would result in more computational overhead because it calls library() itself.\n\n\nMost packages have datasets included. Open the mammalsleep dataset from package mice by typing mammalsleep in the console, and subsequently by using the function View(). \n\nUsing View() is preferred for inspecting datasets that are large. View() opens the dataset in a spreadsheet-like window (conform MS Excel, or SPSS). If you View() your own datasets, you can even edit the datasets’ contents.\n\n\nWrite the mammalsleep dataset from package mice to the work directory (= the directory of your R project) as a tab-delimited text file with . as a decimal separator. Use the function write.table() and name the file mammalsleep.txt.\n\n\nwrite.table(x = mammalsleep, # the data to be exported\n            file = \"mammalsleep.txt\", # the name of the file\n            sep = \"\\t\", # column seperated by tabs\n            dec = \".\", # decimal separator\n            row.names = FALSE) # do not include the rownames as column\n\nThe command sep = \"\\t\" indicates that the file is tabulated and the command dec = \".\" indicates that a point is used as the decimal separator (instead of a comma). row.names = FALSE tells R that row names are not to be included in the exported file.\n\n\nImport the mammalsleep.txt file with read.table(). \n\n\nsleepdata &lt;- read.table(\"mammalsleep.txt\", # the name of the file\n                        sep = \"\\t\", # columns seperated by tabs\n                        dec = \".\", # decimal separator\n                        header = TRUE, # 1st row contains variable names\n                        stringsAsFactors = TRUE) # convert strings to factors\nsleepdata %&lt;&gt;% # assign pipe to feed the result back into sleepdata\n  as_tibble() # convert to tibble\n\nThe command sep = \"\\t\" indicates that the file is tabulated and the command dec = \".\" indicates that a point is used as the decimal separator (instead of a comma). header = TRUE tells R that variable names are included in the header.\nAll files that are presented in the work directory of the current R project, can essentially be imported into the workspace (the space that contains all environments) directly. All other locations require you to specify the specific path from the root of your machine. To find out what the current work directory is, you can type getwd() and to change the work directory you can use setwd(). The beauty of using projects in RStudio is that you would never have to change the work directory, as the work directory is automatically set, relative to your projects’ R-scripts.\nThere are many packages that facilitate importing data sets from other statistical software packages, such as SPSS (e.g. function read_spss() from package haven), Mplus (package MplusAutomation), Stata (read_dta() in haven and read.dta() in foreign), SAS (sasxport.get() from package Hmisc) and from spreadsheet software, such as MS Excel (function read.xlsx() from package xlsx).\n\n\n\nExercise 6-10\n\n\nThe dataset we’ve just imported contains the sleepdata by Allison & Cicchetti (1976). Inspect the sleepdata and make yourself familiar with it. \n\nIf you would like to know more about this dataset, you can open the help for the mammalsleep dataset in package mice through ?mammalsleep.\nInspecting the sleepdata could be done by\n\n# the data structure\nsummary(sleepdata) #distributional summaries\n\n                      species         bw                brw         \n African elephant         : 1   Min.   :   0.005   Min.   :   0.14  \n African giant pouched rat: 1   1st Qu.:   0.600   1st Qu.:   4.25  \n Arctic Fox               : 1   Median :   3.342   Median :  17.25  \n Arctic ground squirrel   : 1   Mean   : 198.790   Mean   : 283.13  \n Asian elephant           : 1   3rd Qu.:  48.203   3rd Qu.: 166.00  \n Baboon                   : 1   Max.   :6654.000   Max.   :5712.00  \n (Other)                  :56                                       \n      sws               ps              ts             mls         \n Min.   : 2.100   Min.   :0.000   Min.   : 2.60   Min.   :  2.000  \n 1st Qu.: 6.250   1st Qu.:0.900   1st Qu.: 8.05   1st Qu.:  6.625  \n Median : 8.350   Median :1.800   Median :10.45   Median : 15.100  \n Mean   : 8.673   Mean   :1.972   Mean   :10.53   Mean   : 19.878  \n 3rd Qu.:11.000   3rd Qu.:2.550   3rd Qu.:13.20   3rd Qu.: 27.750  \n Max.   :17.900   Max.   :6.600   Max.   :19.90   Max.   :100.000  \n NA's   :14       NA's   :12      NA's   :4       NA's   :4        \n       gt               pi             sei             odi       \n Min.   : 12.00   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.: 35.75   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  \n Median : 79.00   Median :3.000   Median :2.000   Median :2.000  \n Mean   :142.35   Mean   :2.871   Mean   :2.419   Mean   :2.613  \n 3rd Qu.:207.50   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :645.00   Max.   :5.000   Max.   :5.000   Max.   :5.000  \n NA's   :4                                                       \n\nsleepdata %&gt;% \n  select(-species) %&gt;% # exclude the first column (because it is character)\n  cor(use = \"pairwise.complete.obs\") %&gt;% # calculate Pearson's correlation\n  round(2) # round to two decimal places \n\n       bw   brw   sws    ps    ts   mls    gt    pi   sei   odi\nbw   1.00  0.93 -0.38 -0.11 -0.31  0.30  0.65  0.06  0.34  0.13\nbrw  0.93  1.00 -0.37 -0.11 -0.36  0.51  0.75  0.03  0.37  0.15\nsws -0.38 -0.37  1.00  0.51  0.96 -0.38 -0.59 -0.32 -0.54 -0.48\nps  -0.11 -0.11  0.51  1.00  0.73 -0.30 -0.45 -0.45 -0.54 -0.58\nts  -0.31 -0.36  0.96  0.73  1.00 -0.41 -0.63 -0.40 -0.64 -0.59\nmls  0.30  0.51 -0.38 -0.30 -0.41  1.00  0.61 -0.10  0.36  0.06\ngt   0.65  0.75 -0.59 -0.45 -0.63  0.61  1.00  0.20  0.64  0.38\npi   0.06  0.03 -0.32 -0.45 -0.40 -0.10  0.20  1.00  0.62  0.92\nsei  0.34  0.37 -0.54 -0.54 -0.64  0.36  0.64  0.62  1.00  0.79\nodi  0.13  0.15 -0.48 -0.58 -0.59  0.06  0.38  0.92  0.79  1.00\n\nhead(mammalsleep) # first six rows\n\n                    species       bw    brw sws  ps   ts  mls  gt pi sei odi\n1          African elephant 6654.000 5712.0  NA  NA  3.3 38.6 645  3   5   3\n2 African giant pouched rat    1.000    6.6 6.3 2.0  8.3  4.5  42  3   1   3\n3                Arctic Fox    3.385   44.5  NA  NA 12.5 14.0  60  1   1   1\n4    Arctic ground squirrel    0.920    5.7  NA  NA 16.5   NA  25  5   2   3\n5            Asian elephant 2547.000 4603.0 2.1 1.8  3.9 69.0 624  3   5   4\n6                    Baboon   10.550  179.5 9.1 0.7  9.8 27.0 180  4   4   4\n\ntail(mammalsleep) # last six rows\n\n                 species    bw  brw  sws  ps   ts  mls  gt pi sei odi\n57                Tenrec 0.900  2.6 11.0 2.3 13.3  4.5  60  2   1   2\n58            Tree hyrax 2.000 12.3  4.9 0.5  5.4  7.5 200  3   1   3\n59            Tree shrew 0.104  2.5 13.2 2.6 15.8  2.3  46  3   2   2\n60                Vervet 4.190 58.0  9.7 0.6 10.3 24.0 210  4   3   4\n61         Water opossum 3.500  3.9 12.8 6.6 19.4  3.0  14  2   1   1\n62 Yellow-bellied marmot 4.050 17.0   NA  NA   NA 13.0  38  3   1   1\n\nglimpse(mammalsleep) # a quick overview of the data structure\n\nRows: 62\nColumns: 11\n$ species &lt;fct&gt; African elephant, African giant pouched rat, Arctic Fox, Arcti…\n$ bw      &lt;dbl&gt; 6654.000, 1.000, 3.385, 0.920, 2547.000, 10.550, 0.023, 160.00…\n$ brw     &lt;dbl&gt; 5712.0, 6.6, 44.5, 5.7, 4603.0, 179.5, 0.3, 169.0, 25.6, 440.0…\n$ sws     &lt;dbl&gt; NA, 6.3, NA, NA, 2.1, 9.1, 15.8, 5.2, 10.9, 8.3, 11.0, 3.2, 7.…\n$ ps      &lt;dbl&gt; NA, 2.0, NA, NA, 1.8, 0.7, 3.9, 1.0, 3.6, 1.4, 1.5, 0.7, 2.7, …\n$ ts      &lt;dbl&gt; 3.3, 8.3, 12.5, 16.5, 3.9, 9.8, 19.7, 6.2, 14.5, 9.7, 12.5, 3.…\n$ mls     &lt;dbl&gt; 38.6, 4.5, 14.0, NA, 69.0, 27.0, 19.0, 30.4, 28.0, 50.0, 7.0, …\n$ gt      &lt;dbl&gt; 645, 42, 60, 25, 624, 180, 35, 392, 63, 230, 112, 281, NA, 365…\n$ pi      &lt;int&gt; 3, 3, 1, 5, 3, 4, 1, 4, 1, 1, 5, 5, 2, 5, 1, 2, 2, 2, 1, 1, 5,…\n$ sei     &lt;int&gt; 5, 1, 1, 2, 5, 4, 1, 5, 2, 1, 4, 5, 1, 5, 1, 2, 2, 2, 2, 1, 5,…\n$ odi     &lt;int&gt; 3, 3, 1, 3, 4, 4, 1, 4, 1, 1, 4, 5, 2, 5, 1, 2, 2, 2, 1, 1, 5,…\n\n\n\n?mammalsleep # the help\n\nNote that the sleepdata dataset is automatically recognized as a dataframe. There is one factor (categorical variable) containing the animal names.\nThe functions head() and tail() are very useful functions. As is function str() as it gives you a quick overview of the measurement levels in mammalsleep.\nSince mammalsleep is an R-data set, there should be a help file. Taking a look at ?mammalsleep provides information about the measurements and origin of the variables.\nOne thing that may have caught your attention is the relation between ts, ps and sws. This is a deterministic relation where total sleep (ts) is the sum of paradoxical sleep (ps) and short-wave sleep (sws). In the event that you would model the data, you need to take such relations into account.\n\n\nSave the current workspace. Name the workspace Practical_3.RData. Also, save the sleepdata file as a separate workspace called Sleepdata.RData. \n\nNow that we have imported our data, it may be wise to save the current workspace, i.e. the current state of affairs. Saving the workspace will leave everything as is, so that we can continue from this exact state at a later time, by simply opening the workspace file. To save everything in the current workspace, type:\n\n# To save the entire workspace:\nsave.image(\"Practical_3juni2025.RData\")\n\nTo save just the data set sleepdata, and nothing else, type:\n\n# To save the data set only.\nsave(sleepdata, file = \"sleepdata.RData\")\n\nWith the save functions, any object in the work space can be saved.\n\n\nSome animals were not used in the calculations by Allison and Cicchetti. Exclude the following animals from the sleepdata data set: Echidna, Lesser short-tailed shrew and Musk shrew. Save the data set as sleepdata2. Tip: use the square brackets to indicate [rows, columns] or use the function filter() from dplyr.\n\nThere are three ways to exclude the three animals from the data set. The first approach uses the names:\n\nexclude &lt;- c(\"Echidna\", \"Lesser short-tailed shrew\", \"Musk shrew\")\n# Indicate the species that match the names in exclude\nwhich &lt;- sleepdata$species %in% exclude \nwhich\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE\n\nsleepdata_new &lt;- sleepdata[!which, ]\n\nand the second approach uses the row numbers directly (you would need to inquire about, or calculate the row numbers)\n\nsleepdata_new &lt;- sleepdata[-c(16, 32, 38), ]\n\nNote that the numbered option requires less code, but the named option has a much lower probability for error. As the data set might change, or might get sorted differently, the second option may not be valid anymore.\nThe third approach uses function filter() from package dplyr:\n\nlibrary(dplyr) # Data Manipulation\ndplyr::filter(sleepdata, !sleepdata$species %in% exclude) \n\n# A tibble: 59 × 11\n   species             bw    brw   sws    ps    ts   mls    gt    pi   sei   odi\n   &lt;fct&gt;            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 African eleph… 6.65e+3 5712    NA    NA     3.3  38.6   645     3     5     3\n 2 African giant… 1   e+0    6.6   6.3   2     8.3   4.5    42     3     1     3\n 3 Arctic Fox     3.38e+0   44.5  NA    NA    12.5  14      60     1     1     1\n 4 Arctic ground… 9.2 e-1    5.7  NA    NA    16.5  NA      25     5     2     3\n 5 Asian elephant 2.55e+3 4603     2.1   1.8   3.9  69     624     3     5     4\n 6 Baboon         1.06e+1  180.    9.1   0.7   9.8  27     180     4     4     4\n 7 Big brown bat  2.3 e-2    0.3  15.8   3.9  19.7  19      35     1     1     1\n 8 Brazilian tap… 1.6 e+2  169     5.2   1     6.2  30.4   392     4     5     4\n 9 Cat            3.3 e+0   25.6  10.9   3.6  14.5  28      63     1     2     1\n10 Chimpanzee     5.22e+1  440     8.3   1.4   9.7  50     230     1     1     1\n# ℹ 49 more rows\n\n# ! makes all TRUES into FALSE --&gt; it takes the complement\n\n\n\nPlot brain weight as a function of species. \n\n\nplot(brw ~ species, data = sleepdata_new)\n\n\n\n\n\n\n\n\n\n\nSome animals have much heavier brains than other animals. Find out the names of the animals that have a brain weight larger than 1 standard deviation above the mean brain weight. Replicate the plot from Question 9 with only these animals and do not plot any information about the other animals. \n\nTo find out which animals have a brain weight larger than 1 standard deviation above the mean brain weight:\n\nsd.brw &lt;- sd(sleepdata_new$brw) # standard deviation  \nmean.brw &lt;- mean(sleepdata_new$brw) # mean\nwhich &lt;- sleepdata_new$brw &gt; (mean.brw + (1 * sd.brw)) # which are larger?\nas.character(sleepdata_new$species[which]) # names of the animals with brw &gt; 1000\n\n[1] \"African elephant\" \"Asian elephant\"   \"Man\"             \n\n\nTo plot these animals:\n\nplot(brw ~ species, data = sleepdata_new[which, ])\n\n\n\n\n\n\n\n\nThe downside is that it still prints all the animals on the x-axis. This is due to the factor labels for species being copied to the smaller subset of the data. Plot automatically takes over the labels. For example,\n\nsleepdata_new$species[which]\n\n[1] African elephant Asian elephant   Man             \n62 Levels: African elephant African giant pouched rat ... Yellow-bellied marmot\n\n\nreturns only 3 mammals, but still has 62 factor levels. To get rid of the unused factor levels, we can use function factor():\n\nsleepdata_3mammals &lt;- sleepdata_new[which, ]\nsleepdata_3mammals$species &lt;- factor(sleepdata_3mammals$species)\nsleepdata_3mammals$species\n\n[1] African elephant Asian elephant   Man             \nLevels: African elephant Asian elephant Man\n\n\nTo plot the graph that we wanted:\n\nplot(brw ~ species, data = sleepdata_3mammals)\n\n\n\n\n\n\n\n\n\nIf your current software-analysis platform is different from R, chances are that you prepare your data in the software of your choice. In R there are fantastic facilities for importing and exporting data and I would specifically like to pinpoint you to package haven by Hadley Wickham. It provides wonderful functions to import and export many data types from software such as Stata, SAS and SPSS.\n\n\n\nUseful links for the Extra Practical\n\nPackage haven for importing/exporting SPSS, SAS and STATA data.\n\n\nEnd of Practical",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Management</span>"
    ]
  },
  {
    "objectID": "meeting3.html",
    "href": "meeting3.html",
    "title": "Data Manipulatie",
    "section": "",
    "text": "Practical1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulatie</span>"
    ]
  },
  {
    "objectID": "meeting3.html#practicallabcredits",
    "href": "meeting3.html#practicallabcredits",
    "title": "Data Manipulatie",
    "section": "",
    "text": "Load the tidyverse package\nLoad the tidyverse package to be able to use the functions in the dplyr and readr packages.\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nDownload overview of dplyr functions\nDownload the dplyr cheat sheet here\n\n\nImport the data\nThe Mammals Sleep data set2 contains the sleep times and weights for a set of mammals. This data set contains 83 rows (the animals) and 11 variables (the characteristics of the animals).\nBe sure to place the data set msleep.csv in the same folder as the RStudio Project you are working on. Use the function read_csv from the readr package to import the data and save it as msleep (using the assignment &lt;- operator).\n\n\nRows: 83 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): name, genus, vore, order, conservation\ndbl (6): sleep_total, sleep_rem, sleep_cycle, awake, brainwt, bodywt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nmsleep &lt;- readr::read_csv(\"msleep.csv\")\n\n\n\n\nInspect the data with view()\nYou will see that the data msleep is now in the “Data” window in the “Environment” tab. If you click on the blue arrow of the data set, you will see the list of variables in the data. Clicking on the spreadsheet symbol will open a new window where you can have a look at the data. The same can be achieved with the view()function. Use this function to have a look at the data\n\n\nCode\nview(msleep)\n\n\nHere is the description of the variables in the data set:\n\nname: common name\ngenus: taxonomic rank\nvore: carnivore, omnivore or herbivore\norder: taxonomic rank\nconservation: the conservation status of the mammal\nsleep_total: total amount of sleep, in hours\nsleep_rem: rem sleep, in hours\nsleep_cycle: length of sleep cycle, in hours\nawake: amount of time spent awake, in hours\nbrainwt: brain weight in kilograms\nbodywt: body weight in kilograms\n\n\n\nUse dplyr::glimpse() to inspect the data\nUse dplyr::glimpse() to inspect the msleep data and compare it with str() on the same data. What information do you obtain? What are the differences?\n\n\nCode\ndplyr::glimpse(msleep)\n\n\nRows: 83\nColumns: 11\n$ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n$ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n$ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n$ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n$ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"dome…\n$ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n$ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n$ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333, N…\n$ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n$ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n$ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\n\n\n\nCode\nstr(msleep)\n\n\nspc_tbl_ [83 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ name        : chr [1:83] \"Cheetah\" \"Owl monkey\" \"Mountain beaver\" \"Greater short-tailed shrew\" ...\n $ genus       : chr [1:83] \"Acinonyx\" \"Aotus\" \"Aplodontia\" \"Blarina\" ...\n $ vore        : chr [1:83] \"carni\" \"omni\" \"herbi\" \"omni\" ...\n $ order       : chr [1:83] \"Carnivora\" \"Primates\" \"Rodentia\" \"Soricomorpha\" ...\n $ conservation: chr [1:83] \"lc\" NA \"nt\" \"lc\" ...\n $ sleep_total : num [1:83] 12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ...\n $ sleep_rem   : num [1:83] NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ...\n $ sleep_cycle : num [1:83] NA NA NA 0.133 0.667 ...\n $ awake       : num [1:83] 11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ...\n $ brainwt     : num [1:83] NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ...\n $ bodywt      : num [1:83] 50 0.48 1.35 0.019 600 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   name = col_character(),\n  ..   genus = col_character(),\n  ..   vore = col_character(),\n  ..   order = col_character(),\n  ..   conservation = col_character(),\n  ..   sleep_total = col_double(),\n  ..   sleep_rem = col_double(),\n  ..   sleep_cycle = col_double(),\n  ..   awake = col_double(),\n  ..   brainwt = col_double(),\n  ..   bodywt = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\nUse base R function summary() to obtain descriptives\nThe base R function summary() gives descriptive statistics for all the variables in a data frame. It takes into account the data type (class) of each variable. Run the code below. What information do you get about the data? And how does this differ depending on the class (data type) of the variable?\n\n\nCode\nsummary(msleep)\n\n\n     name              genus               vore              order          \n Length:83          Length:83          Length:83          Length:83         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n conservation        sleep_total      sleep_rem      sleep_cycle    \n Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n                    Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n                    3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.5792  \n                    Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n                                    NA's   :22      NA's   :51      \n     awake          brainwt            bodywt        \n Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n 1st Qu.:10.25   1st Qu.:0.00290   1st Qu.:   0.174  \n Median :13.90   Median :0.01240   Median :   1.670  \n Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n 3rd Qu.:16.15   3rd Qu.:0.12550   3rd Qu.:  41.750  \n Max.   :22.10   Max.   :5.71200   Max.   :6654.000  \n                 NA's   :27",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulatie</span>"
    ]
  },
  {
    "objectID": "meeting3.html#multiple-transformations-with",
    "href": "meeting3.html#multiple-transformations-with",
    "title": "Data Manipulatie",
    "section": "Multiple transformations with %>%",
    "text": "Multiple transformations with %&gt;%\nWrite code to perform the following operations using dplyr functions and pipes:\n\nSelect three columns from msleep (the variables “name”, “order” and “sleep_total”)\nArrange the rows by order and by sleep_total in descending order.\nFilter the rows for mammals that sleep 16 or more hours.\nShow the first 5 lines of the resulting transformation.\n\n\n\nCode\nmsleep %&gt;% \n    dplyr::select(name, order, sleep_total) %&gt;%\n    dplyr::arrange(order, desc(sleep_total)) %&gt;% \n    dplyr::filter(sleep_total &gt;= 16) %&gt;% \n    head(n=5)\n\n\n# A tibble: 5 × 3\n  name                 order           sleep_total\n  &lt;chr&gt;                &lt;chr&gt;                 &lt;dbl&gt;\n1 Little brown bat     Chiroptera             19.9\n2 Big brown bat        Chiroptera             19.7\n3 Giant armadillo      Cingulata              18.1\n4 Long-nosed armadillo Cingulata              17.4\n5 Thick-tailed opposum Didelphimorphia        19.4\n\n\n\nCreate new columns using dplyr::mutate()\nThe dplyr::mutate() function will add new columns to the data frame. Create a new column called rem_proportion, which is calculated as the following ratio: rem_proportion = sleep_rem / sleep_total. Show the first 5 rows of the result.\n\n\nCode\nmsleep %&gt;% \n    dplyr::mutate(rem_proportion = sleep_rem / sleep_total) %&gt;%\n    dplyr::slice_head(n=5)\n\n\n# A tibble: 5 × 12\n  name    genus vore  order conservation sleep_total sleep_rem sleep_cycle awake\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Cheetah Acin… carni Carn… lc                  12.1      NA        NA      11.9\n2 Owl mo… Aotus omni  Prim… &lt;NA&gt;                17         1.8      NA       7  \n3 Mounta… Aplo… herbi Rode… nt                  14.4       2.4      NA       9.6\n4 Greate… Blar… omni  Sori… lc                  14.9       2.3       0.133   9.1\n5 Cow     Bos   herbi Arti… domesticated         4         0.7       0.667  20  \n# ℹ 3 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;, rem_proportion &lt;dbl&gt;\n\n\nYou can add several new columns using dplyr::mutate() (separated by commas).\nWrite code to:\n\nCreate two new variables in msleep:\n\nrem_proportion = sleep_rem / sleep_total\nbrain_body = brainwt / bodywt\n\nSave the msleep data with these new variables as sleepdata.\nVerify that sleepdata indeed contains the two new variables.\n\n\n\nCode\nsleepdata &lt;- msleep %&gt;% \n    dplyr::mutate(rem_proportion = sleep_rem / sleep_total, \n           brain_body = brainwt / bodywt) %&gt;% \n  glimpse()\n\n\nRows: 83\nColumns: 13\n$ name           &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater sh…\n$ genus          &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"B…\n$ vore           &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"ca…\n$ order          &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"A…\n$ conservation   &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"do…\n$ sleep_total    &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0,…\n$ sleep_rem      &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8…\n$ sleep_cycle    &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333,…\n$ awake          &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0,…\n$ brainwt        &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000,…\n$ bodywt         &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.…\n$ rem_proportion &lt;dbl&gt; NA, 0.10588235, 0.16666667, 0.15436242, 0.17500000, 0.1…\n$ brain_body     &lt;dbl&gt; NA, 0.032291667, NA, 0.015263158, 0.000705000, NA, NA, …\n\n\nCheck whether there is a relationship between the total amount of sleep (sleep_total) mammals need, and the ratio of the brain weight compared to the body weight (brain_body). Do mammals with relatively larger brains need more sleep? Make the plot with the following code. What do you conclude from the plot?\n\n\nCode\nplot(sleepdata$brain_body, sleepdata$sleep_total)\n\n\n\n\n\n\n\n\n\n\n\nPipe operator and model formula\nA step further would be to fit a linear regression model, with total hours of sleep as outcome variable (y = sleep_total) and the ratio between brain weight and body weight as independent variable (x = brain_body).\nIn R we fit linear regression models with: lm(y ~ x, data = data_frame).\nLook at the code below and see if you understand what it does. Why do we need to use data = . as an argument in the lm() function?\n\n\nCode\nmsleep %&gt;% \n    dplyr::mutate(rem_proportion = sleep_rem / sleep_total, \n           brain_body = brainwt / bodywt) %&gt;% \n    lm(sleep_total ~ brain_body, data = .) %&gt;%\n    summary()\n\n\n\nCall:\nlm(formula = sleep_total ~ brain_body, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.606 -3.420 -0.477  2.107  9.297 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.5973     0.8529  10.080 5.16e-14 ***\nbrain_body  152.0003    61.6672   2.465   0.0169 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.231 on 54 degrees of freedom\n  (27 observations deleted due to missingness)\nMultiple R-squared:  0.1011,    Adjusted R-squared:  0.08449 \nF-statistic: 6.075 on 1 and 54 DF,  p-value: 0.01692",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulatie</span>"
    ]
  },
  {
    "objectID": "meeting3.html#close-the-project",
    "href": "meeting3.html#close-the-project",
    "title": "Data Manipulatie",
    "section": "Close the project",
    "text": "Close the project\nClose the RStudio Project using the option you prefer.\nHere are the 2 options:\n\nQuit RStudio using RStudio -&gt; Quit RStudio. This will close the RStudio application but keep the current RStudio Project active. This means that when you open RStudio the next time, it will automatically open with the current RStudio Project.\nClose the RStudio Project using File -&gt; Close Project. This will only close the current RStudio Project, but it will not close the RStudio application.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulatie</span>"
    ]
  },
  {
    "objectID": "meeting3.html#use-case_when-to-recode-variables",
    "href": "meeting3.html#use-case_when-to-recode-variables",
    "title": "Data Manipulatie",
    "section": "Use case_when to recode variables",
    "text": "Use case_when to recode variables\nNow create another variable sleep_cat based on sleep_total and this time using three categories: animals that sleep 6 hours or less are “short”, animals that sleep between 6 and 10 hours are “normal”, and animals that sleep more than 10 hours are “long”. Create a new data set with this new variable included as a factor. Use the function case_when() and save the data set with the new variable under a new name.\n\n\nCode\nnewdata2 &lt;- newdata %&gt;%\n  mutate(sleep_cat = case_when(\n            sleep_total &lt;= 6 ~ \"short\",\n            sleep_total &gt; 10  ~ \"long\",\n            TRUE ~ \"normal\"),\n         sleep_cat = factor(sleep_cat)       \n        )\n\nsummary(newdata2$sleep_cat)\n\n\n  long normal  short \n    44     23     16 \n\n\n\nChange the levels of a categorical variable with dplyr and case_when\nCreate a new variable vore_cat that combines the two categories “carni” and “insecti” in the original variable vore. Save the new data set under a new name and ensure that the new variable vore-cat is converted to a factor variable.\n\n\nCode\nnewdata3 &lt;- msleep %&gt;%\n  mutate(vore_cat = case_when(\n            vore == \"carni\" ~ \"carni\",\n            vore == \"insecti\" ~ \"carni\",\n            vore == \"herbi\" ~ \"herbi\",\n            vore == \"omni\" ~ \"omni\"),\n         vore_cat = factor(vore_cat)       \n        )\n\nsummary(newdata3$vore_cat)\n\n\ncarni herbi  omni  NA's \n   24    32    20     7 \n\n\n\n\nExclude a few animals from the data set with base R code and with dplyr\nExclude the following animals from the msleep (variable ‘name’): Echidna, Lesser short-tailed shrew and Musk shrew. Save the data set as msleep2. Tip: use the square brackets to indicate [rows, columns] or use the function filter() from dplyr.\n\n\nCode\n# The first approach uses the names\nexclude &lt;- c(\"Bottle-nosed dolphin\", \"Lesser short-tailed shrew\", \"Musk shrew\")\nwhich &lt;- msleep$name %in% exclude #Indicate the species that match the names in exclude\nwhich\n\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[73]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n\n\nCode\nmsleep2 &lt;- msleep[!which, ]\n\n\n\n\nCode\n# The second approach uses the row numbers directly (you would need to inquire about, or calculate the row numbers)\nmsleep3 &lt;- msleep[-c(17, 73, 80), ]\n\n# Note that the numbered option requires less code, but the named option has a much lower probability for error. As the data set might change, or might get sorted differently, the second option may not be valid anymore. \n\n\n\n\nCode\n# Using dplyr and filter()\n\nlibrary(dplyr) \nexclude &lt;- c(\"Bottle-nosed dolphin\", \"Lesser short-tailed shrew\", \"Musk shrew\")\nmsleep4 &lt;- dplyr::filter(msleep, !msleep$name %in% exclude) # ! makes all TRUES into FALSE\n\n\n\n\nClose the project\nClose the RStudio Project using the option you prefer.\nHere are the 2 options:\n\nQuit RStudio using RStudio -&gt; Quit RStudio. This will close the RStudio application but keep the current RStudio Project active. This means that when you open RStudio the next time, it will automatically open with the current RStudio Project.\nClose the RStudio Project using File -&gt; Close Project. This will only close the current RStudio Project, but it will not close the RStudio application.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulatie</span>"
    ]
  },
  {
    "objectID": "meeting3.html#footnotes",
    "href": "meeting3.html#footnotes",
    "title": "Data Manipulatie",
    "section": "",
    "text": "The exercises in this lab are inspired by the exercises made by Stephen Turner, see here.↩︎\nA quantitative, theoretical framework for understanding mammalian sleep. Van M. Savage, Geoffrey B. West. Proceedings of the National Academy of Sciences Jan 2007, 104 (3) 1051-1056; DOI: 10.1073/pnas.0610080104↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulatie</span>"
    ]
  },
  {
    "objectID": "meeting4.html",
    "href": "meeting4.html",
    "title": "Statistische Analyse",
    "section": "",
    "text": "Exercises",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#load-packages",
    "href": "meeting4.html#load-packages",
    "title": "Statistische Analyse",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse) # for data manipulation and visualization\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# tidyverse loads readr, dplyr, tidyr, tibble, stringr, etcetera\n# all these packages we need in some form in this practical\nlibrary(magrittr)  # for flexible pipes\n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#linear-model",
    "href": "meeting4.html#linear-model",
    "title": "Statistische Analyse",
    "section": "Linear model",
    "text": "Linear model\nExercise 1: Fit the following linear models on the anscombe data:\n\ny1 modeled by x1 - stored (i.e. assign with &lt;-) in object fit1\ny2 modeled by x2 - stored (i.e. assign with &lt;-) in object fit2\ny3 modeled by x3 - stored (i.e. assign with &lt;-) in object fit3\ny4 modeled by x4 - stored (i.e. assign with &lt;-) in object fit4\n\n\n\nCode\nfit1 &lt;- anscombe %$%\n  lm(y1 ~ x1)\nfit2 &lt;- anscombe %$%\n  lm(y2 ~ x2)\nfit3 &lt;- anscombe %$%\n  lm(y3 ~ x3)\nfit4 &lt;- anscombe %$%\n  lm(y4 ~ x4)\n\n\nIt is a convention to call an object that contains a fitted model (lm(y1 ~ x1) results in a fitted linear model) by its name prefixed with fit. This is not a requirement, but it is a convention that makes it easier to read the code. Anyone who sees fit1 knows that this is a fitted model - and most likely the first one - in a series of fitted models.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#structure-the-output",
    "href": "meeting4.html#structure-the-output",
    "title": "Statistische Analyse",
    "section": "Structure the output",
    "text": "Structure the output\nExercise 2: Create a data frame from the coefficients of the 4 fitted objects from Exercise 1 and name the resulting object fitted_coefs We did not yet discuss this in the lecture, but the coef() function returns the coefficients of a fitted model. We can use this to quickly extract the coefficients of fitted models to create a data frame with the coefficients of the four fitted anscombe models.\n\n\nCode\nfitted_coefs &lt;- data.frame(fit1 = coef(fit1),\n                           fit2 = coef(fit2),\n                           fit3 = coef(fit3),\n                           fit4 = coef(fit4))\nfitted_coefs\n\n\n                 fit1     fit2      fit3      fit4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\n\nThese estimates are very similar, as we already established in today’s lecture. For the interpretation of the estimates:\n-   The intercept represents the expected value of the outcome ($y$) when all predictor variables ($x$) are zero.\n-   Each regression estimate (coefficient) shows the expected change in $y$ for a one-unit increase in that predictor, holding all other variables constant.\n-   A positive coefficient means $y$ increases as the predictor $x$ increases; a negative coefficient means $y$ decreases with increasing $x$.\n\nExercise 3: Now add the rownames as a column to the data and make sure that the resulting object is a tibble.\n\n\nCode\nfitted_coefs %&lt;&gt;% # assign pipe parses the result back to fitted_coefs\n  rownames_to_column(var = \"estimate\") %&gt;% # add rownames to the data\n  as_tibble() # explicitly make it a tibble\n\n\n\nExercise 4: Inspect the fitted_coefs data set. Why does fit2 have fewer decimals printed than the other models?\n\n\nCode\nfitted_coefs\n\n\n# A tibble: 2 × 5\n  estimate     fit1  fit2  fit3  fit4\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 (Intercept) 3.00   3.00 3.00  3.00 \n2 x1          0.500  0.5  0.500 0.500\n\n\nCode\n#The coefficient for `fit2` is exactly `0.5`, which is printed with only one decimal, while the other coefficients are printed with 3 digits. Tibbles print numbers with three significant digits by default, switching to scientific notation if the available space is too small. If it can be represented with fewer numbers, it will do so.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#plotting-the-models",
    "href": "meeting4.html#plotting-the-models",
    "title": "Statistische Analyse",
    "section": "Plotting the models",
    "text": "Plotting the models\nExercise 5: Plot the four fitted models from the anscombe data set in a single plotting window as follows: use plot() to make a plot for the first model and points() to add each subsequent model’s points to the plot window. Make the points for the models in the plots blue (y1 ~ x1), gray (y2 ~ x2), orange (y3 ~ x3) and purple (y4 ~ x4), respectively. \nHint: look at ?plot and ?points for the arguments that you need to plot the models and to change the color of the points.\n\n\nCode\nplot(y1 ~ x1, col = \"blue\", data = anscombe)\npoints(y2 ~ x2, col = \"gray\", data = anscombe)\npoints(y3 ~ x3, col = \"orange\", data = anscombe)\npoints(y4 ~ x4, col = \"purple\", data = anscombe)\n\n\n\n\n\n\n\n\n\n\nExercise 6: Now plot all four fitted models in a plotting window with 2 rows and 2 columns.\nHint: use the command par(mfrow = c(2, 2)) to set the plotting window to 2 rows and 2 columns. Use this command before you start the plots. You do not have to use points() in this case, but rather use plot() for every seperate model plot.\n\n\nCode\npar(mfrow = c(2, 2))\nplot(y1 ~ x1, data = anscombe)\nplot(y2 ~ x2, data = anscombe)\nplot(y3 ~ x3, data = anscombe)\nplot(y4 ~ x4, data = anscombe)\n\n\n\n\n\n\n\n\n\nWith par(mfrow = c(2, 2)) we set the plotting window to have 2 rows and 2 columns. This means that the first plot will be placed in the first row, first column, the next plot will be placed in the first row, second column, and so on.\nTo revert to a single plotting window, you can use par(mfrow = c(1, 1)) after the plots.\n\n\nCode\npar(mfrow = c(1, 1)) # revert to single plotting window",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#read-in-the-titanic-data-set",
    "href": "meeting4.html#read-in-the-titanic-data-set",
    "title": "Statistische Analyse",
    "section": "Read in the titanic data set",
    "text": "Read in the titanic data set\nWe use the titanic data set for the next exercises. Use the code below to read them in from the internet:\n\n\nCode\ncon &lt;- url(\"https://www.gerkovink.com/erasmus/Day%202/Part%20D/titanic.csv\")\ntitanic &lt;- read_csv(con) # reads in the connection as a csv file\n\n\nRows: 887 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Name, Sex\ndbl (6): Survived, Pclass, Age, Siblings/Spouses Aboard, Parents/Children Ab...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nExercise 7: Inspect the titanic data set by calling titanic in the console and with functions summary(), str() and glimpse.\n\ntitanic will print the data set in the console:\n\n\n\nCode\ntitanic\n\n\n# A tibble: 887 × 8\n   Survived Pclass Name                       Sex     Age Siblings/Spouses Abo…¹\n      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                      &lt;chr&gt; &lt;dbl&gt;                  &lt;dbl&gt;\n 1        0      3 Mr. Owen Harris Braund     male     22                      1\n 2        1      1 Mrs. John Bradley (Floren… fema…    38                      1\n 3        1      3 Miss. Laina Heikkinen      fema…    26                      0\n 4        1      1 Mrs. Jacques Heath (Lily … fema…    35                      1\n 5        0      3 Mr. William Henry Allen    male     35                      0\n 6        0      3 Mr. James Moran            male     27                      0\n 7        0      1 Mr. Timothy J McCarthy     male     54                      0\n 8        0      3 Master. Gosta Leonard Pal… male      2                      3\n 9        1      3 Mrs. Oscar W (Elisabeth V… fema…    27                      0\n10        1      2 Mrs. Nicholas (Adele Ache… fema…    14                      1\n# ℹ 877 more rows\n# ℹ abbreviated name: ¹​`Siblings/Spouses Aboard`\n# ℹ 2 more variables: `Parents/Children Aboard` &lt;dbl&gt;, Fare &lt;dbl&gt;\n\n\nWe can see that the titanic data set is imported as a tibble. A tibble is a more flexible data frame with a much nicer printing class.\n\nsummary() gives us a quick overview of the data set:\n\n\n\nCode\ntitanic %&gt;% summary()\n\n\n    Survived          Pclass          Name               Sex           \n Min.   :0.0000   Min.   :1.000   Length:887         Length:887        \n 1st Qu.:0.0000   1st Qu.:2.000   Class :character   Class :character  \n Median :0.0000   Median :3.000   Mode  :character   Mode  :character  \n Mean   :0.3856   Mean   :2.306                                        \n 3rd Qu.:1.0000   3rd Qu.:3.000                                        \n Max.   :1.0000   Max.   :3.000                                        \n      Age        Siblings/Spouses Aboard Parents/Children Aboard\n Min.   : 0.42   Min.   :0.0000          Min.   :0.0000         \n 1st Qu.:20.25   1st Qu.:0.0000          1st Qu.:0.0000         \n Median :28.00   Median :0.0000          Median :0.0000         \n Mean   :29.47   Mean   :0.5254          Mean   :0.3833         \n 3rd Qu.:38.00   3rd Qu.:1.0000          3rd Qu.:0.0000         \n Max.   :80.00   Max.   :8.0000          Max.   :6.0000         \n      Fare        \n Min.   :  0.000  \n 1st Qu.:  7.925  \n Median : 14.454  \n Mean   : 32.305  \n 3rd Qu.: 31.137  \n Max.   :512.329  \n\n\nThe summary() output gives us direct information about the parametric nature of the columns in the data\n\nstr() gives us the structure of the data set:\n\n\n\nCode\ntitanic %&gt;% str()\n\n\nspc_tbl_ [887 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Survived               : num [1:887] 0 1 1 1 0 0 0 0 1 1 ...\n $ Pclass                 : num [1:887] 3 1 3 1 3 3 1 3 3 2 ...\n $ Name                   : chr [1:887] \"Mr. Owen Harris Braund\" \"Mrs. John Bradley (Florence Briggs Thayer) Cumings\" \"Miss. Laina Heikkinen\" \"Mrs. Jacques Heath (Lily May Peel) Futrelle\" ...\n $ Sex                    : chr [1:887] \"male\" \"female\" \"female\" \"female\" ...\n $ Age                    : num [1:887] 22 38 26 35 35 27 54 2 27 14 ...\n $ Siblings/Spouses Aboard: num [1:887] 1 1 0 1 0 0 0 3 0 1 ...\n $ Parents/Children Aboard: num [1:887] 0 0 0 0 0 0 0 1 2 0 ...\n $ Fare                   : num [1:887] 7.25 71.28 7.92 53.1 8.05 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Survived = col_double(),\n  ..   Pclass = col_double(),\n  ..   Name = col_character(),\n  ..   Sex = col_character(),\n  ..   Age = col_double(),\n  ..   `Siblings/Spouses Aboard` = col_double(),\n  ..   `Parents/Children Aboard` = col_double(),\n  ..   Fare = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nWhen we study the structure of the data set, we see that the outcome Survived is not coded as a factor, but as a numeric column. The same holds for Pclass. This will influence the default estimation later on. There are more irregularities, but we’ll ignore those for now.\n\n\nCode\ntitanic %&gt;% glimpse()\n\n\nRows: 887\nColumns: 8\n$ Survived                  &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,…\n$ Pclass                    &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3,…\n$ Name                      &lt;chr&gt; \"Mr. Owen Harris Braund\", \"Mrs. John Bradley…\n$ Sex                       &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\"…\n$ Age                       &lt;dbl&gt; 22, 38, 26, 35, 35, 27, 54, 2, 27, 14, 4, 58…\n$ `Siblings/Spouses Aboard` &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0,…\n$ `Parents/Children Aboard` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0,…\n$ Fare                      &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.…\n\n\nThere are no missing values in this titanic data set.\n\nExercise 8: Correct the measurement level of the columns Pclass and Survived. Then ask for the summary() once more.\n\n\nCode\ntitanic %&lt;&gt;% \n  mutate(Pclass = factor(Pclass, labels = c(\"1st class\", \"2nd class\", \"3rd class\")), \n         Survived = factor(Survived, labels = c(\"No\", \"Yes\")))\ntitanic %&gt;% summary()\n\n\n Survived        Pclass        Name               Sex           \n No :545   1st class:216   Length:887         Length:887        \n Yes:342   2nd class:184   Class :character   Class :character  \n           3rd class:487   Mode  :character   Mode  :character  \n                                                                \n                                                                \n                                                                \n      Age        Siblings/Spouses Aboard Parents/Children Aboard\n Min.   : 0.42   Min.   :0.0000          Min.   :0.0000         \n 1st Qu.:20.25   1st Qu.:0.0000          1st Qu.:0.0000         \n Median :28.00   Median :0.0000          Median :0.0000         \n Mean   :29.47   Mean   :0.5254          Mean   :0.3833         \n 3rd Qu.:38.00   3rd Qu.:1.0000          3rd Qu.:0.0000         \n Max.   :80.00   Max.   :8.0000          Max.   :6.0000         \n      Fare        \n Min.   :  0.000  \n 1st Qu.:  7.925  \n Median : 14.454  \n Mean   : 32.305  \n 3rd Qu.: 31.137  \n Max.   :512.329  \n\n\nWe now see the tabular information about the Survived and Pclass columns. This is because these columns are now coded as factors (i.e. categorical variables with a numeric representation). Note that in the mutate call, I used the %&lt;&gt;% pipe. This assign pipe returns the endresult of the pipe to the original object. This mitigates the use of the &lt;- assign operator and the double calling of the titanic set in the regular strategy below:\n\n\nCode\ntitanic &lt;- titanic %&gt;% \n  mutate(Pclass = factor(Pclass, labels = c(\"1st class\", \"2nd class\", \"3rd class\")), \n         Survived = factor(Survived, labels = c(\"No\", \"Yes\")))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#correlations",
    "href": "meeting4.html#correlations",
    "title": "Statistische Analyse",
    "section": "Correlations",
    "text": "Correlations\nExercise 9: Calculate Pearson’s correlation coefficient between Age and Fare in the titanic data set.\n\n\nCode\ntitanic %&gt;% \n  summarise(correlation = cor(Age, Fare, use = \"pairwise.complete.obs\"))\n\n\n# A tibble: 1 × 1\n  correlation\n        &lt;dbl&gt;\n1       0.112\n\n\nCode\n# or\ntitanic %$%\n  cor(Age, Fare, use = \"pairwise.complete.obs\")\n\n\n[1] 0.1123286",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#t-test",
    "href": "meeting4.html#t-test",
    "title": "Statistische Analyse",
    "section": "T-test",
    "text": "T-test\nExercise 10: Calculate the mean and variance of age for the survivors and the non-surivors using summarise()\n\n\nCode\ntitanic %&gt;%\n  group_by(Survived) %&gt;%\n  summarise(mean_age = mean(Age, na.rm = TRUE),\n            var_age = var(Age, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Survived mean_age var_age\n  &lt;fct&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 No           30.1    193.\n2 Yes          28.4    208.\n\n\n\nExercise 11: Perform a t-test to compare the mean Age of passengers that survived and those that did not. Perform the t-test once with equal variances assumed, and once without. Does the conclusion change?\n\n\nCode\ntitanic %$%\n  t.test(Age ~ Survived, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  Age by Survived\nt = 1.7781, df = 885, p-value = 0.07572\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -0.1795246  3.6398052\nsample estimates:\n mean in group No mean in group Yes \n         30.13853          28.40839 \n\n\nCode\ntitanic %$%\n  t.test(Age ~ Survived, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  Age by Survived\nt = 1.763, df = 704.1, p-value = 0.07834\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -0.1966269  3.6569075\nsample estimates:\n mean in group No mean in group Yes \n         30.13853          28.40839 \n\n\nThere does not seem to be a significant difference in age between the survivors and the non-survivors. The p-value is larger than 0.05 in both cases, so we cannot reject the null hypothesis that the means are equal.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#chi-squared-test",
    "href": "meeting4.html#chi-squared-test",
    "title": "Statistische Analyse",
    "section": "Chi-squared test",
    "text": "Chi-squared test\nExercise 12: Perform a chi-squared test to compare the survival rates of passengers in the different classes. Also study the observed frequencies table and study the expected frequencies.\n\n\nCode\ntitanic %$%\n  table(Pclass, Survived) # Create a contingency table\n\n\n           Survived\nPclass       No Yes\n  1st class  80 136\n  2nd class  97  87\n  3rd class 368 119\n\n\nCode\ntitanic %$%\n  chisq.test(table(Pclass, Survived)) # Perform the chi-squared test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(Pclass, Survived)\nX-squared = 101.22, df = 2, p-value &lt; 2.2e-16\n\n\nCode\ntitanic %$%\n  chisq.test(table(Pclass, Survived)) %&gt;% \n  .$expected # Study the expected frequencies\n\n\n           Survived\nPclass            No       Yes\n  1st class 132.7170  83.28298\n  2nd class 113.0552  70.94476\n  3rd class 299.2277 187.77227\n\n\nThe observed frequencies show that there are more survivors in the 1st class than in the 2nd and 3rd class.\nThe \\(\\chi^2\\)-test indicates a significant difference in survival rates between the different classes, as the p-value is smaller than 0.05. The expected frequencies are all larger than 5, so we can safely use the chi-squared test.\nAlternatively, we could have used broom::tidy() to tidy the output of the chi-squared test:\n\n\nCode\nlibrary(broom) # for tidy output\ntitanic %$%\n  chisq.test(table(Pclass, Survived)) %&gt;% \n  broom::tidy()\n\n\n# A tibble: 1 × 4\n  statistic  p.value parameter method                    \n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;                     \n1      101. 1.05e-22         2 Pearson's Chi-squared test",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting4.html#anova",
    "href": "meeting4.html#anova",
    "title": "Statistische Analyse",
    "section": "ANOVA",
    "text": "ANOVA\nExercise 13: Calculate the mean and variance of Fare for every passenger class using summarise()\n\n\nCode\ntitanic %&gt;% \n  group_by(Pclass) %&gt;% \n  summarise(mean_fare = mean(Fare, na.rm = TRUE),\n            var_fare = var(Fare, na.rm = TRUE))\n\n\n# A tibble: 3 × 3\n  Pclass    mean_fare var_fare\n  &lt;fct&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 1st class      84.2    6143.\n2 2nd class      20.7     180.\n3 3rd class      13.7     140.\n\n\nThere is a visible difference in mean fare between the different classes, as the variance is larger for the more luxurious classes. The mean fare for 1st class is much higher than for 2nd and 3rd class, which is expected.\n\nExercise 14: Perform an ANOVA to compare the mean Fare of passengers in the different classes.\n\n\nCode\ntitanic %$%\n  lm(Fare ~ Pclass) %&gt;%\n  anova()\n\n\nAnalysis of Variance Table\n\nResponse: Fare\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nPclass      2  774068  387034  240.66 &lt; 2.2e-16 ***\nResiduals 884 1421663    1608                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\n# or\ntitanic %$%\n  aov(Fare ~ Pclass) %&gt;%\n  summary()\n\n\n             Df  Sum Sq Mean Sq F value Pr(&gt;F)    \nPclass        2  774068  387034   240.7 &lt;2e-16 ***\nResiduals   884 1421663    1608                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe ANOVA shows that there is a significant difference in mean fare between the different classes, as the p-value is smaller than 0.05.\n\nEnd of Practical.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Statistische Analyse</span>"
    ]
  },
  {
    "objectID": "meeting5.html",
    "href": "meeting5.html",
    "title": "Functioneel Programmeren",
    "section": "",
    "text": "Practical\nI will not tell you which packages you will need for this practical. You will need to load the packages in the practical when you need them. This is to help you get used to knowing when to use which package.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#create-some-random-data",
    "href": "meeting5.html#create-some-random-data",
    "title": "Functioneel Programmeren",
    "section": "Create some random data",
    "text": "Create some random data\nDraw 50 values from a standard normal distribution (i.e. with mean 0 and variance 1). Use the drawn values to make a tibble named random_tibble with 10 rows and 5 columns. Make sure to set a seed so that you can reproduce the results.\n\n\nCode\nset.seed(123) # if you want to reproduce the results\nlibrary(tibble) # needed for tibbles\n\n# draw random numbers\nrandom_data &lt;- rnorm(50, mean = 0, sd = 1)\n\n# create random tibble\nrandom_tibble &lt;- tibble(\n  V1 = random_data[1:10],\n  V2 = random_data[11:20],\n  V3 = random_data[21:30],\n  V4 = random_data[31:40],\n  V5 = random_data[41:50]\n)\n\n# or \nrandom_tibble &lt;- as_tibble(matrix(random_data, nrow = 10, ncol = 5))\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#your-own-function",
    "href": "meeting5.html#your-own-function",
    "title": "Functioneel Programmeren",
    "section": "Your own function",
    "text": "Your own function\nWrite a function that takes a vector of numbers and returns the squares of the numbers in the vector. Test your function on the vector c(1, 2, 3, 4, 5).\n\n\nCode\nsquares &lt;- function(x) {\n  output &lt;- x^2 # square the numbers\n  return(output) # return the squared numbers\n}\n# Test your function\nvector &lt;- c(1, 2, 3, 4, 5)\nsquares(vector)\n\n\n[1]  1  4  9 16 25",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#apply-your-function",
    "href": "meeting5.html#apply-your-function",
    "title": "Functioneel Programmeren",
    "section": "Apply your function",
    "text": "Apply your function\nUse apply(), lapply() and sapply() to apply your function to the random_tibble data. Try all margins for apply() and try the defaults for lapply() and sapply(). Also try argument simplify = FALSE for sapply().\n\n\nCode\napply(random_tibble, MARGIN = 1, squares) # apply to rows\n\n\n        [,1]       [,2]      [,3]        [,4]       [,5]      [,6]      [,7]\nV1 0.3141330 0.05298168 2.4295716 0.004971433 0.01671532 2.9414479 0.2124437\nV2 1.4983762 0.12946599 0.1606178 0.012250664 0.30895937 3.1930586 0.2478551\nV3 1.1402475 0.04751306 1.0526851 0.531282424 0.39067409 2.8449343 0.7018871\nV4 0.1818717 0.08706718 0.8012499 0.771118422 0.67499547 0.4742254 0.3068248\nV5 0.4826178 0.04322959 1.6012279 4.704369980 1.45917219 1.2613729 0.1623162\n         [,8]       [,9]       [,10]\nV1 1.60037993 0.47176684 0.198614592\nV2 3.86758304 0.49190010 0.223531715\nV3 0.02352331 1.29535569 1.572051856\nV4 0.00383306 0.09361315 0.144758183\nV5 0.21776722 0.60834559 0.006950401\n\n\nCode\napply(random_tibble, MARGIN = 2, squares) # apply to columns\n\n\n               V1         V2         V3         V4          V5\n [1,] 0.314132950 1.49837625 1.14024747 0.18187173 0.482617787\n [2,] 0.052981677 0.12946599 0.04751306 0.08706718 0.043229594\n [3,] 2.429571609 0.16061776 1.05268513 0.80124995 1.601227927\n [4,] 0.004971433 0.01225066 0.53128242 0.77111842 4.704369980\n [5,] 0.016715318 0.30895937 0.39067409 0.67499547 1.459172189\n [6,] 2.941447909 3.19305856 2.84493432 0.47422540 1.261372890\n [7,] 0.212443749 0.24785510 0.70188713 0.30682477 0.162316191\n [8,] 1.600379927 3.86758304 0.02352331 0.00383306 0.217767219\n [9,] 0.471766840 0.49190010 1.29535569 0.09361315 0.608345586\n[10,] 0.198614592 0.22353172 1.57205186 0.14475818 0.006950401\n\n\nCode\nlapply(random_tibble, squares) # apply to each column as a list\n\n\n$V1\n [1] 0.314132950 0.052981677 2.429571609 0.004971433 0.016715318 2.941447909\n [7] 0.212443749 1.600379927 0.471766840 0.198614592\n\n$V2\n [1] 1.49837625 0.12946599 0.16061776 0.01225066 0.30895937 3.19305856\n [7] 0.24785510 3.86758304 0.49190010 0.22353172\n\n$V3\n [1] 1.14024747 0.04751306 1.05268513 0.53128242 0.39067409 2.84493432\n [7] 0.70188713 0.02352331 1.29535569 1.57205186\n\n$V4\n [1] 0.18187173 0.08706718 0.80124995 0.77111842 0.67499547 0.47422540\n [7] 0.30682477 0.00383306 0.09361315 0.14475818\n\n$V5\n [1] 0.482617787 0.043229594 1.601227927 4.704369980 1.459172189 1.261372890\n [7] 0.162316191 0.217767219 0.608345586 0.006950401\n\n\nCode\nsapply(random_tibble, squares) # return a matrix with the results\n\n\n               V1         V2         V3         V4          V5\n [1,] 0.314132950 1.49837625 1.14024747 0.18187173 0.482617787\n [2,] 0.052981677 0.12946599 0.04751306 0.08706718 0.043229594\n [3,] 2.429571609 0.16061776 1.05268513 0.80124995 1.601227927\n [4,] 0.004971433 0.01225066 0.53128242 0.77111842 4.704369980\n [5,] 0.016715318 0.30895937 0.39067409 0.67499547 1.459172189\n [6,] 2.941447909 3.19305856 2.84493432 0.47422540 1.261372890\n [7,] 0.212443749 0.24785510 0.70188713 0.30682477 0.162316191\n [8,] 1.600379927 3.86758304 0.02352331 0.00383306 0.217767219\n [9,] 0.471766840 0.49190010 1.29535569 0.09361315 0.608345586\n[10,] 0.198614592 0.22353172 1.57205186 0.14475818 0.006950401\n\n\nCode\nsapply(random_tibble, squares, simplify = FALSE) # return a list with the results\n\n\n$V1\n [1] 0.314132950 0.052981677 2.429571609 0.004971433 0.016715318 2.941447909\n [7] 0.212443749 1.600379927 0.471766840 0.198614592\n\n$V2\n [1] 1.49837625 0.12946599 0.16061776 0.01225066 0.30895937 3.19305856\n [7] 0.24785510 3.86758304 0.49190010 0.22353172\n\n$V3\n [1] 1.14024747 0.04751306 1.05268513 0.53128242 0.39067409 2.84493432\n [7] 0.70188713 0.02352331 1.29535569 1.57205186\n\n$V4\n [1] 0.18187173 0.08706718 0.80124995 0.77111842 0.67499547 0.47422540\n [7] 0.30682477 0.00383306 0.09361315 0.14475818\n\n$V5\n [1] 0.482617787 0.043229594 1.601227927 4.704369980 1.459172189 1.261372890\n [7] 0.162316191 0.217767219 0.608345586 0.006950401\n\n\nThe argument simplify = FALSE in sapply() is used to return the results as a list instead of a matrix. This is useful when the results are not of the same length or type, as it prevents coercion to a matrix. It mimics the output of lapply().",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#map",
    "href": "meeting5.html#map",
    "title": "Functioneel Programmeren",
    "section": "Map",
    "text": "Map\nNow map your function over the random_tibble data using map(). Use map_df() to return a tibble with the results. Study the difference between the two function’s output.\n\n\nCode\nlibrary(purrr) # needed for map functions\nmap(random_tibble, squares) # returns a list\n\n\n$V1\n [1] 0.314132950 0.052981677 2.429571609 0.004971433 0.016715318 2.941447909\n [7] 0.212443749 1.600379927 0.471766840 0.198614592\n\n$V2\n [1] 1.49837625 0.12946599 0.16061776 0.01225066 0.30895937 3.19305856\n [7] 0.24785510 3.86758304 0.49190010 0.22353172\n\n$V3\n [1] 1.14024747 0.04751306 1.05268513 0.53128242 0.39067409 2.84493432\n [7] 0.70188713 0.02352331 1.29535569 1.57205186\n\n$V4\n [1] 0.18187173 0.08706718 0.80124995 0.77111842 0.67499547 0.47422540\n [7] 0.30682477 0.00383306 0.09361315 0.14475818\n\n$V5\n [1] 0.482617787 0.043229594 1.601227927 4.704369980 1.459172189 1.261372890\n [7] 0.162316191 0.217767219 0.608345586 0.006950401\n\n\nCode\nmap_df(random_tibble, squares) # returns a tibble\n\n\n# A tibble: 10 × 5\n        V1     V2     V3      V4      V5\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 0.314   1.50   1.14   0.182   0.483  \n 2 0.0530  0.129  0.0475 0.0871  0.0432 \n 3 2.43    0.161  1.05   0.801   1.60   \n 4 0.00497 0.0123 0.531  0.771   4.70   \n 5 0.0167  0.309  0.391  0.675   1.46   \n 6 2.94    3.19   2.84   0.474   1.26   \n 7 0.212   0.248  0.702  0.307   0.162  \n 8 1.60    3.87   0.0235 0.00383 0.218  \n 9 0.472   0.492  1.30   0.0936  0.608  \n10 0.199   0.224  1.57   0.145   0.00695\n\n\nCode\n# or with the pipe\nlibrary(magrittr) # needed for the pipe operators\n\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nCode\nrandom_tibble %&gt;%\n  map(squares) # returns a list\n\n\n$V1\n [1] 0.314132950 0.052981677 2.429571609 0.004971433 0.016715318 2.941447909\n [7] 0.212443749 1.600379927 0.471766840 0.198614592\n\n$V2\n [1] 1.49837625 0.12946599 0.16061776 0.01225066 0.30895937 3.19305856\n [7] 0.24785510 3.86758304 0.49190010 0.22353172\n\n$V3\n [1] 1.14024747 0.04751306 1.05268513 0.53128242 0.39067409 2.84493432\n [7] 0.70188713 0.02352331 1.29535569 1.57205186\n\n$V4\n [1] 0.18187173 0.08706718 0.80124995 0.77111842 0.67499547 0.47422540\n [7] 0.30682477 0.00383306 0.09361315 0.14475818\n\n$V5\n [1] 0.482617787 0.043229594 1.601227927 4.704369980 1.459172189 1.261372890\n [7] 0.162316191 0.217767219 0.608345586 0.006950401\n\n\nCode\nrandom_tibble %&gt;%\n  map_df(squares) # returns a tibble\n\n\n# A tibble: 10 × 5\n        V1     V2     V3      V4      V5\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 0.314   1.50   1.14   0.182   0.483  \n 2 0.0530  0.129  0.0475 0.0871  0.0432 \n 3 2.43    0.161  1.05   0.801   1.60   \n 4 0.00497 0.0123 0.531  0.771   4.70   \n 5 0.0167  0.309  0.391  0.675   1.46   \n 6 2.94    3.19   2.84   0.474   1.26   \n 7 0.212   0.248  0.702  0.307   0.162  \n 8 1.60    3.87   0.0235 0.00383 0.218  \n 9 0.472   0.492  1.30   0.0936  0.608  \n10 0.199   0.224  1.57   0.145   0.00695\n\n\nWith map() you can apply a function to each element of a list or vector, and it returns a list. With map_df(), the results are combined into a single data frame (or tibble), which is useful for data manipulation tasks.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#continue-mapping",
    "href": "meeting5.html#continue-mapping",
    "title": "Functioneel Programmeren",
    "section": "Continue mapping",
    "text": "Continue mapping\nNow calculate the sums of squares of the columns in the data. Use the function you wrote earlier to calculate the squares of the numbers in the columns, just like in the previous exercise. Use another map() call to calculate the sums of squares. Again, study the difference in output.\n\n\nCode\nrandom_tibble %&gt;%\n  map(squares) %&gt;% # returns a list\n  map(sum) # returns a list with sums of squares\n\n\n$V1\n[1] 8.243026\n\n$V2\n[1] 10.1336\n\n$V3\n[1] 9.600154\n\n$V4\n[1] 3.539557\n\n$V5\n[1] 10.54737\n\n\nCode\nrandom_tibble %&gt;%\n  map_df(squares) %&gt;% # returns a tibble\n  map_df(sum) # returns a vector with sums of squares\n\n\n# A tibble: 1 × 5\n     V1    V2    V3    V4    V5\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  8.24  10.1  9.60  3.54  10.5\n\n\nmap_df() will always return a vector (if only one dimension is left) or a tibble (if two dimensions are remaining), while map() will always return a list.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#reduce",
    "href": "meeting5.html#reduce",
    "title": "Functioneel Programmeren",
    "section": "Reduce",
    "text": "Reduce\nNow use reduce() to calculate the sum of the squares. Use the function you wrote earlier to calculate the squares of the numbers in the columns, just like in the previous exercise. Use map to calulate the squares first, and then use reduce(sum) to calculate the sum of the squares. What is different about the output?\n\n\nCode\nlibrary(purrr) # needed for reduce\nrandom_tibble %&gt;%\n  map(squares) %&gt;% # returns a list\n  reduce(sum) # returns a single value, the sum of squares\n\n\n[1] 42.06371\n\n\nreduce() is used to apply a function cumulatively to the elements of a list or vector, reducing it to a single value. In this case, it sums up the squares of the numbers in the columns of the tibble. The output is a single numeric value, which is the total sum of squares across all columns. This is different from map() or map_df(), which return lists or tibbles with the results for each column.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#reduce-some-more",
    "href": "meeting5.html#reduce-some-more",
    "title": "Functioneel Programmeren",
    "section": "Reduce some more",
    "text": "Reduce some more\nNow use reduce() to calculate the sum of the squares of the columns in the data. Use the function you wrote earlier to calculate the squares of the numbers in the columns, just like in the previous exercise. Use map to calulate the squares first, and then use reduce(+) to sum up the squares. What is different about the output when compared to reduce(sum)?\n\n\nCode\nrandom_tibble %&gt;%\n  map(squares) %&gt;% # returns a list\n  reduce(`+`) # returns a vector with sums of squares summed over the elements\n\n\n [1]  3.6172462  0.3602575  6.0453524  6.0239929  2.8505164 10.7150391\n [7]  1.6313269  5.7130866  2.9609814  2.1459067\n\n\nreduce(sum) returns a single value, the total sum of squares across all columns, while reduce(+) returns a vector with the sums of squares for each row in the data. The difference is that reduce(sum) applies the sum function cumulatively to all elements, while reduce(+) applies the addition operator to each element in the list, resulting in the sum of squares for every element - which is the same as the sum of square over the rows\n\n\nCode\n# verify that `reduce(`+`)` returns the row sums of squares\nrandom_tibble %&gt;%\n  apply(MARGIN = 2, FUN = squares) %&gt;% # returns a list\n  rowSums # calculate the sums over the rows \n\n\n [1]  3.6172462  0.3602575  6.0453524  6.0239929  2.8505164 10.7150391\n [7]  1.6313269  5.7130866  2.9609814  2.1459067",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#map-reduce",
    "href": "meeting5.html#map-reduce",
    "title": "Functioneel Programmeren",
    "section": "Map-reduce",
    "text": "Map-reduce\nNow create 1000 random number sets like random_tibble and calculate the column means for every colum. The goal is to obtain the overall simulated column means across all tibbles. Follow these steps:\n\nUse replicate() to draw the random numbers\nUse map() to create the tibbles\nUse map() to calculate the column means for every tibble\nFinally, use reduce() to calculate the overall simulated column means across all tibbles.\n\n\n\nCode\nset.seed(123) # if you want to reproduce the results\n\n# create the 1000 random number sets\nrandom_numbers_list &lt;- \n  replicate(1000, \n            expr = rnorm(50, mean = 0, sd = 1), \n            simplify = FALSE)\n\n# convert the list of random numbers to a list of tibbles\ntibbles_list &lt;- map(random_numbers_list, \n                    ~ as_tibble(matrix(.x, nrow = 10, ncol = 5)))\n\n# calculate the column means for each tibble\nmeans_list &lt;- map(tibbles_list, ~ colMeans(.x))\n\n# calculate the overall means across all tibbles\nreduce(means_list, `+`) / length(means_list)\n\n\n          V1           V2           V3           V4           V5 \n 0.008846081  0.004720094 -0.004193883 -0.004779168 -0.013311323 \n\n\nCode\n# or with a pipe\nrandom_numbers_list %&gt;% \n  map(~.x %&gt;% \n        matrix(nrow = 10, ncol = 5) %&gt;%\n        set_colnames(c(\"V1\", \"V2\", \"V3\", \"V4\", \"V5\")) %&gt;% # set column names\n        tibble() %&gt;% \n        colMeans()\n      ) %&gt;% # end of map\n  reduce(`+`) / 1000\n\n\n        ..V1         ..V2         ..V3         ..V4         ..V5 \n 0.008846081  0.004720094 -0.004193883 -0.004779168 -0.013311323",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting5.html#map-reduce-without-reduce",
    "href": "meeting5.html#map-reduce-without-reduce",
    "title": "Functioneel Programmeren",
    "section": "Map-reduce without reduce",
    "text": "Map-reduce without reduce\nNow do the same thing as in the previous exercise, but with a twist: Create 1000 random number sets like random_tibble and calculate the column means for every colum. The goal is to obtain the overall simulated column means across all tibbles without using reduce(). Follow these steps:\n\nUse replicate() to draw the random numbers\nUse map() to create the tibbles\nUse map_df() to calculate the column means for every tibble presented in a tibble\nFinally, use colMeans() to calculate the overall simulated column means based on the previous step.\n\n\n\nCode\nset.seed(123) # if you want to reproduce the results\n\n# create the 1000 random number sets\nrandom_numbers_list &lt;- \n  replicate(1000, \n            expr = rnorm(50, mean = 0, sd = 1), \n            simplify = FALSE)\n\n# convert the list of random numbers to a list of tibbles\ntibbles_list &lt;- map(random_numbers_list, \n                    ~ as_tibble(matrix(.x, nrow = 10, ncol = 5)))\n\n# calculate the column means for each tibble\nmeans_list &lt;- map_df(tibbles_list, ~ colMeans(.x))\n\n# calculate the overall means across all tibbles\ncolMeans(means_list)\n\n\n          V1           V2           V3           V4           V5 \n 0.008846081  0.004720094 -0.004193883 -0.004779168 -0.013311323 \n\n\nCode\n# or with a pipe\nrandom_numbers_list %&gt;% \nmap_df(~.x %&gt;% \n           matrix(nrow = 10, ncol = 5) %&gt;%\n           set_colnames(c(\"V1\", \"V2\", \"V3\", \"V4\", \"V5\")) %&gt;% # set column names\n           tibble() %&gt;% \n           colMeans()\n         ) %&gt;% # end of map\n  colMeans() # calculate the overall means\n\n\n        ..V1         ..V2         ..V3         ..V4         ..V5 \n 0.008846081  0.004720094 -0.004193883 -0.004779168 -0.013311323",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functioneel Programmeren</span>"
    ]
  },
  {
    "objectID": "meeting6.html",
    "href": "meeting6.html",
    "title": "Geavanceerde Data Technieken",
    "section": "",
    "text": "Multiple imputation with mice\nWe fix the RNG seed to allow for replication of the below results.\nset.seed(123)\nThe mice package contains several datasets. Once the package is loaded, these datasets can be used. Have a look at the nhanes dataset (Schafer, 1997, Table 6.14) by typing\nnhanes\n\n   age  bmi hyp chl\n1    1   NA  NA  NA\n2    2 22.7   1 187\n3    1   NA   1 187\n4    3   NA  NA  NA\n5    1 20.4   1 113\n6    3   NA  NA 184\n7    1 22.5   1 118\n8    1 30.1   1 187\n9    2 22.0   1 238\n10   2   NA  NA  NA\n11   1   NA  NA  NA\n12   2   NA  NA  NA\n13   3 21.7   1 206\n14   2 28.7   2 204\n15   1 29.6   1  NA\n16   1   NA  NA  NA\n17   3 27.2   2 284\n18   2 26.3   2 199\n19   1 35.3   1 218\n20   3 25.5   2  NA\n21   1   NA  NA  NA\n22   1 33.2   1 229\n23   1 27.5   1 131\n24   3 24.9   1  NA\n25   2 27.4   1 186\nThe nhanes dataset is a small data set with non-monotone missing values. It contains 25 observations on four variables: age group, body mass index, hypertension and cholesterol (mg/dL).\nTo learn more about the data, use one of the two following help commands:\nhelp(nhanes)\n?nhanes\nThe nhanes dataset is incomplete. We can visualize the missing data patterns by\nmd.pattern(nhanes)\n\n\n\n\n\n\n\n\n   age hyp bmi chl   \n13   1   1   1   1  0\n3    1   1   1   0  1\n1    1   1   0   1  1\n1    1   0   0   1  2\n7    1   0   0   0  3\n     0   8   9  10 27\nFor more informative axis labels, we can use the equivalent ggmice function plot_pattern() as follows\nplot_pattern(nhanes)\nAlthough the most common pattern is the one where all variables are observed, the majority of cases have at least one missing value.\n1. Vary the number of imputations, such that the nhanes set is imputed \\(m=3\\) times.\nThe number of imputed data sets can be specified by the m = ... argument. For example, to create just three imputed data sets, specify\nimp &lt;- mice(nhanes, m = 3, print = FALSE)\nThe print = FALSE argument omits printing of the iteration history from the output. The main reason to omit printing here is to save space in the document.\n2. Change the predictor matrix\nThe predictor matrix is a square matrix that specifies the variables that can be used to impute each incomplete variable. Let us have a look at the predictor matrix that was used\nimp$pred\n\n    age bmi hyp chl\nage   0   1   1   1\nbmi   1   0   1   1\nhyp   1   1   0   1\nchl   1   1   1   0\nEach variable in the data has a row and a column in the predictor matrix. A value 1 indicates that the column variable was used to impute the row variable. For example, the 1 at entry [bmi, age] indicates that variable age was used to impute the incomplete variable bmi. Note that the diagonal is zero because a variable is not allowed to impute itself. The row of age is redundant, because there were no missing values in age. Even though predictor relations are specified for age, mice will not use these relations because it will never overwrite the observed values with imputations. mice gives you complete control over the predictor matrix, enabling you to choose your own predictor relations. This can be very useful, for example, when you have many variables or when you have clear ideas or prior knowledge about relations in the data at hand.\nThere are two ways in which you can create a predictor matrix in mice:\nFor example, we can use any mice() object fitted to the data to grab the predictorMatrix or we can use mice to quickly initialize a predictor matrix, and change it afterwards, without running the algorithm. This latter approach can be done by setting the maximum number of iterations to maxit=0. This leaves the algorithm at initialization, but generates the necessary inner objects.\nini &lt;- mice(nhanes, maxit = 0, print = FALSE)\npred &lt;- ini$pred\npred\n\n    age bmi hyp chl\nage   0   1   1   1\nbmi   1   0   1   1\nhyp   1   1   0   1\nchl   1   1   1   0\nThe object pred contains the predictor matrix from an initial run of mice with zero iterations. It is a square matrix that captures the information about which variables (in the rows) are imputed based on which predictors (in the columns).\nFor example,\npred &lt;- make.predictorMatrix(nhanes)\npred\n\n    age bmi hyp chl\nage   0   1   1   1\nbmi   1   0   1   1\nhyp   1   1   0   1\nchl   1   1   1   0\nAltering the predictor matrix and returning it to the mice algorithm is very simple. For example, the following code removes the variable hyp from the set of predictors, but still leaves it to be predicted by the other variables.\npred[, \"hyp\"] &lt;- 0\npred\n\n    age bmi hyp chl\nage   0   1   0   1\nbmi   1   0   0   1\nhyp   1   1   0   1\nchl   1   1   0   0\nUse your new predictor matrix in mice() as follows\nimp &lt;- mice(nhanes, predictorMatrix =  pred, print = FALSE)\nAs you can see, we can easily feed the new matrix pred to mice. We can also abbreviate the logical operator in the argument print = FALSEALSE.\nThere is a quickpred() function that applies a quick selection procedure of predictors, which can be handy for datasets containing many variables. See ?quickpred for more info. Selecting predictors according to data relations with a minimum correlation of \\(\\rho=.30\\) can be done by\nini &lt;- mice(nhanes, pred = quickpred(nhanes, mincor = .3), print = FALSE)\nini$pred\n\n    age bmi hyp chl\nage   0   0   0   0\nbmi   1   0   0   1\nhyp   1   0   0   1\nchl   1   1   1   0\nFor large predictor matrices, it can be useful to export them to dedicated spreadsheet software like e.g. Microsoft Excel for easier configuration (e.g. see the xlsx package for easy exporting and importing of Excel files). Importing data is straightforward in RStudio through File &gt; Import Dataset.\nYou can visualize the predictor matrix with the ggmice function plot_pred() as follows\nplot_pred(pred)\n3. Inspect the convergence of the algorithm\nThe mice() function implements an iterative Markov Chain Monte Carlo type of algorithm. Let us have a look at the trace lines generated by the algorithm to study convergence:\nimp &lt;- mice(nhanes, print = FALSE)\nplot_trace(imp)\nThe plot shows the mean (left) and standard deviation (right) of the imputed values only. In general, we would like the streams to intermingle (mixing) and be free of any trends at the later iterations (non-stationary). We inspect trends for the imputed values alone, because the observed data does not change. In our case we cannot speak of convergence, especially not for bmi. More iterations or a different model are needed.\nThe mice algorithm uses random sampling, and therefore, the results will be (perhaps slightly) different if we repeat the imputations with different seeds. In order to get identical mice objects between calls, we can fix the use the seed argument.\nimp &lt;- mice(nhanes, seed = 123, print = FALSE)\nwhere 123 is some arbitrary number that you can choose yourself. Rerunning this command will always yields the same imputed values.\n4. Change the imputation method\nFor each column, the algorithm requires a specification of the imputation method. To see which method was used by default:\nimp$meth\n\n  age   bmi   hyp   chl \n   \"\" \"pmm\" \"pmm\" \"pmm\"\nThe variable age is complete and therefore not imputed, denoted by the \"\" empty string. The other variables have method pmm, which stands for predictive mean matching, the default in mice for numerical and integer data.\nIn reality, the nhanes data are better described a as mix of numerical and categorical data. Let us take a look at the nhanes2 data frame:\nsummary(nhanes2)\n\n    age          bmi          hyp          chl       \n 20-39:12   Min.   :20.40   no  :13   Min.   :113.0  \n 40-59: 7   1st Qu.:22.65   yes : 4   1st Qu.:185.0  \n 60-99: 6   Median :26.75   NA's: 8   Median :187.0  \n            Mean   :26.56             Mean   :191.4  \n            3rd Qu.:28.93             3rd Qu.:212.0  \n            Max.   :35.30             Max.   :284.0  \n            NA's   :9                 NA's   :10\nand the structure of the data frame\nstr(nhanes2)\n\n'data.frame':   25 obs. of  4 variables:\n $ age: Factor w/ 3 levels \"20-39\",\"40-59\",..: 1 2 1 3 1 3 1 1 2 2 ...\n $ bmi: num  NA 22.7 NA NA 20.4 NA 22.5 30.1 22 NA ...\n $ hyp: Factor w/ 2 levels \"no\",\"yes\": NA 1 1 NA 1 NA 1 1 1 NA ...\n $ chl: num  NA 187 187 NA 113 184 118 187 238 NA ...\nVariable age consists of 3 age categories, while variable hyp is binary. The mice() function takes these properties automatically into account. Impute the nhanes2 dataset\nimp &lt;- mice(nhanes2, print = FALSE)\nimp$meth\n\n     age      bmi      hyp      chl \n      \"\"    \"pmm\" \"logreg\"    \"pmm\"\nNotice that mice has set the imputation method for variable hyp to logreg, which implements multiple imputation by logistic regression.\nAn up-to-date overview of the methods in mice can be found by\nmethods(mice)\n\n [1] mice.impute.2l.bin              mice.impute.2l.lmer            \n [3] mice.impute.2l.norm             mice.impute.2l.pan             \n [5] mice.impute.2lonly.mean         mice.impute.2lonly.norm        \n [7] mice.impute.2lonly.pmm          mice.impute.cart               \n [9] mice.impute.jomoImpute          mice.impute.lasso.logreg       \n[11] mice.impute.lasso.norm          mice.impute.lasso.select.logreg\n[13] mice.impute.lasso.select.norm   mice.impute.lda                \n[15] mice.impute.logreg              mice.impute.logreg.boot        \n[17] mice.impute.mean                mice.impute.midastouch         \n[19] mice.impute.mnar.logreg         mice.impute.mnar.norm          \n[21] mice.impute.mpmm                mice.impute.norm               \n[23] mice.impute.norm.boot           mice.impute.norm.nob           \n[25] mice.impute.norm.predict        mice.impute.panImpute          \n[27] mice.impute.passive             mice.impute.pmm                \n[29] mice.impute.polr                mice.impute.polyreg            \n[31] mice.impute.quadratic           mice.impute.rf                 \n[33] mice.impute.ri                  mice.impute.sample             \n[35] mice.mids                       mice.theme                     \nsee '?methods' for accessing help and source code\nLet us change the imputation method for bmi to Bayesian normal linear regression imputation\nmeth &lt;- make.method(nhanes2)\nmeth\n\n     age      bmi      hyp      chl \n      \"\"    \"pmm\" \"logreg\"    \"pmm\" \n\nmeth[\"bmi\"] &lt;- \"norm\"\nmeth\n\n     age      bmi      hyp      chl \n      \"\"   \"norm\" \"logreg\"    \"pmm\"\nThe new methods vector can be visualized with the predictor matrix by\nplot_pred(pred, method = meth)\nNow, we can run the imputations again.\nimp &lt;- mice(nhanes2, meth = meth, print = FALSE)\nand we may again plot trace lines to study convergence\nplot_trace(imp)\n5. Extend the number of iterations\nThough using just five iterations (the default) often works well in practice, we need to extend the number of iterations of the mice algorithm to confirm that there is no trend and that the trace lines intermingle well. We can increase the number of iterations to 40 by running 35 additional iterations using the mice.mids() function.\nimp40 &lt;- mice.mids(imp, maxit = 35, print = FALSE)\nplot_trace(imp40)\n6. Further diagnostic checking.\nGenerally, one would prefer for the imputed data to be plausible values, i.e. values that could have been observed if they had not been missing. In order to form an idea about plausibility, one may check the imputations and compare them against the observed values. If we are willing to assume that the data are missing completely at random (MCAR), then the imputations should have the same distribution as the observed data. In general, distributions may be different because the missing data are MAR (or even MNAR). However, very large discrepancies need to be screened. Let us plot the observed and imputed data of chl by\nggmice(imp, aes(x = .imp, y = chl)) + \n  geom_jitter(width = .1)\nThe convention is to plot observed data in blue and the imputed data in red. The figure graphs the data values of chl before and after imputation. Since the PMM method draws imputations from the observed data, imputed values have the same gaps as in the observed data, and are always within the range of the observed data. The figure indicates that the distributions of the imputed and the observed values are similar. The observed data have a particular feature that, for some reason, the data cluster around the value of 187. The imputations reflect this feature, and are close to the data. Under MCAR, univariate distributions of the observed and imputed data are expected to be identical. Under MAR, they can be different, both in location and spread, but their multivariate distribution is assumed to be identical. There are many other ways to look at the imputed data.\nThe following commands create a the graph from the previous step for bmi.\npurrr::map(names(imp$data), ~{\n  ggmice(imp, aes(x = .imp, y = .data[[.x]])) + \n    geom_jitter(width = .1)\n})\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\nRemember that bmi was imputed by Bayesian linear regression and (the range of) imputed values may therefore be different than observed values.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Geavanceerde Data Technieken</span>"
    ]
  },
  {
    "objectID": "meeting6.html#for-fun",
    "href": "meeting6.html#for-fun",
    "title": "Geavanceerde Data Technieken",
    "section": "For fun",
    "text": "For fun\nWhat you shouldn’t do with passive imputation!\nNever set all relations fixed. You will remain with the starting values and waste your computer’s energy (and your own).\n\nmeth &lt;- make.method(boys)\npred &lt;- make.predictorMatrix(boys)\nmeth[\"bmi\"] &lt;- \"~ I(wgt / (hgt / 100)^2)\"\nmeth[\"wgt\"] &lt;- \"~ I(bmi * (hgt / 100)^2)\"\nmeth[\"hgt\"] &lt;- \"~ I(sqrt(wgt / bmi) * 100)\"\npred[c(\"bmi\", \"wgt\", \"hgt\"), ] &lt;- 0\nimp.path &lt;- mice(boys, \n                 meth=meth, \n                 pred=pred, \n                 seed=123)\n\n\n iter imp variable\n  1   1  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  1   2  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  1   3  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  1   4  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  1   5  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  2   1  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  2   2  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  2   3  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  2   4  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  2   5  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  3   1  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  3   2  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  3   3  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  3   4  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  3   5  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  4   1  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  4   2  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  4   3  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  4   4  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  4   5  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  5   1  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  5   2  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  5   3  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  5   4  hc  gen  phb  tv  reg  hgt  wgt  bmi\n  5   5  hc  gen  phb  tv  reg  hgt  wgt  bmi\n\nplot_trace(imp.path, c(\"hgt\", \"wgt\", \"bmi\"))\n\n\n\n\n\n\n\n\nWe named the mids object imp.path, because the nonconvergence is pathological in this example!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Geavanceerde Data Technieken</span>"
    ]
  },
  {
    "objectID": "meeting7.html",
    "href": "meeting7.html",
    "title": "Data Visualisatie",
    "section": "",
    "text": "Practical",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Visualisatie</span>"
    ]
  },
  {
    "objectID": "meeting7.html#practical",
    "href": "meeting7.html#practical",
    "title": "Data Visualisatie",
    "section": "",
    "text": "Exercises\n\nThe following packages are required for this practical:\n\n\nCode\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(mice)\nlibrary(ggplot2)\n\n\nand if you’d like the same results as I have obtained, you can fix the random seed\n\n\nCode\nset.seed(123)\n\n\n\n\nFunction plot() is the core plotting function in R. Find out more about plot(): Try both the help in the help-pane and ?plot in the console. Look at the examples by running example(plot).\n\nThe help tells you all about a functions arguments (the input you can specify), as well as the element the function returns to the Global Environment. There are strict rules for publishing packages in R. For your packages to appear on the Comprehensive R Archive Network (CRAN), a rigorous series of checks have to be passed. As a result, all user-level components (functions, datasets, elements) that are published, have an acompanying documentation that elaborates how the function should be used, what can be expected, or what type of information a data set contains. Help files often contain example code that can be run to demonstrate the workings.\n\n\nCode\n?plot\n\n\nHelp on topic 'plot' was found in the following packages:\n\n  Package               Library\n  graphics              /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library\n  base                  /Library/Frameworks/R.framework/Resources/library\n\n\nUsing the first match ...\n\n\nCode\nexample(plot)\n\n\n\nplot&gt; Speed &lt;- cars$speed\n\nplot&gt; Distance &lt;- cars$dist\n\nplot&gt; plot(Speed, Distance, panel.first = grid(8, 8),\nplot+      pch = 0, cex = 1.2, col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nplot&gt; plot(Speed, Distance,\nplot+      panel.first = lines(stats::lowess(Speed, Distance), lty = \"dashed\"),\nplot+      pch = 0, cex = 1.2, col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nplot&gt; ## Show the different plot types\nplot&gt; x &lt;- 0:12\n\nplot&gt; y &lt;- sin(pi/5 * x)\n\nplot&gt; op &lt;- par(mfrow = c(3,3), mar = .1+ c(2,2,3,1))\n\nplot&gt; for (tp in c(\"p\",\"l\",\"b\",  \"c\",\"o\",\"h\",  \"s\",\"S\",\"n\")) {\nplot+    plot(y ~ x, type = tp, main = paste0(\"plot(*, type = \\\"\", tp, \"\\\")\"))\nplot+    if(tp == \"S\") {\nplot+       lines(x, y, type = \"s\", col = \"red\", lty = 2)\nplot+       mtext(\"lines(*, type = \\\"s\\\", ...)\", col = \"red\", cex = 0.8)\nplot+    }\nplot+ }\n\n\n\n\n\n\n\n\n\n\nplot&gt; par(op)\n\nplot&gt; ##--- Log-Log Plot  with  custom axes\nplot&gt; lx &lt;- seq(1, 5, length.out = 41)\n\nplot&gt; yl &lt;- expression(e^{-frac(1,2) * {log[10](x)}^2})\n\nplot&gt; y &lt;- exp(-.5*lx^2)\n\nplot&gt; op &lt;- par(mfrow = c(2,1), mar = par(\"mar\")-c(1,0,2,0), mgp = c(2, .7, 0))\n\nplot&gt; plot(10^lx, y, log = \"xy\", type = \"l\", col = \"purple\",\nplot+      main = \"Log-Log plot\", ylab = yl, xlab = \"x\")\n\n\n\nplot&gt; plot(10^lx, y, log = \"xy\", type = \"o\", pch = \".\", col = \"forestgreen\",\nplot+      main = \"Log-Log plot with custom axes\", ylab = yl, xlab = \"x\",\nplot+      axes = FALSE, frame.plot = TRUE)\n\n\n\n\n\n\n\n\n\n\nplot&gt; my.at &lt;- 10^(1:5)\n\nplot&gt; axis(1, at = my.at, labels = formatC(my.at, format = \"fg\"))\n\nplot&gt; e.y &lt;- -5:-1 ; at.y &lt;- 10^e.y\n\nplot&gt; axis(2, at = at.y, col.axis = \"red\", las = 1,\nplot+      labels = as.expression(lapply(e.y, function(E) bquote(10^.(E)))))\n\nplot&gt; par(op)\n\n\nThere are many more functions that can plot specific types of plots. For example, function hist() plots histograms, but falls back on the basic plot() function. Package ggplot2 is an excellent package to use for more complex plots. Pretty much any type of plot can be made in R. All ggplot2 documentation can be found at ggplot2.tidyverse.org\n\n\nCreate a scatterplot between age and bmi in the mice::boys data set\n\nWith the standard plotting device in R:\n\n\nCode\nmice::boys %$% plot(bmi ~ age)\n\n\n\n\n\n\n\n\n\nor, with ggplot2:\n\n\nCode\np &lt;- ggplot(mice::boys, aes(age, bmi))\np + geom_point()\n\n\nWarning: Removed 21 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nPackage ggplot2 offers far greater flexibility in data visualization than the standard plotting devices in R. However, it has its own language, which allows you to easily expand graphs with additional commands. To make these expansions or layers clearly visible, it is advisable to use the plotting language conventions. For example,\n\n\nCode\nmice::boys %&gt;% \n  ggplot(aes(age, bmi)) +\n  geom_point()\n\n\nwould yield the same plot as\n\n\nCode\nggplot(mice::boys, aes(age, bmi)) + geom_point()\n\n\nbut the latter style may be less informative, especially if more customization takes place and if you share your code with others.\n\n\nNow recreate the plot with the following specifications:\n\n\nIf bmi &lt; 18.5 use color = \"light blue\"\nIf bmi &gt; 18.5 & bmi &lt; 25 use color = \"light green\"\nIf bmi &gt; 25 & bmi &lt; 30 use color = \"orange\"\nIf bmi &gt; 30 use color = \"red\"\n\nHint: it may help to expand the data set with a new variable.\nIt may be easier to create a new variable that creates the specified categories. We can use the cut() function to do this quickly\n\n\nCode\nboys2 &lt;- \n  boys %&gt;%\n  mutate(class = cut(x = bmi, breaks = c(0, 18.5, 25, 30, Inf),\n                    labels = c(\"underweight\",\n                               \"healthy\",\n                               \"overweight\",\n                               \"obese\")))\n\n\nby specifying the boundaries of the intervals. In this case we obtain 4 intervals: 0-18.5, 18.5-25, 25-30 and 30-Inf. We used the %&gt;% pipe to work with bmi directly. Alternatively, we could have done this without a pipe:\n\n\nCode\nboys3 &lt;- boys\nboys3$class &lt;- cut(boys$bmi, c(0, 18.5, 25, 30, Inf), \n                   labels = c(\"underweight\",\n                              \"healthy\",\n                              \"overweight\",\n                              \"obese\"))\n\n\nto obtain the same result.\nWith the standard plotting device in R we can now specify:\n\n\nCode\nplot(bmi ~ age, subset = class == \"underweight\", col = \"lightblue\", data = boys2, \n     ylim = c(10, 35), xlim = c(0, 25))\npoints(bmi ~ age, subset = class == \"healthy\", col = \"lightgreen\", data = boys2)\npoints(bmi ~ age, subset = class == \"overweight\", col = \"orange\", data = boys2)\npoints(bmi ~ age, subset = class == \"obese\", col = \"red\", data = boys2)\n\n\n\n\n\n\n\n\n\nand with ggplot2 we can call\n\n\nCode\nboys2 %&gt;%\n  ggplot() +\n  geom_point(aes(age, bmi, col = class))\n\n\nWarning: Removed 21 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAlthough the different classifications have different colours, the colours are not conform the specifications of this exercise. We can manually override this:\n\n\nCode\nboys2 %&gt;%\n  ggplot() +\n  geom_point(aes(age, bmi, col = class)) +\n  scale_color_manual(values = c(\"lightblue\", \"lightgreen\", \"orange\", \"red\"))\n\n\nWarning: Removed 21 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBecause there are missing values, ggplot2 displays a warning message. If we would like to not consider the missing values when plotting, we can simply exclude the NAs by using a filter():\n\n\nCode\nboys2 %&gt;% \n  filter(!is.na(class)) %&gt;%\n  ggplot() +\n  geom_point(aes(age, bmi, col = class)) +\n  scale_color_manual(values = c(\"lightblue\", \"lightgreen\", \"orange\", \"red\"))\n\n\n\n\n\n\n\n\n\nSpecifying a filter on the feature class is sufficient: age has no missings and the missings in class directly correspond to missing values on bmi. Filtering on bmi would therefore yield an identical plot.\n\n\nCreate a histogram for age in the boys data set\n\nWith the standard plotting device in R:\n\n\nCode\nboys %$%\n  hist(age, breaks = 50)\n\n\n\n\n\n\n\n\n\nThe breaks = 50 overrides the default breaks between the bars. By default the plot would be\n\n\nCode\nboys %$%\n  hist(age)\n\n\n\n\n\n\n\n\n\nUsing a pipe is a nice approach for this plot because it inherits the names of the objects we aim to plot. Without the pipe we might need to adjust the main title for the histogram:\n\n\nCode\nhist(boys$age, breaks = 50)\n\n\n\n\n\n\n\n\n\nWith ggplot2:\n\n\nCode\nboys %&gt;%\n  ggplot() + \n  geom_histogram(aes(age), binwidth = .4)\n\n\n\n\n\n\n\n\n\nPlease note that the plots from geom_histogram() and hist use different calculations for the bars (bins) and hence may look slightly different.\n\n\nCreate a bar chart for reg in the boys data set With a standard plotting device in R:\n\n\n\nCode\nboys %$%\n  table(reg) %&gt;%\n  barplot()\n\n\n\n\n\n\n\n\n\nWith ggplot2:\n\n\nCode\nboys %&gt;%\n  ggplot() + \n  geom_bar(aes(reg))\n\n\n\n\n\n\n\n\n\nNote that geom_bar by default plots the NA’s, while barplot() omits the NA’s without warning. If we would not like to plot the NAs, then a simple filter() (see exercise 2) on the boys data is efficient.\n\n\nCreate a box plot for hgt with different boxes for reg in the boys data set With a standard plotting device in R:\n\n\n\nCode\nboys %$%\n  boxplot(hgt ~ reg)\n\n\n\n\n\n\n\n\n\nWith ggplot2:\n\n\nCode\nboys %&gt;%\n  ggplot(aes(reg, hgt)) +\n  geom_boxplot()\n\n\nWarning: Removed 20 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nCode\n# This does not work!\n#boys %$%\n#  ggplot(aes(reg, hgt)) +\n#  geom_boxplot()\n\n\n\n\nCreate a density plot for age with different curves for boys from the city and boys from rural areas (!city). With a standard plotting device in R:\n\n\n\nCode\nd1 &lt;- boys %&gt;%\n  subset(reg == \"city\") %$%\n  density(age)\nd2 &lt;- boys %&gt;%\n  subset(reg != \"city\") %$% \n  density(age)\n\nplot(d1, col = \"red\", ylim = c(0, .08)) \nlines(d2, col = \"blue\") \n\n\n\n\n\n\n\n\n\nThe above plot can also be generated without pipes, but results in an ugly main title. You may edit the title via the main argument in the plot() function.\n\n\nCode\nplot(density(boys$age[!is.na(boys$reg) & boys$reg == \"city\"]), \n     col = \"red\", \n     ylim = c(0, .08))\nlines(density(boys$age[!is.na(boys$reg) & boys$reg != \"city\"]), \n      col = \"blue\")\n\n\n\n\n\n\n\n\n\nWith ggplot2 everything looks much nicer:\n\n\nCode\nboys %&gt;%\n  mutate(area = ifelse(reg == \"city\", \"city\", \"rural\")) %&gt;%\n  filter(!is.na(area)) %&gt;%\n  ggplot(aes(age, fill = area)) +\n  geom_density(alpha = .3) # some transparency\n\n\n\n\n\n\n\n\n\n\n\nCreate a diverging bar chart for hgt in the boys data set, that displays for every age year that year’s mean height in deviations from the overall average hgt\n\nLet’s not make things too complicated and just focus on ggplot2:\n\n\nCode\nboys %&gt;%\n  mutate(Hgt = hgt - mean(hgt, na.rm = TRUE),\n         Age = cut(age, 0:22, labels = 0:21)) %&gt;%\n  group_by(Age) %&gt;%\n  summarize(Hgt = mean(Hgt, na.rm = TRUE)) %&gt;% \n  mutate(Diff = cut(Hgt, c(-Inf, 0, Inf),\n                    labels = c(\"Below Average\", \"Above Average\"))) %&gt;%\n  ggplot(aes(x = Age, y = Hgt, fill = Diff)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nWe can clearly see that the average height in the group is reached just before age 7.\nThe group_by() and summarize() function are advanced dplyr functions used to return the mean() of deviation Hgt for every group in Age. For example, if we would like the mean and sd of height hgt for every region reg in the boys data, we could call:\n\n\nCode\nboys %&gt;%\n  group_by(reg) %&gt;% \n  summarize(mean_hgt = mean(hgt, na.rm = TRUE), \n            sd_hgt   = sd(hgt, na.rm = TRUE))\n\n\n# A tibble: 6 × 3\n  reg   mean_hgt sd_hgt\n  &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 north    152.    43.8\n2 east     134.    43.2\n3 west     130.    48.0\n4 south    128.    46.3\n5 city     126.    46.9\n6 &lt;NA&gt;      73.0   29.3\n\n\nThe na.rm argument ensures that the mean and sd of only the observed values in each category are used.\n\n\nBonus: Change the overall appearance of the plot you have created for exercise 7 using an available theme. Customize the theme (using theme()) in any way you like.\n\nFor example:\n\n\nCode\nboys %&gt;%\n  mutate(Hgt = hgt - mean(hgt, na.rm = TRUE),\n         Age = cut(age, 0:22, labels = 0:21)) %&gt;%\n  group_by(Age) %&gt;%\n  summarize(Hgt = mean(Hgt, na.rm = TRUE)) %&gt;% \n  mutate(Diff = cut(Hgt, c(-Inf, 0, Inf),\n                    labels = c(\"Below Average\", \"Above Average\"))) %&gt;%\n  ggplot(aes(x = Age, y = Hgt, fill = Diff)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip() + \n  theme_classic() +\n  theme(panel.grid.major = element_line(colour = \"darkgreen\"), \n        legend.position = \"bottom\",\n        legend.box.background = element_rect(),\n        legend.title = element_text(face = \"bold\")) \n\n\n\n\n\n\n\n\n\n\nEnd of Practical\n\n\n\nUseful References\nThe ggplot2 reference page",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Visualisatie</span>"
    ]
  },
  {
    "objectID": "meeting8.html",
    "href": "meeting8.html",
    "title": "Ontwikkelen en Programmeren in R",
    "section": "",
    "text": "R-packages\nIt is much easier to create, manage and co-develop an R-package when you incorporate it into a distributed version control system like Git. The extension to a software development hosting service like GitHub is then a natural one. Although there are other procedures, devops systems and hosting services that may lend itself for package development, we outline the workflow with Git and GitHub. We also assume that you have RStudio installed.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ontwikkelen en Programmeren in R</span>"
    ]
  },
  {
    "objectID": "meeting8.html#r-packages",
    "href": "meeting8.html#r-packages",
    "title": "Ontwikkelen en Programmeren in R",
    "section": "",
    "text": "Recap on Git\nGit is a free and open source version control system for text files. It can handle extensive change logging for you, no matter the size of the project. Git is fast and efficient, but its effectiveness depends also on the frequency you instruct it to log your project’s changes.\nYou can see Git as a blank canvas that starts at a certain point in time. Every time you (or others) instruct Git to log any changes that have been made, Git adds the changes that are made to this canvas. We call the changes to the canvas commits. With every commit an extensive log is created that includes at least the following information:\n\nthe changes made\nwho made the changes\nmetadata\na small piece of text that describe the changes made\n\nThe difference between two commits - or the changes between them - are called diffs.\nIf you’d like to know much more about Git, this online book is a very good resource. If you’d like to practice with the command line interface use this webpage for a quick course. This book covers pretty much everything you need to marry Git and R.\n\n\nWhy GitHub\nGitHub is the social and user interface to Git that allows you to work in repositories. These repositories can be seen as project folders in which you publish your work, but you can also use them as test sites for development, testing, etcetera. There is a distinction between private repositories (only for you and those you grant access) and public repositories (visible for everyone).\nYour public repositories can be viewed and forked by everyone. Forking is when other people create a copy of your repository on their own account. This allows them to work on a repository without affecting the master. You can also do this yourself, but then the process is called branching instead of forking. If you create a copy of a repository that is offline, the process is called cloning.\nGitHub’s ability to branch, fork and clone is very useful as it allows other people and yourself to experiment on (the code in) a repository before any definitive changes are merged with the master. If you’re working in a forked repository, you can submit a pull request to the repository collaborators to accept (or reject) any suggested changes.\nFor now, this may be confusing, but I hope you recognize the benefits GitHub can have on the process of development and bug-fixing. For example, the most up-to-date version of the mice package in R can be directly installed from the mice repository with the following code:\n\ninstall.packages(\"devtools\")\ndevtools::install_github(repo = \"stefvanbuuren/mice\")\n\nYou can see that this process requires package devtools that expands the R functionality with essential development tools. Loading packages in R directly from their respective GitHub repositories, allows you to obtain the latest - often improved and less buggy - iteration of that software even before it is published on CRAN.\n\n\nInstall RStudio\nInstall RStudio from Posit’s website. The free edition will suffice.\n\n\nSome R-code\nIn order to demonstrate the creation of an R-package, we will identify some odd behaviour by R:\n\nlibrary(dplyr)\nc(0.5, 1.5, 2.5, 3.5) %&gt;% round()\n\n[1] 0 2 2 4\n\n\nWe can see that R rounds - by default - the number 1.5 to integer 2 and the number 2.5 also to integer 2. The reason for this behaviour is the IEC 60559 standard where a 5 is expected to be rounded to the even digit.\nIf we’d like to round up to the next integer, we can easily define the following function:\n\nrounder &lt;- function(x){\n  diff &lt;- x - floor(x)\n  out &lt;- x %&gt;% ceiling()\n  out[diff &lt; .5] &lt;- floor(x)[diff &lt; .5]\n  return(out)\n}\n\nwhere the vector c(0.5, 1.5, 2.5, 3.5) is rounded up to the next integer\n\nc(0.5, 1.5, 2.5, 3.5) %&gt;% rounder()\n\n[1] 1 2 3 4\n\n\nand where the vector c(0.49, 1.49, 2.49, 3.49) is rounded down to the previous integer\n\nc(0.49, 1.49, 2.49, 3.49) %&gt;% rounder()\n\n[1] 0 1 2 3",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ontwikkelen en Programmeren in R</span>"
    ]
  },
  {
    "objectID": "meeting8.html#create-r-package-roundr",
    "href": "meeting8.html#create-r-package-roundr",
    "title": "Ontwikkelen en Programmeren in R",
    "section": "Create R-package roundR",
    "text": "Create R-package roundR\nThe goal of this document is to create the code for the rounder() function into a stand-alone R-package with its referenceable Digital Object Identifier\n\nSteps in creating an R-package\n\nPackages and sources needed\nWe need the following packages to help us with building, testing and maintaining our package:\n\nlibrary(devtools) # development tools\nlibrary(usethis)  # automated package and project setup\nlibrary(testthat) # unit testing\n\n\n\nPreparing the package structure\nWe need a location for our R-package. The simplest approach to creating the skeleton for an R-package is to use RStudio. The following gif outlines this procedure:\n\n\n\nWe have now created the necessary structure for an R-package. We can see this structure and the generated package files in the File Pane in RStudio.\n\n\n\nThe R subfolder contains all the R-code for your package and the man folder contains all the corresponding R manuals. By default, for a new R-package generated by RStudio the file hello.R is generated.\n\n\n\nAs a matter of fact, the skeleton R-package is already a fully functional R-package. Try installing the package in the build pane.\n\n\n\n\n\nAdd the description\nOpen the file DESCRIPTION from the file pane. The following window opens:\n\n\n\n\nNow, replace the contents of the DESCRIPTION file with\n\nPackage: roundR\nType: Package\nTitle: Round Numeric Values to the Nearest Integer\nVersion: 0.1.0\nAuthor: Gerko Vink and Hanne Oberman\nMaintainer: Gerko Vink &lt;G.Vink@uu.nl&gt;\nDescription: In R the default choice for rounding follows the IEC 60559 standard where a 5 is expected to be rounded to the even digit. This package offers alternative functionality to round to the closest integer. \nLicense: No LiCeNsE YeT\nEncoding: UTF-8\nLazyData: true\n\nThe DESCRIPTION file governs the information about the licence, authors, contributors, maintainers, etcetera. The argument lazyData: true indicates that data sets should be lazily loaded. This means that data will not occupy any memory unless it is needed. This is a good argument to have as default.\nWe also need to set a license. Running the following code from package usethis will write a permissive MIT license to the description file\n\nusethis::use_mit_license()\n\nDon’t forget to save the updated DESCRIPTION file and change our names to your name.\n\n\nAdd the functional code\nNow it is time to extend the package with the functionality we promised in our updated DESCRIPTION. To do so, we start a new file names rounder.R by either manually creating it in the R sub folder, or by running the following code evaluation\n\nusethis::use_r(\"rounder\")\n\nThe use_r() function from the usethis package is very convenient, because it creates the necessary file in the correct location and opens the file in the editor pane.\n\n\n\n\nNow that we have created the file for our functional code, we can start building the code file. The most flexible approach to creating and maintaining a package is to use roxygen2. The roxygen2 package is a convenient in-line documentation convention that generates your Rd documentation, NAMESPACE file, and much more for you. Remember that man folder in our package root? That contains all documentation files. However, you can imagine if we have two seperate locations for our R-code and our Rd help files, that at some point the code and documentation might get out of sync. For example, if we update the code, but forget to reflect changes in our manual, the usability of our package may be at stake and documentation to end-users might get confusing. Most of all, it would be a lot of work for us to maintain multiple linked files in multiple locations. roxygen2 solves this for us by extracting the documentation from our R-code file. The only thing we need to do is maintain a single file.\nTo start with roxygen2 in our package, we need to instruct the package to use roxygen2 from now on:\n\nusethis::use_roxygen_md()\n\nThe above call will add the following lines to our DESCRIPTION file:\n\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\n\nWe mentioned before that the roxygen2 engine expects the function documentation in the same file as the function code. A good starting point for that documentation is the following block:\n\n#' A short description of your function\n#' \n#' @param x The first argument to be governed by the letter x.\n#' @param y The second argument to denoted by the letter y.\n#' @returns a short description of the expected return.\n#' @examples\n#' examplecode 1\n#' examplecode 2\n\nIn R, when you have executed usethis::use_r() and have filled in your R code, you can run Code &gt; Insert Roxygen Skeleton to automatically create the relevant roxygen documentation. For our function rounder() - with some customization and examples, this could result in the following rounder.R code file\n\n#' Round to the nearest integer\n#'\n#'Function \\code{\\link{base::round}} rounds - by default -  the number `1.5` to\n#'integer `2` and the number `2.5` also to integer `2`. The reason for this\n#'behaviour is the IEC 60559 standard where a 5 is expected to be rounded to the\n#'even digit. This function provides an integer rounding alternative to\n#'\\code{\\link{base::round}}.\n#'\n#' @param x A numeric element or vector to round to the nearest integer\n#' @returns An integer element or vector\n#' @author Gerko Vink \\email{g.vink@uu.nl} and Hanne Oberman \\email{h.i.oberman@uu.nl}\n#' @examples\n#' # rounds weirdly\n#' c(0.5, 1.5, 2.5, 3.5) %&gt;% round()\n#' # rounds correctly\n#' c(0.5, 1.5, 2.5, 3.5) %&gt;% rounder()\n#'\nrounder &lt;- function(x) {\n  diff &lt;- x - floor(x)\n  out &lt;- x %&gt;% ceiling()\n  out[diff &lt; .5] &lt;- floor(x)[diff &lt; .5]\n  return(out)\n}\n\nYou can copy the above code chunk to your rounder.R file. A good source to find inspiration for writing roxygen2 documentation is the roxygen2 reference page.\nNow that we have a working rounder.R file with documentation included, we can build the documentation. A good wrapper function to build all documentation in your package is the following code evaluation:\n\ndevtools::document()\n\n\n\n\n\nThe document() function from the devtools package will build all documentation for all files that use roxygen2 and it will build the NAMESPACE of your package accordingly. If you encounter the following message:\n\nSkipping NAMESPACE\n✖ It already exists and was not generated by roxygen2. \n\njust remove the NAMESPACE file and re-run the document() function.\nWe can now remove the R/hello.R and man/hello.Rd files as they are not supposed to be part of our package\n\n\nBuilding and checking\nLet’s check the functionality of our package.\n\n\n\n\nWe can see under build &gt; check that our current package yields 1 error, 1 warning and 1 note.\n\nError\n\n❯ checking examples ... ERROR\n  Running examples in ‘roundR-Ex.R’ failed\n  The error most likely occurred in:\n\n    ...\n  \n  &gt; c(0.5, 1.5, 2.5, 3.5) %&gt;% round()\n  Error in c(0.5, 1.5, 2.5, 3.5) %&gt;% round() : \n    could not find function \"%&gt;%\"\n  Execution halted\n\nThe error stems from the examples in our documentation. The examples use the binary function %&gt;% from package magrittr, but we did not load that package in the example. Remember that these examples are self-contained and that any dependent packages need to be explicitly loaded via library() for the code to run. Just like any other R instance. Simply adding library(magrittr) to the example code will solve the issue.\nAdd library(magrittr) to the example code:\n\n#' @examples\n#' library(magrittr)\n#' # rounds weirdly\n#' c(0.5, 1.5, 2.5, 3.5) %&gt;% round()\n#' # rounds correctly\n#' c(0.5, 1.5, 2.5, 3.5) %&gt;% rounder()\n\n\n\nWarning\n\n❯ checking Rd cross-references ... WARNING\n  Missing link or links in documentation object 'rounder.Rd':\n    ‘base::round’\n  \n  See section 'Cross-references' in the 'Writing R Extensions' manual.\n\nThe error stems from the crossreference we attempted in our documentation. The proper way to refer to function round() from package base is not with \\link{base::round}, but with \\link[base]{round} following the structure \\link[package]{function}. We could have opted for not referencing, or linking the round() function at all, but this would not align with open and inclusive development conventions.\nCorrect the faulty crossreferences in the documentation:\n\n#'Function \\code{\\link[base]{round}} rounds - by default -  the number `1.5` to\n#'integer `2` and the number `2.5` also to integer `2`. The reason for this\n#'behaviour is the IEC 60559 standard where a 5 is expected to be rounded to the\n#'even digit. This function provides an integer rounding alternative to\n#'\\code{\\link[base]{round}}.\n\n\n\nNote\n\n❯ checking R code for possible problems ... NOTE\n  rounder: no visible global function definition for ‘%&gt;%’\n  Undefined global functions or variables:\n    %&gt;%\n\nWe use function %&gt;% from package magrittr, but we neglected to make explicit that this function should have been imported from package magrittr. In other words, R needs to know that our package roundR would depend on package magrittr for its functionality to work.\nWe can fix this by runnin the following usethis evaluation in the console:\n\nusethis::use_import_from(\"magrittr\", \"%&gt;%\")\n\nWhen asked\n\n`use_import_from()` requires package-level documentation.\nWould you like to add it now?\n\n1: For sure\n2: Not now\n3: No way\n\nchoose the fun option that would add it (i.e. For Sure, Yes, Absolutely, etc). These options change every time you re-run the function code, so read it carefully!\nOnce you have selected the correct option, we can re-run the CHECK. You will find that there still persists an error in the example:\n\n❯ checking examples ... ERROR\n  Running examples in ‘roundR-Ex.R’ failed\n  The error most likely occurred in:\n  \n  ...\n  \n  &gt; c(0.5, 1.5, 2.5, 3.5) %&gt;% rounder()\n  Error in rounder(.) : could not find function \"rounder\"\n  Calls: %&gt;%\n  Execution halted\n\nOur package CHECK cannot find function rounder(). That may seem weird, since it is the only function in our package. The thing is - we have not explicitly told roxygen2 to export our function, i.e. to make our function available outside of the package namespace. Simply adding @export to the rounder.R file would solve this error:\n\n...\n#' @author Gerko Vink \\email{g.vink@uu.nl} and Hanne Oberman \\email{h.i.oberman@uu.nl}\n#' @export\n#' @examples\n#' library(magrittr)\n...\n\nTry re-running the CHECK to see if you hit three green check marks (NO errors, warnings and notes). If all is well, you’ll see:\n\n── R CMD check results ────────────────────────────────────────── roundR 0.1.0 ────\nDuration: 6.6s\n\n0 errors ✔ | 0 warnings ✔ | 0 notes ✔\n\nR CMD check succeeded\n\n\n\n\nIncreasing the version\nNow that we have a working package with a succesfull R CMD check, we might think about updating the version of the package. After all, a lot has changed since the last version got defined at the start of our development journey.\nThe easiest means to increasing the version to 0.2.0 (indicating a minor update) is to use\n\nusethis::use_version()\n\nYou will be presented with something like:\n\n✔ Setting active project to '/Users/gerko/surfdrive/Werk/GitHub/roundR/roundR'\nCurrent version is 0.1.1.\nWhat should the new version be? (0 to exit) \n\n1: major --&gt; 1.0.0\n2: minor --&gt; 0.2.0\n3: patch --&gt; 0.1.2\n4:   dev --&gt; 0.1.1.9000\n\nSelection: 2\n✔ Setting Version field in DESCRIPTION to '0.2.0'\nThere is 1 uncommitted file:\n* 'DESCRIPTION'\nIs it ok to commit it?\n\n1: For sure\n2: Negative\n3: Nope\n\nSelection: 1\n✔ Adding files\n✔ Making a commit with message 'Increment version number to 0.2.0'\n\nThe question Is it ok to commit it? is related to Git. Please click to commit the version increase. For reasons of brevity and simplicity, we will leave a thorough discussion of incremental Git commits for now and demonstrate to use of Git and GitHub at the end of this walkthrough.\n\n\nAdd tests\nThe next step for a mature package is to include tests. Every function should have functional tests. The testthat package is geared to that. Make sure that you have the rounder.R file open in the Source pane and run:\n\nusethis::use_test()\n\nThe proper structure for test files has now been created:\n\n✔ Adding 'testthat' to Suggests field in DESCRIPTION\n✔ Setting Config/testthat/edition field in DESCRIPTION to '3'\n✔ Creating 'tests/testthat/'\n✔ Writing 'tests/testthat.R'\n✔ Writing 'tests/testthat/test-rounder.R'\n• Modify 'tests/testthat/test-rounder.R'\n\nYou are asked to modify the tests/testthat/test-rounder.R file. Replace the example test with:\n\ntest_that(\"rounder works\", {\n  A &lt;- c(0.5, 1.5, 2.5, 3.5) %&gt;% rounder()\n  B &lt;- c(0.49, 1.49, 2.49, 3.49) %&gt;% rounder()\n  expect_equal(A, c(1, 2, 3, 4))\n  expect_equal(B, c(0, 1, 2, 3))\n})\n\ntest_that(\"rounder yields different results than round\", {\n  vec1 &lt;- c(0.5, 1.5, 2.5, 3.5)\n  vec2 &lt;- c(0.499999999999999999995,\n            1.499999999999999999995,\n            2.499999999999999999995,\n            3.499999999999999999995)\n  A &lt;- vec1 %&gt;% rounder()\n  B &lt;- vec1 %&gt;% round()\n  C &lt;- vec2 %&gt;% rounder()\n  D &lt;- vec2 %&gt;% round()\n  expect_false(identical(A, B))\n  expect_false(identical(C, D))\n})\n\nClick the Test button in the build pane:\n\n\n\nAll test should pass, meaning that your rounder() function yields correct results (test 1) that differ fundamentally from the results obtained with round() (test 2).\nIf test would fail, you’d be notified. For example\n\ntest_that(\"rounder works\", {\n  A &lt;- c(0.5, 1.5, 2.5, 3.5) %&gt;% rounder()\n  expect_equal(A, c(4, 3, 2, 1))\n  })\n\n── Failure: rounder works ──────────────────────────────────────────────────────\n`A` not equal to c(4, 3, 2, 1).\n4/4 mismatches (average diff: 2)\n[1] 1 - 4 == -3\n[2] 2 - 3 == -1\n[3] 3 - 2 ==  1\n[4] 4 - 1 ==  3\n\n\nError:\n! Test failed\n\n\nFortunately, our test all passed. Now rerun the R CMD check. If all is well you’ll receive confirmation of a successful check.\n\n\nPublishing to GitHub\nThis section assumes that you are logged into your GitHub account. If you have trouble realizing this, GitHub has a great step-by-step walkthrough.\nLet’s publish our R-package to GitHub. To do so, we need to perform two steps. First, we must log (commit) our changes to the Git distributed version control system. This stores the file changes to our own machine. Next we must link our local Git to a remote online repository on GitHub. Luckily, with GitHub Desktop, we can perform all these steps in a single window interface.\nLet’s start by adding our R-package to GitHub desktop. Remember that we already started the package in RStudio as a Git repository, so we only have to point GitHub desktop to the correct directory.\n\n\n\nNext, we commit the changes. This means that we save the state of files for a moment in time, so that we can always revert to that state and see how the files changed with respect to the previous state.\n\n\n\nNaturally, you would not only do this at the start (when RStudio created the Git repository) and end (when we have a working package), but at regular and informative intervals. For example, when you add a function, a test, a help file, a license, etcetera.\nNow that we have commited our package, we can publish it on GitHub.\n\n\n\nTry your online GitHub repositories at https://github.com. You will see your package there and that the license is automatically recognized. You will also see that you are in the main branch. By default, that will be the live version of your package. Now that your package is live, it would be nice to add a Readme file that informs visitors to your repository. But we will extend our workflow with a good behaviour: not working in the main branch. We would not want to accidentally overwrite or break the functionality of our package, just because we were working in the same branch. So let’s add a Readme to a new development branch.\n\n\n\nWhen we commit the new Readme file to the development branch, a new window opens to propose the pull request (PR). The PR is nothing more than a request to the package developers to pull your proposed changes into (usually) the main branch of the software. Since we are the developers, we have to both create and accept the PR.\n\n\n\nIt is good procedure to write an informative PR message, usually outlining the nature and rationale of the changes. I also demonstrate how to accept a PR, thereby approving the changes per file (only one now) and signing it with my initials. I cannot formally approve my own PR, since that would leave great opportunity for subjectivity or error. Proper procedure would be to have someone else check and approve your changes.\n\n\n\nWhen you go back to GitHub desktop and fetch the changes on teh remote (that would be GitHub online), you will see that you have now access to the readme file and the development branch.\n\n\nRegistering a DOI\nNow that we have a proper and open source package online and the world as our user base, it would be wise to allow for proper referencing of our package.\nGitHub and Zenodo have paired to facilitate this procedure. If you link your Zenodo account to GitHub, as outlined here, you only have to click, copy and paste to fully make your GitHub repo citeable.\n\n\n\n\n\nAdd citation\nZenodo prepares the repository citation for us. We can simply grab the info, change our personal information and submit it to GitHub.\n\n\n\nThe final step before we would put our package out there is to notify how users can refer to our package. Run the following code:\n\nusethis::use_citation()\n\nwhich will create the necessary citation files for modification\n\n✔ Creating 'inst/'\n✔ Writing 'inst/CITATION'\n• Modify 'inst/CITATION'\n\nWe can now simply grab the text and/or bibtex citation from GitHub and paste it into the CITATION file. The citation info cf. R-packages could be:\n\ncitHeader(\"To cite roundR in publications use:\")\n\ncitEntry(\n  entry    = \"Manual\",\n  title    = \"gerkovink/roundR: Version 0.2.0 - First release\",\n  author   = \"Gerko Vink and Hanne Oberman\",\n  year     = \"2023\",\n  doi      = \"10.5281/zenodo.7668889\",\n  url      = \"github.com/gerkovink/roundR\",\n  textVersion = paste(\n\"Vink, G and Oberman, H.I. (2023). gerkovink/roundR: Version 0.2.0 - First release (Version v0.2.0) [Computer software]. https://doi.org/10.5281/zenodo.7668889\"\n  )\n)\n\nModify this to your name and paste it into the CITATION file.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ontwikkelen en Programmeren in R</span>"
    ]
  },
  {
    "objectID": "meeting8.html#installing-your-own-package-from-github",
    "href": "meeting8.html#installing-your-own-package-from-github",
    "title": "Ontwikkelen en Programmeren in R",
    "section": "Installing your own package from GitHub",
    "text": "Installing your own package from GitHub\nGo to GitHub desktop, and commit and push the changes to GitHub. Then run the following code block:\n\ndevtools::install_github(\"gerkovink/roundR\")\n\nwhere you replace \"gerkovink/roundR\" with your GitHub handle and repository name.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ontwikkelen en Programmeren in R</span>"
    ]
  },
  {
    "objectID": "meeting8.html#advanced-topics",
    "href": "meeting8.html#advanced-topics",
    "title": "Ontwikkelen en Programmeren in R",
    "section": "Advanced topics",
    "text": "Advanced topics\n\n\n\n\nPotential next steps include:\n\nCreating package documentation (e.g. vignettes)\nCreating a hex logo (e.g. with hexmake)\nCreating a package website (e.g. with pkgdown)\nChecking the FAIR-ness of your package (e.g. with howfairis, or BadgeApp)\nChecking the code coverage of your package (e.g. with Codecov)\nMaintaining the package (e.g. with GitHub issues)\nMaintaining contributions (e.g. with a code of conduct)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ontwikkelen en Programmeren in R</span>"
    ]
  },
  {
    "objectID": "meeting8.html#other-useful-sources",
    "href": "meeting8.html#other-useful-sources",
    "title": "Ontwikkelen en Programmeren in R",
    "section": "Other useful sources",
    "text": "Other useful sources\n\nThe R Packages book by Hadley Wickham and Jenny Bryan",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ontwikkelen en Programmeren in R</span>"
    ]
  }
]