# Geavanceerde Data Technieken {#sec-mt6}

::: callout-tip
## Hoorcollege 10 juni 2025
Vandaag gaan we zelf data maken. Op het eerste gezicht klinkt dat misschien een beetje frauduleus - hoe komen we aan die data en waarom zou deze data goed zijn? We zullen zien dat we data-gebaseerde en informatie-gebaseerde modellen kunnen gebruiken om valide inferentie (gevolgtrekkingen) te kunnen trekken op basis van bestaande - al dan niet compleet geobserveerde - data. We gebruiken daarvoor veel van de technieken en theorie die we tot nu toe hebben geleerd. Eigenlijk komt alles wat we tot nu toe hebben besproken samen in dit college. De collegeslides kunt u [hier vinden](slides/lec-6.html)
:::

---
subtitle: "A very quick crash course in `mice`"

author: 
  - name: Gerko Vink
    orcid: 0000-0001-9767-1924
    email: g.vink@uu.nl
    affiliations:
      - name: Methodology & Statistics @ Utrecht University
  - name: Hanne Oberman
    orcid: 0000-0003-3276-2141
    email: h.i.oberman@uu.nl
    affiliations:
      - name: Methodology & Statistics @ Utrecht University
format:
  html:
    highlight-style: github
    number-sections: false
    toc: true
    toc-depth: 3
    code-fold: false
---

The aim of this guide is to make you familiar with [mice](https://github.com/amices/mice) in `R` and to enhance your understanding of multiple imputation, in general. You will learn how to perform and inspect multiple imputations and how to pool the results of analyses performed on multiply-imputed data, how to approach different types of data and how to avoid some of the pitfalls many data scientists may fall into. The main objective is to increase your knowledge and understanding on applications of multiple imputation. 

We start by loading (with `library()`) the necessary packages and fixing the random seed to allow for our outcomes to be replicable. 
```{r, message=FALSE, warning=FALSE}
library(mice)    # data imputation
library(ggmice)  # plotting 
library(ggplot2) # plotting 
library(dplyr)   # data manipulation
library(purrr)   # functional programming
library(magrittr) # pipe operators
```


---

# Multiple imputation with `mice`

---

We fix the RNG seed to allow for replication of the below results. 
```{r}
set.seed(123)
```

The `mice` package contains several datasets. Once the package is loaded, these datasets can be used. Have a look at the `nhanes` dataset (Schafer, 1997, Table 6.14) by typing
```{r}
nhanes
```
 The `nhanes` dataset is a small data set with non-monotone
 missing values. It contains 25 observations on four variables:
 
 - `age`: *age group*
 - `bmi`: *body mass index*
 - `hyp`: *hypertension*
 - `chol`: *cholesterol (mg/dL)*.

To learn more about the data, use one of the two following help commands:
```{r, eval = FALSE, cache = FALSE}
help(nhanes)
?nhanes
```

The `nhanes` dataset is incomplete. We can visualize the missing data patterns by
```{r}
md.pattern(nhanes)
```

For more informative axis labels, we can use the equivalent `ggmice` function `plot_pattern()` as follows
```{r}
plot_pattern(nhanes)
```

Although the most common pattern is the one where all variables are observed, the majority of cases have at least one missing value.

---

**1. Vary the number of imputations, such that the `nhanes` set is imputed $m=3$ times. **

The number of imputed data sets can be specified by the `m = ...` argument. For example, to create just three imputed data sets, specify
```{r, cache = FALSE}
imp <- mice(nhanes, m = 3, print = FALSE)
```

The `print = FALSE` argument omits printing of the iteration history from the output. The main reason to omit printing here is to save space in the document. 

---

**2. Now impute the `nhanes` data $m=5$ times. Inspect the convergence of the algorithm**

The `mice()` function implements an iterative Markov Chain Monte Carlo type of algorithm. Let us have a look at the trace lines generated by the algorithm to study convergence:
```{r, cache = FALSE}
imp <- mice(nhanes, m = 5)
plot_trace(imp)
```

The plot shows the mean (left) and standard deviation (right) of the imputed values only. In general, we would like the streams to intermingle (mixing) and be free of any trends at the later iterations (non-stationary). We inspect trends for the imputed values alone, because the observed data does not change. In our case we cannot speak of convergence, especially not for `bmi`. More iterations or a different model are needed. 

---

**3. Impute the `nhanes` data again, but now fix the random seed to be able to reproduce the imputations.**

The `mice` algorithm uses random sampling, and therefore, the results will be (perhaps slightly) different if we repeat the imputations with different seeds. In order to get identical `mice` objects between calls, we can fix the  use the `seed` argument.  
```{r, cache = FALSE}
imp <- mice(nhanes, seed = 123, print = FALSE)

# or 

set.seed(123)
imp <- mice(nhanes, print = FALSE)
```
where `123` is some arbitrary number that you can choose yourself. Rerunning this command will always yields the same imputed values.

---

**4. See which imputation method was used by studying the `method` dimension in the `imp` object.** 
HINT: you can *take* the correct dimension from the `imp` object with the `$` operator

For each column, the algorithm requires a specification of the imputation method. To see which method was used by default:
```{r, cache = FALSE}
imp$method
```
The variable `age` is complete and therefore not imputed, denoted by the `""` empty string. The other variables have method `pmm`, which stands for *predictive mean matching*, the default in
`mice` for numerical and integer data.  

---

In reality, the `nhanes` data are better described a as mix of numerical and categorical data. Let us take a look at the `nhanes2` data frame:
```{r, cache = FALSE}
summary(nhanes2)
```
and the structure of the data frame
```{r, cache = FALSE}
str(nhanes2)
```
Variable `age` consists of 3 age categories, while variable `hyp` is binary. The `mice()` function takes these properties automatically into account. 

---

**5. Impute the `nhanes2` dataset with `mice` and inspect which methods are now used for imputing the columns.**
```{r, cache = FALSE}
imp <- mice(nhanes2, print = FALSE)
imp$meth
```
Notice that `mice` has set the imputation method for
variable `hyp` to `logreg`, which implements multiple imputation by *logistic
regression*. 

::: .callout-warning
# Set the measurement level
If you correctly have set the measurement levels of your data variables, `mice` will by default apply the correct imputation method. If you have not set the measurement levels, `mice` may falsely assume that a variable is of a different nature. This may lead to unexpected results, so it is always a good idea to check the measurement levels of your data before running `mice()`.
:::

Now we may again plot trace lines to study convergence
```{r, cache = FALSE}
plot_trace(imp)
```

---

**6. Extend the number of iterations**

Though using just five iterations (the default) often works well in practice, we can extend the number of iterations of the `mice` algorithm to confirm that there is no trend and that the trace lines intermingle well. We can increase the number of iterations to 40 by 

- re-running the `mice()` function with argument `maxit = 40`
- running 35 additional iterations using the `mice.mids()` function and the object `imp` as the starting point.

```{r, cache = FALSE}
imp40 <- mice.mids(imp, maxit = 35, print = FALSE)
plot_trace(imp40)
```

All is in order. There is one particularity to note: the trace lines for the sd of `hyp` sometimes drop to zero. This is because the imputed values for `hyp` are binary, and therefore the standard deviation of a binary variable can be zero if all the imputed values are the same (i.e. 0 or 1).

---

# Repeated analysis in `mice`

---

**7. Perform the following regression analysis on the multiply imputed data and assign the result to object `fit`. **


$$\text{bmi} = \beta_0 + \beta_1 \text{chl} + \epsilon$$

Let's run the above model on the imputed data set. 
```{r, cache = FALSE}
fit <- imp40 %>% 
  complete("all") %>% 
  map(~.x %$% lm(bmi ~ chl))
fit
```

The `fit` object contains the regression summaries for each data set. Suppose we want to find the regression model fitted to the
second imputed data set. It can be found as
```{r, cache = FALSE}
summary(fit[[2]])
```

---

**8. Pool the analyses from object `fit`. **

Pooling the repeated regression analyses can be done simply by typing
```{r, cache = FALSE}
pool.fit <- pool(fit)
summary(pool.fit)
pool.fit
```
which gives the relevant pooled regression coefficients and
parameters, as well as the fraction of information about the
coefficients missing due to non-response (`fmi`) and the proportion of the variation attributable to the missing data (`lambda`). The pooled fit object is of class `mipo`, which stands for *multiply imputed pooled object*. 

Alternatively, we could use a functional programming pipe to achieve the same
```{r}
fit <- imp40 %>%  
  complete("all") %>%  # list of imputed data sets
  map(~.x %$% lm(bmi ~ chl)) %>%  
  pool() %>% 
  summary()
```

`mice` can pool many analyses from a variety of packages for you (it uses `broom` to gather all parameters). 

---

# Conclusion
We have seen that the practical execution of multiple imputation and pooling is straightforward with the `R` package `mice`. The package is designed to allow you to assess and control the imputations themselves, the convergence of the algorithm and the distributions and multivariate relations of the observed and imputed data. 

It is important to 'gain' this control as a user. After all, we are imputing values and we aim to properly adress the uncertainty about the missingness problem. 

---

# Materials beyond this course
A more detailed practical guide to `mice` in `R` can be found [here](https://www.gerkovink.com/miceVignettes/)

---

# References

Rubin, D. B. *Multiple imputation for nonresponse in surveys*. John Wiley & Sons, 1987. [Amazon](http://www.amazon.com/Multiple-Imputation-Nonresponse-Surveys-Donald/dp/0471655740/ref=sr_1_1?ie=UTF8&qid=1434466788&sr=8-1&keywords=Multiple+imputation+for+nonresponse+in+surveys)

Schafer, J.L. (1997). *Analysis of Incomplete Multivariate Data*. London: Chapman & Hall. Table 6.14. [Amazon](http://www.amazon.com/Incomplete-Multivariate-Monographs-Statistics-Probability/dp/0412040611/ref=sr_1_1?ie=UTF8&qid=1434466828&sr=8-1&keywords=Analysis+of+Incomplete+Multivariate+Data)

Van Buuren, S. and Groothuis-Oudshoorn, K. (2011). mice: Multivariate Imputation by Chained Equations in R. *Journal of Statistical Software*, 45(3), 1-67. [pdf](http://www.jstatsoft.org/v45/i03/paper)

---

**- End of practical**

---

```{r}
sessionInfo()
```

